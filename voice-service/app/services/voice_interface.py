"""
ASR æ¥å£ï¼šrecognize_voice
KWS å”¤é†’æ¥å£ï¼škws_wakeup
ASR & KWS æ¥å£ï¼šasr_wake
"""

import logging
import os
import re
import shutil
import subprocess
import tempfile
import time
from typing import List, Optional, Union, Any, Tuple, Dict

# ASRä½¿ç”¨FunASR WebSocketå®¢æˆ·ç«¯
import asyncio
import websockets
import json
import base64
# KWSç»§ç»­ä½¿ç”¨æœ¬åœ°AutoModel
from funasr import AutoModel
from app.services.full_hotwords import SYMS
from app.services.hg_deepseek import process_speech_result

# æµå¼å¤„ç†ç›¸å…³å¯¼å…¥
import numpy as np
import wave
from io import BytesIO

logger = logging.getLogger(__name__)

SAMPLE_RATE = 16000
CHANNELS = 1

# FunASR WebSocketé…ç½®
FUNASR_WS_URL = "ws://localhost:10095"

def load_hotwords_from_file() -> str:
    """
    ä»çƒ­è¯æ–‡ä»¶åŠ è½½çƒ­è¯å’Œæƒé‡ï¼Œè¿”å›FunASRæ‰€éœ€çš„JSONå­—ç¬¦ä¸²æ ¼å¼
    æ ¼å¼ï¼š"{\"å°äº‘\":80,\"å°äº‘å°äº‘\":85}"
    
    æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
    1. å¸¦æƒé‡ï¼šword weightï¼ˆä¾‹å¦‚ï¼š"èƒ¸é—· 80"ï¼‰
    2. ä¸å¸¦æƒé‡ï¼šwordï¼ˆä¾‹å¦‚ï¼š"èƒ¸é—·"ï¼‰ï¼Œä½¿ç”¨é»˜è®¤æƒé‡ 20
    """
    # æ³¨æ„ï¼šçƒ­è¯åŠ è½½é€šå¸¸åªåœ¨é¦–æ¬¡è°ƒç”¨æ—¶è€—æ—¶ï¼Œåç»­ä¼šä½¿ç”¨ç¼“å­˜
    hotwords = {}
    try:
        hotwords_file = "app/services/hotwords.txt"
        with open(hotwords_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:  # è·³è¿‡ç©ºè¡Œ
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æƒé‡ï¼ˆåŒ…å«ç©ºæ ¼ä¸”æœ€åä¸€éƒ¨åˆ†æ˜¯æ•°å­—ï¼‰
                if ' ' in line:
                    parts = line.rsplit(' ', 1)
                    word = parts[0].strip()
                    weight_str = parts[1].strip()
                    try:
                        weight = int(weight_str)
                        hotwords[word] = weight
                    except ValueError:
                        # å¦‚æœæœ€åä¸€éƒ¨åˆ†ä¸æ˜¯æ•°å­—ï¼Œæ•´è¡Œä½œä¸ºçƒ­è¯ï¼Œä½¿ç”¨é»˜è®¤æƒé‡
                        logger.debug("çƒ­è¯è¡Œæ— æœ‰æ•ˆæƒé‡ï¼Œä½¿ç”¨é»˜è®¤æƒé‡: %s", line)
                        hotwords[line] = 20
                else:
                    # æ²¡æœ‰ç©ºæ ¼ï¼Œæ•´è¡Œä½œä¸ºçƒ­è¯ï¼Œä½¿ç”¨é»˜è®¤æƒé‡
                    hotwords[line] = 20
        logger.info("å·²åŠ è½½ %s ä¸ªçƒ­è¯", len(hotwords))
    except Exception as e:
        logger.error("åŠ è½½çƒ­è¯æ–‡ä»¶å¤±è´¥: %s", e)
        # ä½¿ç”¨é»˜è®¤çƒ­è¯
        hotwords = {"å°äº‘": 80, "å°äº‘å°äº‘": 85}
    
    # è¿”å›JSONå­—ç¬¦ä¸²æ ¼å¼ï¼ˆç¬¦åˆFunASRå®˜æ–¹è¦æ±‚ï¼‰
    if hotwords:
        return json.dumps(hotwords, ensure_ascii=False)
    return ""


# ---------------- ffmpeg-only éŸ³é¢‘è½¬æ¢å·¥å…· ----------------

def _find_ffmpeg() -> Optional[str]:
    """è¿”å›ç³»ç»Ÿä¸­ ffmpeg çš„è·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¦åˆ™ Noneã€‚"""
    return shutil.which("ffmpeg")


def _convert_with_ffmpeg(ffmpeg_path: str, input_path: str, out_path: str,
                         target_sr: int = SAMPLE_RATE, channels: int = CHANNELS) -> bool:
    """
    ä½¿ç”¨ ffmpeg è¿›è¡Œè½¬æ¢ä¸º 16k å•å£°é“ PCM WAVã€‚
    è¿”å› True è¡¨ç¤ºæˆåŠŸï¼ŒFalse è¡¨ç¤ºå¤±è´¥ã€‚
    """
    ffmpeg_start = time.perf_counter()
    logger.info("_convert_with_ffmpegå¼€å§‹: input_path=%s, out_path=%s", input_path, out_path)
    cmd = [
        ffmpeg_path, "-y", "-hide_banner", "-loglevel", "error",
        "-i", input_path,
        "-ac", str(channels),
        "-ar", str(target_sr),
        "-acodec", "pcm_s16le",
        out_path
    ]
    try:
        if os.path.exists(input_path):
            logger.info("è¾“å…¥æ–‡ä»¶å­˜åœ¨: %s", input_path)
        else:
            logger.error("è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: %s", input_path)
            return False

        # capture_output é¿å…åœ¨æ§åˆ¶å°æ‰“å° ffmpeg ä¿¡æ¯ï¼›è‹¥éœ€è¦è°ƒè¯•å¯å»æ‰ capture_output å¹¶è§‚å¯Ÿ stderr
        logger.info("æ‰§è¡Œffmpegå‘½ä»¤: %s", ' '.join(cmd))
        _ = subprocess.run(cmd, check=True, capture_output=True, text=True)
        ffmpeg_time = (time.perf_counter() - ffmpeg_start) * 1000
        logger.info("ffmpegè½¬æ¢æˆåŠŸ")
        logger.info("è€—æ—¶ç»Ÿè®¡ - ffmpegè½¬æ¢: %.2f ms", ffmpeg_time)
        return True
    except subprocess.CalledProcessError as e:
        logger.error("ffmpegè½¬æ¢å¤±è´¥: %s", e)
        logger.error("ffmpeg stderr: %s", e.stderr)
        logger.error("ffmpeg stdout: %s", e.stdout)
        return False
    except Exception as e:
        logger.error("ffmpegè½¬æ¢å¼‚å¸¸: %s", e)
        return False


def ensure_wav_mono_16k(input_path: str, max_tmp: Optional[str] = None) -> str:
    """
    å°†è¾“å…¥æ–‡ä»¶ä½¿ç”¨ ffmpeg è½¬ä¸ºä¸´æ—¶ 16k å•å£°é“ PCM WAVï¼Œè¿”å›è·¯å¾„ï¼ˆä»¥ .wav ç»“å°¾ï¼‰ã€‚
    ä»…ä½¿ç”¨ ffmpegï¼›è‹¥ç³»ç»Ÿæ‰¾ä¸åˆ° ffmpeg æˆ–è½¬æ¢å¤±è´¥åˆ™æŠ›å‡º RuntimeErrorã€‚
    """
    convert_start = time.perf_counter()
    logger.info("ensure_wav_mono_16kå¼€å§‹: input_path=%s", input_path)

    if not os.path.isfile(input_path):
        logger.error("éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: %s", input_path)
        raise FileNotFoundError(f"audio file not found: {input_path}")

    ffmpeg_check_start = time.perf_counter()
    ffmpeg_path = _find_ffmpeg()
    if not ffmpeg_path:
        logger.error("ffmpegæœªæ‰¾åˆ°")
        raise RuntimeError(
            "ffmpeg not found. Please install ffmpeg and make it available in PATH, "
            "or add its directory to PATH. Check with `ffmpeg -version`."
        )
    ffmpeg_check_time = (time.perf_counter() - ffmpeg_check_start) * 1000
    logger.info("è€—æ—¶ç»Ÿè®¡ - æŸ¥æ‰¾ffmpeg: %.2f ms", ffmpeg_check_time)

    tmp_create_start = time.perf_counter()
    tmp_dir = max_tmp or tempfile.gettempdir()
    fd, tmp_wav = tempfile.mkstemp(suffix=".wav", dir=tmp_dir)
    os.close(fd)
    tmp_create_time = (time.perf_counter() - tmp_create_start) * 1000
    logger.info("åˆ›å»ºä¸´æ—¶æ–‡ä»¶: %s", tmp_wav)
    logger.info("è€—æ—¶ç»Ÿè®¡ - åˆ›å»ºè½¬æ¢ä¸´æ—¶æ–‡ä»¶: %.2f ms", tmp_create_time)

    ffmpeg_path = "ffmpeg"
    ok = _convert_with_ffmpeg(ffmpeg_path, input_path, tmp_wav, target_sr=SAMPLE_RATE, channels=CHANNELS)
    if ok:
        total_convert_time = (time.perf_counter() - convert_start) * 1000
        logger.info("éŸ³é¢‘è½¬æ¢æˆåŠŸ")
        logger.info("è€—æ—¶ç»Ÿè®¡ - ensure_wav_mono_16kæ€»è€—æ—¶: %.2f ms", total_convert_time)
        return tmp_wav

    # è½¬æ¢å¤±è´¥ï¼Œæ¸…ç†å¹¶æŠ›é”™
    logger.error("éŸ³é¢‘è½¬æ¢å¤±è´¥")
    try:
        os.remove(tmp_wav)
    except Exception:
        pass

    raise RuntimeError(
        f"ffmpeg conversion failed for file: {input_path}\n"
        "Ensure the input file is valid and ffmpeg supports its format."
    )


# ---------------- è¯†åˆ«æ¥å£ï¼ˆhotwords å¯é€‰ï¼‰ ----------------
def _normalize_hotwords(hotwords: Optional[Union[List[str], str]]) -> str:
    """
    å°†çƒ­è¯åˆ—è¡¨æˆ–å•å­—ç¬¦ä¸²è½¬ä¸º funasr æ‰€éœ€çš„çƒ­è¯å­—ç¬¦ä¸²ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼‰ã€‚
    å¦‚æœ hotwords ä¸º None æˆ–ç©ºï¼Œåˆ™è¿”å›ç©ºå­—ç¬¦ä¸²ã€‚
    """
    if not hotwords:
        return ""
    if isinstance(hotwords, str):
        return hotwords
    return " ".join([w.strip() for w in hotwords if w and w.strip()])


# ========== æ—§çš„ FunASR WebSocket æ¥å£ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™ä½œä¸ºå‚è€ƒï¼‰ ==========
# async def recognize_voice_websocket(audio_path: str, hotwords: Optional[List[str]] = None) -> str:
#     """
#     WebSocket ASRæ¥å£ï¼ˆå®˜æ–¹æµå¼åè®®ï¼‰ï¼š
#       - audio_path: æœ¬åœ°éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
#       - hotwords: å¯é€‰çš„çƒ­è¯åˆ—è¡¨ï¼ˆList[str]ï¼‰ï¼Œä¼  None æˆ–ä¸ä¼ æ—¶ä¸ä½¿ç”¨çƒ­è¯
#     è¿”å›ï¼š
#       - è¯†åˆ«ç»“æœå­—ç¬¦ä¸²
#     """
#     websocket_start = time.perf_counter()
    
    # # âš ï¸ è¯»å–å¹¶è®°å½•FunASR LMé…ç½®çŠ¶æ€ï¼ˆç”¨äºç¡®è®¤LMæ˜¯å¦è¢«ç¦ç”¨ï¼‰
    # try:
    #     from app.config import config
    #     voice_config = getattr(config, "voice_service", None)
    #     if voice_config:
    #         funasr_disable_lm = voice_config.funasr_disable_lm
    #         lm_status = "å·²ç¦ç”¨" if funasr_disable_lm else "å·²å¯ç”¨"
    #         logger.info("ğŸ”§ [FunASR LMé…ç½®] funasr_disable_lm=%s (%s)", funasr_disable_lm, lm_status)
    #     else:
    #         logger.warning("âš ï¸ [FunASR LMé…ç½®] æ— æ³•è¯»å–voice_serviceé…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼")
    # except Exception as e:
    #     logger.warning("âš ï¸ [FunASR LMé…ç½®] è¯»å–é…ç½®å¼‚å¸¸: %s", e)
    
    # logger.info("recognize_voice_websocketå¼€å§‹: audio_path=%s", audio_path)
    # tmp_wav = None
    # try:
    #     # 1. éŸ³é¢‘æ ¼å¼è½¬æ¢
    #     tmp_wav = ensure_wav_mono_16k(audio_path)
    #     logger.info("éŸ³é¢‘è½¬æ¢å®Œæˆ: %s", tmp_wav)
        
    #     # 2. è¯»å–éŸ³é¢‘æ–‡ä»¶ï¼ˆäºŒè¿›åˆ¶ï¼Œä¸ç”¨base64ï¼‰
    #     read_start = time.perf_counter()
    #     with open(tmp_wav, 'rb') as f:
    #         audio_data = f.read()
    #     read_time = (time.perf_counter() - read_start) * 1000
    #     logger.info("è€—æ—¶ç»Ÿè®¡ - è¯»å–éŸ³é¢‘æ–‡ä»¶: %.2f ms", read_time)
        
    #     # 3. å‡†å¤‡çƒ­è¯é…ç½®ï¼ˆJSONå­—ç¬¦ä¸²æ ¼å¼ï¼‰
    #     hotword_start = time.perf_counter()
    #     hotword_str = load_hotwords_from_file()
    #     if hotwords:
    #         # å¦‚æœä¼ å…¥é¢å¤–çƒ­è¯ï¼Œéœ€è¦åˆå¹¶
    #         hotword_dict = json.loads(hotword_str) if hotword_str else {}
    #         for word in hotwords:
    #             if word not in hotword_dict:
    #                 hotword_dict[word] = 20  # é»˜è®¤æƒé‡
    #         hotword_str = json.dumps(hotword_dict, ensure_ascii=False)
    #     hotword_time = (time.perf_counter() - hotword_start) * 1000
    #     logger.info("çƒ­è¯é…ç½®: %s...", hotword_str[:100])  # åªæ‰“å°å‰100å­—ç¬¦
    #     logger.info("è€—æ—¶ç»Ÿè®¡ - åŠ è½½çƒ­è¯é…ç½®: %.2f ms", hotword_time)
        
    #     # 4. WebSocketè¿æ¥å’Œè¯†åˆ«ï¼ˆå®˜æ–¹æµå¼åè®®ï¼‰
    #     ws_connect_start = time.perf_counter()
    #     async with websockets.connect(FUNASR_WS_URL) as websocket:
    #         ws_connect_time = (time.perf_counter() - ws_connect_start) * 1000
    #         logger.info("è€—æ—¶ç»Ÿè®¡ - WebSocketè¿æ¥: %.2f ms", ws_connect_time)
            
    #         # 4.1 å‘é€åˆå§‹åŒ–JSONï¼ˆmode: offline, wav_format: wavï¼‰
    #         init_start = time.perf_counter()
    #         init_request = {
    #             "mode": "offline",
    #             "wav_name": os.path.basename(tmp_wav),
    #             "wav_format": "wav",
    #             "is_speaking": True,
    #             "hotwords": hotword_str  # JSONå­—ç¬¦ä¸²
    #         }
            
    #         await websocket.send(json.dumps(init_request))
    #         init_time = (time.perf_counter() - init_start) * 1000
    #         logger.info("å·²å‘é€WebSocketåˆå§‹åŒ–è¯·æ±‚")
    #         logger.info("è€—æ—¶ç»Ÿè®¡ - å‘é€åˆå§‹åŒ–è¯·æ±‚: %.2f ms", init_time)
            
    #         # 4.2 åˆ†å—å‘é€äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®ï¼ˆå‚è€ƒå®˜æ–¹ç¤ºä¾‹ï¼Œofflineæ¨¡å¼å¿«é€Ÿå‘é€ï¼‰
    #         send_start = time.perf_counter()
    #         chunk_size = 8192  # 8KBæ¯å—
    #         total_chunks = (len(audio_data) + chunk_size - 1) // chunk_size
    #         logger.info("å‡†å¤‡åˆ†å—å‘é€éŸ³é¢‘: æ€»å¤§å°=%så­—èŠ‚, å…±%så—", len(audio_data), total_chunks)
            
    #         for i in range(total_chunks):
    #             beg = i * chunk_size
    #             end = min(beg + chunk_size, len(audio_data))
    #             chunk = audio_data[beg:end]
    #             await websocket.send(chunk)  # ç›´æ¥å‘é€äºŒè¿›åˆ¶
    #             # offlineæ¨¡å¼å‡ ä¹ä¸éœ€è¦å»¶è¿Ÿï¼ˆå‚è€ƒå®˜æ–¹è„šæœ¬0.001ç§’ï¼‰
    #             if i < total_chunks - 1:  # æœ€åä¸€å—å‘é€åç«‹å³å‘ç»“æŸä¿¡å·ï¼Œä¸å»¶è¿Ÿ
    #                 await asyncio.sleep(0.001)
    #             logger.debug("å·²å‘é€éŸ³é¢‘å— %s/%s (%så­—èŠ‚)", i + 1, total_chunks, len(chunk))
            
    #         # 4.3 å‘é€ç»“æŸä¿¡å·
    #         send_time = (time.perf_counter() - send_start) * 1000
    #         logger.info("è€—æ—¶ç»Ÿè®¡ - å‘é€éŸ³é¢‘æ•°æ®: %.2f ms", send_time)
            
    #         end_start = time.perf_counter()
    #         end_request = {"is_speaking": False}
    #         await websocket.send(json.dumps(end_request))
    #         end_time = (time.perf_counter() - end_start) * 1000
    #         logger.info("å·²å‘é€ç»“æŸä¿¡å·")
    #         logger.info("è€—æ—¶ç»Ÿè®¡ - å‘é€ç»“æŸä¿¡å·: %.2f ms", end_time)
            
    #         # 4.4 æ¥æ”¶ç»“æœï¼ˆofflineæ¨¡å¼ï¼šå‚ç…§å®˜æ–¹è„šæœ¬ï¼Œæ”¶åˆ°ç¬¬ä¸€æ¡æœ‰æ•ˆç»“æœå³å®Œæˆï¼‰
    #         receive_start = time.perf_counter()
    #         result_text = ""
    #         first_receive_timeout = 3.0  # ç¬¬ä¸€æ¬¡æ¥æ”¶è¶…æ—¶ï¼š3ç§’ï¼ˆæœåŠ¡ç«¯å¤„ç†éœ€è¦æ—¶é—´ï¼‰
    #         subsequent_timeout = 0.5  # åç»­æ¥æ”¶è¶…æ—¶ï¼š0.5ç§’ï¼ˆå¿«é€Ÿæ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šç»“æœï¼‰
    #         received_count = 0
            
    #         while received_count < 3:  # æœ€å¤šæ¥æ”¶3æ¡æ¶ˆæ¯ï¼ˆé€šå¸¸1æ¡å°±å¤Ÿäº†ï¼‰
    #             try:
    #                 # ç¬¬ä¸€æ¬¡ç­‰å¾…ç¨é•¿ï¼ˆæœåŠ¡ç«¯éœ€è¦å¤„ç†ï¼‰ï¼Œåç»­å¿«é€Ÿæ£€æŸ¥
    #                 timeout = first_receive_timeout if received_count == 0 else subsequent_timeout
    #                 response = await asyncio.wait_for(websocket.recv(), timeout=timeout)
                    
    #                 # å°è¯•è§£æä¸ºJSONï¼ˆå¯èƒ½æ˜¯æ–‡æœ¬æ¶ˆæ¯ï¼‰
    #                 try:
    #                     result = json.loads(response)
    #                 except (json.JSONDecodeError, TypeError):
    #                     # å¦‚æœä¸æ˜¯JSONï¼Œå¯èƒ½æ˜¯äºŒè¿›åˆ¶æ•°æ®ï¼Œç»§ç»­ç­‰å¾…
    #                     logger.warning("æ”¶åˆ°éJSONæ¶ˆæ¯ï¼Œç»§ç»­ç­‰å¾…")
    #                     continue
                    
    #                 received_count += 1
    #                 logger.info("WebSocketè¯†åˆ«ç»“æœ #%s: %s...", received_count, result.get('text', '')[:100])
                    
    #                 # æå–æ–‡æœ¬ï¼ˆå‚ç…§å®˜æ–¹è„šæœ¬ï¼šofflineæ¨¡å¼æ”¶åˆ°ç»“æœå°±å®Œæˆï¼‰
    #                 if isinstance(result, dict):
    #                     if "text" in result:
    #                         current_text = result.get("text", "")
    #                         if current_text:
    #                             result_text = current_text  # offlineæ¨¡å¼è¦†ç›–ä¹‹å‰çš„ç»“æœ
    #                             logger.info("âœ… æ”¶åˆ°è¯†åˆ«ç»“æœ: %s", result_text)
                                
    #                             # offlineæ¨¡å¼ï¼šæ”¶åˆ°æœ‰æ•ˆç»“æœå°±é€€å‡ºï¼ˆå‚ç…§å®˜æ–¹è„šæœ¬ç¬¬286è¡Œï¼‰
    #                             if result.get("mode") == "offline":
    #                                 logger.info("offlineæ¨¡å¼ï¼šæ”¶åˆ°ç»“æœï¼Œç«‹å³è¿”å›")
    #                                 break
                                
    #                             # å…¶ä»–æ¨¡å¼ï¼šç­‰å¾…is_finalæ ‡å¿—
    #                             if result.get("is_final", False):
    #                                 logger.info("æ”¶åˆ°æœ€ç»ˆç»“æœ (is_final=True)")
    #                                 break
                
    #             except asyncio.TimeoutError:
    #                 if result_text:
    #                     # å·²æœ‰ç»“æœï¼Œå¯èƒ½æœåŠ¡ç«¯å¤„ç†å®Œæˆï¼Œé€€å‡º
    #                     logger.info("å·²æ”¶åˆ°ç»“æœä¸”ç­‰å¾…è¶…æ—¶ï¼Œä½¿ç”¨å½“å‰ç»“æœ")
    #                     break
    #                 else:
    #                     # æ²¡æœ‰ç»“æœä½†è¶…æ—¶ï¼Œå¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´
    #                     if received_count == 0:
    #                         logger.warning("é¦–æ¬¡æ¥æ”¶è¶…æ—¶ï¼ˆ%sç§’ï¼‰ï¼Œç»§ç»­ç­‰å¾…...", first_receive_timeout)
    #                         continue  # ç¬¬ä¸€æ¬¡è¶…æ—¶ï¼Œå†è¯•ä¸€æ¬¡
    #                     else:
    #                         logger.info("åç»­æ¥æ”¶è¶…æ—¶ï¼Œä½¿ç”¨å·²æœ‰ç»“æœ")
    #                         break
    #             except Exception as e:
    #                 logger.error("æ¥æ”¶ç»“æœå¼‚å¸¸: %s", e)
    #                 break
            
    #         receive_time = (time.perf_counter() - receive_start) * 1000
    #         logger.info("è€—æ—¶ç»Ÿè®¡ - æ¥æ”¶è¯†åˆ«ç»“æœ: %.2f ms", receive_time)
            
    #         if not result_text:
    #             logger.warning("æœªæ”¶åˆ°æœ‰æ•ˆè¯†åˆ«ç»“æœ")
            
    #         total_websocket_time = (time.perf_counter() - websocket_start) * 1000
    #         logger.info("æœ€ç»ˆè¯†åˆ«ç»“æœ: %s", result_text)
    #         logger.info("è€—æ—¶ç»Ÿè®¡ - recognize_voice_websocketæ€»è€—æ—¶: %.2f ms", total_websocket_time)
    #         return result_text if result_text else ""
        
    # except Exception as e:
    #     logger.error("recognize_voice_websocketå¼‚å¸¸: %s", e, exc_info=True)
    #     raise
    # finally:
    #     # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¦‚æœæ˜¯ä¸´æ—¶ç”Ÿæˆçš„ï¼‰
    #     if tmp_wav and os.path.abspath(tmp_wav) != os.path.abspath(audio_path):
    #         try:
    #             os.remove(tmp_wav)
    #         except Exception:
    #             logger.warning("æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥")


# def recognize_voice(audio_path: str, hotwords: Optional[List[str]] = None) -> str:
#     """
#     åŒæ­¥åŒ…è£…å™¨ï¼ˆä»…ç”¨äºéäº‹ä»¶å¾ªç¯ç¯å¢ƒï¼‰ã€‚
#     åœ¨FastAPIåç¨‹ç¯å¢ƒä¸­è¯·ç›´æ¥è°ƒç”¨ recognize_voice_websocketã€‚
#     """
#     return asyncio.run(recognize_voice_websocket(audio_path, hotwords))


# ---------------- å”¤é†’æ¥å£ï¼ˆå”¤é†’è¯"å°äº‘å°äº‘"ï¼‰----------------
# KWSæ¨¡å‹åˆå§‹åŒ–
kws_model = None

def get_models():
    """
    è·å–æ¨¡å‹å®ä¾‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
    ASRå·²è¿ç§»åˆ°Dockerå®¹å™¨ï¼Œåªè¿”å›KWSæ¨¡å‹
    """
    global kws_model
    
    if kws_model is None:
        logger.info("KWSæ¨¡å‹æœªåˆå§‹åŒ–ï¼Œå¼€å§‹åˆå§‹åŒ–æ¨¡å‹")
        
        # ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼Œé¿å…ä»ModelScopeä¸‹è½½
        # Dockerå®¹å™¨ä¸­æ¨¡å‹è·¯å¾„ï¼š/workspace/models/damo/speech_charctc_kws_phone-xiaoyun/
        # ä»£ç è¿è¡Œåœ¨ /workspace/voice-serviceï¼Œæ‰€ä»¥ä½¿ç”¨ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„
        model_dir = "/workspace/models/damo/speech_charctc_kws_phone-xiaohu"
        
        # å¦‚æœç»å¯¹è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•ç›¸å¯¹è·¯å¾„ï¼ˆæœ¬åœ°å¼€å‘ç¯å¢ƒï¼‰
        if not os.path.exists(model_dir):
            # å°è¯•ä»å½“å‰æ–‡ä»¶ä½ç½®è®¡ç®—ç›¸å¯¹è·¯å¾„
            current_dir = os.path.dirname(os.path.abspath(__file__))
            relative_model_dir = os.path.join(current_dir, "models", "damo", "speech_charctc_kws_phone-xiaohu")
            if os.path.exists(relative_model_dir):
                model_dir = relative_model_dir
                logger.info("ä½¿ç”¨ç›¸å¯¹è·¯å¾„æ¨¡å‹ç›®å½•: %s", model_dir)
            else:
                logger.warning("æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: %s å’Œ %sï¼Œå°†å°è¯•ä»ModelScopeä¸‹è½½", model_dir, relative_model_dir)
                # å¦‚æœæœ¬åœ°è·¯å¾„éƒ½ä¸å­˜åœ¨ï¼Œfallbackåˆ°ModelScopeï¼ˆä½†åº”è¯¥ä¸ä¼šå‘ç”Ÿï¼‰
                model_dir = "iic/speech_charctc_kws_phone-xiaoyun"
        else:
            logger.info("ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç›®å½•: %s", model_dir)
        
        # åˆå§‹åŒ–KWSæ¨¡å‹ - ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„
        kws_model = AutoModel(
            model=model_dir,
            keywords="å°æŠ¤",
            output_dir="./outputs/debug",
            device='cpu',
            disable_update=True,
            disable_pbar=True
        )
        logger.info("KWSæ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
    else:
        logger.info("ä½¿ç”¨å·²åˆå§‹åŒ–çš„KWSæ¨¡å‹")
    
    # è¿”å› (asr_model=Noneå› ä¸ºç”¨HTTP, kws_model)
    return None, kws_model


def kws_wakeup(audio_input: Any = None) -> bool:
    """
    ä½¿ç”¨ model.generate(input=audio_input, cache={}) è§£æå…³é”®è¯å”¤é†’ç»“æœã€‚
    è¿”å›:
      True  - å”¤é†’æˆåŠŸï¼ˆæ£€æµ‹åˆ°çš„æ–‡æœ¬ä¸ç­‰äº 'rejected' ä¸”éç©ºï¼‰
      False - å”¤é†’å¤±è´¥ã€è§£æé”™è¯¯æˆ–å¼‚å¸¸

    æ³¨æ„: audio_input æ˜¯ model.generate èƒ½æ¥å—çš„éŸ³é¢‘è¾“å…¥ï¼ˆä¾‹å¦‚ wav è·¯å¾„ï¼‰ã€‚
    """
    kws_wakeup_start = time.perf_counter()
    logger.info("kws_wakeupå¼€å§‹: audio_input=%s", audio_input)
    try:
        # è·å–KWSæ¨¡å‹å®ä¾‹
        model_get_start = time.perf_counter()
        _, kws_model_instance = get_models()
        model_get_time = (time.perf_counter() - model_get_start) * 1000
        logger.info("è€—æ—¶ç»Ÿè®¡ - è·å–KWSæ¨¡å‹: %.2f ms", model_get_time)
        
        generate_start = time.perf_counter()
        res = kws_model_instance.generate(input=audio_input, cache={})
        generate_time = (time.perf_counter() - generate_start) * 1000
        logger.info("KWSæ¨¡å‹è¿”å›ç»“æœ: %s", res)
        logger.info("è€—æ—¶ç»Ÿè®¡ - KWSæ¨¡å‹æ¨ç†: %.2f ms", generate_time)
    except Exception as e:
        # è°ƒç”¨å¤±è´¥è§†ä¸ºå”¤é†’å¤±è´¥
        logger.error("KWSæ¨¡å‹è°ƒç”¨å¼‚å¸¸: %s", e, exc_info=True)
        return False

    # åŸºæœ¬å®‰å…¨æ£€æŸ¥ï¼šæœŸå¾… res æ˜¯ list/tuple ä¸”ç¬¬ 0 é¡¹ä¸º dictï¼Œä¸”åŒ…å« "text"
    if not (isinstance(res, (list, tuple)) and len(res) > 0 and isinstance(res[0], dict)):
        logger.error("KWSç»“æœæ ¼å¼å¼‚å¸¸: %s %s", type(res), res)
        return False

    # æå– text å­—æ®µ
    wake_field = res[0].get("text", None)
    if wake_field is None:
        logger.info("KWSç»“æœä¸­æ— 'text'å­—æ®µ -> å”¤é†’å¤±è´¥")
        return False

    # å…¼å®¹ text å¯èƒ½ä¸ºå­—ç¬¦ä¸²æˆ–åˆ—è¡¨çš„æƒ…å†µ
    wake_text = None
    if isinstance(wake_field, str):
        wake_text = wake_field
    elif isinstance(wake_field, (list, tuple)) and len(wake_field) > 0:
        first = wake_field[0]
        if isinstance(first, dict):
            wake_text = first.get("text")
        else:
            wake_text = str(first)
    else:
        # å…¶å®ƒç±»å‹ä¸€å¾‹è½¬å­—ç¬¦ä¸²å¤„ç†
        wake_text = str(wake_field)

    logger.info("KWSå”¤é†’æ–‡æœ¬: %s", wake_text)

    # æœ€ç»ˆåˆ¤æ–­ï¼šéç©ºä¸”ä¸ç­‰äº 'rejected' åˆ™è®¤ä¸ºå”¤é†’æˆåŠŸ
    total_kws_time = (time.perf_counter() - kws_wakeup_start) * 1000
    if wake_text and wake_text != "rejected":
        logger.info("KWSå”¤é†’æˆåŠŸ: %s", wake_text)
        logger.info("è€—æ—¶ç»Ÿè®¡ - kws_wakeupæ€»è€—æ—¶: %.2f ms", total_kws_time)
        return True
    else:
        logger.info("KWSå”¤é†’å¤±è´¥: %s", wake_text)
        logger.info("è€—æ—¶ç»Ÿè®¡ - kws_wakeupæ€»è€—æ—¶: %.2f ms", total_kws_time)
        return False

# å‰”é™¤å”¤é†’è¯ï¼ˆ"å°äº‘å°äº‘"æˆ–"å°äº‘"ï¼‰


def remove_xiaoyun(s: str, *, collapse_spaces: bool = True) -> Tuple[str, int]:
    """
    ä»å­—ç¬¦ä¸² s ä¸­ç§»é™¤æ‰€æœ‰ "å°äº‘" æˆ– "å°äº‘å°äº‘" çš„å‡ºç°ï¼ˆä¼˜å…ˆåŒ¹é… "å°äº‘å°äº‘"ï¼‰ã€‚
    è¿”å› (cleaned_string, removed_count)

    å‚æ•°:
      s: åŸå§‹å­—ç¬¦ä¸²
      collapse_spaces: æ˜¯å¦æŠŠç§»é™¤åçš„è¿ç»­ç©ºç™½æ”¶ç¼©ä¸ºå•ä¸ªç©ºæ ¼å¹¶å»é™¤é¦–å°¾ç©ºç™½ï¼ˆé»˜è®¤ Trueï¼‰
    """
    if not s:
        return s, 0

    # åŒ¹é… "å°äº‘" æˆ–è¿ç»­ä¸¤æ¬¡ "å°äº‘å°äº‘"ï¼Œä¼˜å…ˆåŒ¹é…ä¸¤æ¬¡ï¼ˆæ¨¡å¼æŒ‰æœ€é•¿ä¼˜å…ˆï¼‰
    pattern = re.compile(r'(?:å°äº‘){1,2}')
    cleaned, n = pattern.subn('', s)

    if collapse_spaces:
        # æ”¶ç¼©è¿ç»­ç©ºç™½ä¸ºå•ç©ºæ ¼å¹¶å»æ‰é¦–å°¾ç©ºç™½
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()

    return cleaned, n


# ---------------- å”¤é†’&è¯†åˆ« ----------------
async def asr_wake(audio_file: str, hotwords: Optional[List[str]] = SYMS, use_wake: bool = True, use_LLM: bool = True) -> str:
    """
    è¯­éŸ³è¯†åˆ«ä¸»æ¥å£ - æ¢å¤KWSå”¤é†’åŠŸèƒ½
    """
    asr_wake_start = time.perf_counter()
    # ä»é…ç½®è¯»å–å…¨å±€å¼ºåˆ¶å”¤é†’å¼€å…³
    from app.config import config
    voice_config = getattr(config, "voice_service", None)
    require_wake = voice_config.voice_require_wake if voice_config else False
    eff_use_wake = require_wake or use_wake
    logger.info("asr_wakeå¼€å§‹: audio_file=%s, use_wake=%s, VOICE_REQUIRE_WAKE=%s, eff_use_wake=%s", audio_file, use_wake, require_wake, eff_use_wake)
    
    try:
        # 1. KWSå”¤é†’æ£€æµ‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if use_wake:
            logger.info("KWSå”¤é†’æ£€æµ‹")
            kws_start = time.perf_counter()
            wake_result = kws_wakeup(audio_file)
            kws_time = (time.perf_counter() - kws_start) * 1000
            logger.info("KWSå”¤é†’ç»“æœ: %s", wake_result)
            logger.info("è€—æ—¶ç»Ÿè®¡ - KWSå”¤é†’æ£€æµ‹: %.2f ms", kws_time)
            if not wake_result:
                logger.info("å”¤é†’å¤±è´¥ï¼Œè¿”å›ç©ºç»“æœ")
                return ""
            logger.info("å”¤é†’æˆåŠŸï¼Œç»§ç»­ASRè¯†åˆ«")
        
        # 2. è¯­éŸ³è¯†åˆ«ï¼ˆå·²åºŸå¼ƒï¼šä½¿ç”¨è¯´è¯äººåˆ†ç¦»æ¨¡å‹ï¼‰
        # out = await recognize_voice_websocket(audio_file, hotwords)
        # logger.info("è¯†åˆ«ç»“æœ: %s", out)
        logger.warning("asr_wake å‡½æ•°ä¸­çš„ recognize_voice_websocket è°ƒç”¨å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨æ–°çš„è¯´è¯äººåˆ†ç¦»æ¨¡å‹")
        out = ""  # ä¸´æ—¶è¿”å›ç©ºï¼Œéœ€è¦é‡æ„æ­¤å‡½æ•°
        
        # 3. LLMä¿®æ­£ï¼ˆå¯é€‰ï¼‰
        if use_LLM and out:
            llm_start = time.perf_counter()
            _, out = process_speech_result(latest_options=hotwords, text=out)
            llm_time = (time.perf_counter() - llm_start) * 1000
            logger.info("LLMä¿®æ­£åçš„è¯†åˆ«ç»“æœ: %s", out)
            logger.info("è€—æ—¶ç»Ÿè®¡ - LLMä¿®æ­£: %.2f ms", llm_time)
        
        total_asr_wake_time = (time.perf_counter() - asr_wake_start) * 1000
        logger.info("è€—æ—¶ç»Ÿè®¡ - asr_wakeæ€»è€—æ—¶: %.2f ms", total_asr_wake_time)
        return out
        
    except Exception as e:
        total_asr_wake_time = (time.perf_counter() - asr_wake_start) * 1000
        logger.error("è¯†åˆ«å‡ºé”™: %s (è€—æ—¶: %.2f ms)", e, total_asr_wake_time, exc_info=True)
        return ""


# ========== æµå¼å¤„ç†ç›¸å…³ï¼ˆæ–°å¢ï¼Œä¸æ—§é€»è¾‘éš”ç¦»ï¼‰ ==========

# æµå¼å¤„ç†æ¨¡å‹é…ç½®
# ä½¿ç”¨æ³¨å†Œçš„æ¨¡å‹ID + model_path å‚æ•°æ¥æŒ‡å®šæœ¬åœ°æ¨¡å‹è·¯å¾„
# è¿™æ ·å¯ä»¥é¿å… "is not registered" é”™è¯¯ï¼ŒåŒæ—¶ä½¿ç”¨æœ¬åœ°å·²ä¸‹è½½çš„æ¨¡å‹
import os

# å®¹å™¨å†…æ¨¡å‹è·¯å¾„
_MODELS_BASE_DIR = "/workspace/models/damo"
# æœ¬åœ°å¼€å‘ç¯å¢ƒè·¯å¾„ï¼ˆfallbackï¼‰
_LOCAL_MODELS_BASE_DIR = os.path.join(os.path.dirname(__file__), "models", "damo")

def _get_model_path_and_id(local_dir_name: str, registered_model_id: str) -> Tuple[str, str]:
    """
    è·å–æ¨¡å‹è·¯å¾„å’Œæ³¨å†Œçš„æ¨¡å‹ID
    
    Args:
        local_dir_name: æœ¬åœ°ç›®å½•åç§°ï¼ˆåœ¨ damo ç›®å½•ä¸‹ï¼‰
        registered_model_id: æ³¨å†Œè¡¨ä¸­çš„æ¨¡å‹IDï¼ˆç”¨äº AutoModel çš„ model å‚æ•°ï¼‰
    
    Returns:
        (model_path, model_id): æ¨¡å‹è·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰å’Œæ³¨å†Œçš„æ¨¡å‹ID
    """
    # ä¼˜å…ˆå°è¯•å®¹å™¨å†…è·¯å¾„
    container_path = os.path.join(_MODELS_BASE_DIR, local_dir_name)
    if os.path.exists(container_path):
        logger.info("ä½¿ç”¨å®¹å™¨å†…æ¨¡å‹è·¯å¾„: %s (æ³¨å†ŒID: %s)", container_path, registered_model_id)
        return container_path, registered_model_id
    
    # å°è¯•æœ¬åœ°å¼€å‘ç¯å¢ƒè·¯å¾„
    local_path = os.path.join(_LOCAL_MODELS_BASE_DIR, local_dir_name)
    if os.path.exists(local_path):
        logger.info("ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„: %s (æ³¨å†ŒID: %s)", local_path, registered_model_id)
        return local_path, registered_model_id
    
    # å¦‚æœéƒ½ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¨¡å‹IDï¼ˆä¼šä»ModelScopeä¸‹è½½ï¼‰
    logger.warning("æœ¬åœ°æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨æ¨¡å‹IDï¼ˆå¯èƒ½ä»ModelScopeä¸‹è½½ï¼‰: %s", registered_model_id)
    return None, registered_model_id

# VADæ¨¡å‹ï¼šä½¿ç”¨æ³¨å†ŒID + æœ¬åœ°è·¯å¾„ï¼ˆpytorch ç‰ˆæœ¬ï¼‰
_vad_path, _vad_id = _get_model_path_and_id(
    "speech_fsmn_vad_zh-cn-16k-common-pytorch",
    "fsmn-vad"
)
STREAMING_VAD_MODEL = _vad_id
STREAMING_VAD_MODEL_PATH = _vad_path  # å¦‚æœä¸º Noneï¼Œåˆ™ä¸ä½¿ç”¨æœ¬åœ°è·¯å¾„

# ASRæ¨¡å‹ï¼šä½¿ç”¨æ³¨å†ŒID + æœ¬åœ°è·¯å¾„ï¼ˆpytorch æµå¼ç‰ˆæœ¬ï¼‰
_asr_path, _asr_id = _get_model_path_and_id(
    "speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online",
    "paraformer-zh-streaming"  # ä¿æŒåŸæ³¨å†ŒID
)
STREAMING_ASR_MODEL = _asr_id
STREAMING_ASR_MODEL_PATH = _asr_path  # å¦‚æœä¸º Noneï¼Œåˆ™ä¸ä½¿ç”¨æœ¬åœ°è·¯å¾„

# PUNCæ¨¡å‹ï¼šä½¿ç”¨æ³¨å†ŒID + æœ¬åœ°è·¯å¾„ï¼ˆpytorch ç‰ˆæœ¬ï¼‰
_punc_path, _punc_id = _get_model_path_and_id(
    "punc_ct-transformer_cn-en-common-vocab471067-large",
    "iic/punc_ct-transformer_cn-en-common-vocab471067-large"
)
STREAMING_PUNC_MODEL = _punc_id
STREAMING_PUNC_MODEL_PATH = _punc_path  # å¦‚æœä¸º Noneï¼Œåˆ™ä¸ä½¿ç”¨æœ¬åœ°è·¯å¾„

STREAMING_DEVICE = "cuda:0"  # GPUè®¾å¤‡

# æµå¼å¤„ç†å‚æ•°
STREAMING_TARGET_SAMPLE_RATE = 16000
STREAMING_FRONTEND_CHUNK_DURATION = 240  # å‰ç«¯å‘é€ç‰‡æ®µæ—¶é•¿ï¼ˆmsï¼‰
STREAMING_SILENCE_THRESHOLD = 2.0  # é™é»˜2ç§’è§¦å‘ç»“æŸ
STREAMING_TAIL_PROTECTION_DURATION = 0.5  # å°¾éŸ³ä¿æŠ¤æ—¶é•¿ï¼ˆç§’ï¼‰ï¼šæ£€æµ‹åˆ°é™éŸ³åï¼Œå¦‚æœä¹‹å‰æœ‰è¯­éŸ³ï¼Œç»§ç»­ç´¯ç§¯0.5ç§’éŸ³é¢‘
STREAMING_CHUNK_SIZE = [0, 4, 5]  # ASR chunké…ç½®
STREAMING_ENCODER_CHUNK_LOOK_BACK = 4
STREAMING_DECODER_CHUNK_LOOK_BACK = 1

# VAD èƒ½é‡æ£€æµ‹é˜ˆå€¼ï¼ˆæé«˜é˜ˆå€¼ä»¥æ’é™¤æ›´å¤šå™ªå£°ï¼‰
STREAMING_VAD_ENERGY_THRESHOLD = 0.03  # ä»0.03æé«˜åˆ°0.05
STREAMING_VAD_MAX_THRESHOLD = 0.17     # ä»0.15æé«˜åˆ°0.20
STREAMING_VAD_USE_AND_LOGIC = True

# å…¨å±€æ¨¡å‹å®ä¾‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
_streaming_vad_model = None
_streaming_asr_model = None
_streaming_punc_model = None
_streaming_models_initialized = False

# è¯´è¯äººåˆ†ç¦»æ¨¡å‹ï¼ˆå…¨å±€å•ä¾‹ï¼‰
_speaker_diarization_pipeline = None
_speaker_diarization_initialized = False


def _load_model_with_local_path(model_id: str, model_path: Optional[str], device: str) -> AutoModel:
    """
    åŠ è½½æ¨¡å‹ï¼Œä¼˜å…ˆä½¿ç”¨æœ¬åœ°è·¯å¾„
    
    Args:
        model_id: æ³¨å†Œè¡¨ä¸­çš„æ¨¡å‹IDï¼ˆfallbackï¼Œå½“æœ¬åœ°è·¯å¾„ä¸å­˜åœ¨æ—¶ä½¿ç”¨ï¼‰
        model_path: æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        device: è®¾å¤‡ï¼ˆcuda:0 æˆ– cpuï¼‰
    
    Returns:
        AutoModel å®ä¾‹
    """
    if model_path and os.path.exists(model_path):
        # æœ¬åœ°è·¯å¾„å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨è·¯å¾„ä½œä¸º model å‚æ•°ï¼ˆå‚è€ƒ KWS æ¨¡å‹çš„åŠ è½½æ–¹å¼ï¼‰
        logger.info("âœ… ä½¿ç”¨æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹: %s", model_path)
        return AutoModel(
            model=model_path,  # ç›´æ¥ä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼ŒFunASR ä¼šè‡ªåŠ¨è¯»å– config.yaml
            device=device,
            disable_update=True,
            disable_pbar=True
        )
    else:
        # æœ¬åœ°è·¯å¾„ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ³¨å†ŒIDï¼ˆä¼šä» ModelScope ä¸‹è½½æˆ–ä½¿ç”¨ç¼“å­˜ï¼‰
        logger.warning("âš ï¸ æœ¬åœ°æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ³¨å†ŒIDåŠ è½½ï¼ˆå¯èƒ½ä» ModelScope ä¸‹è½½æˆ–ä½¿ç”¨ç¼“å­˜ï¼‰: %s", model_id)
        return AutoModel(
            model=model_id,
            device=device,
            disable_update=True,
            disable_pbar=True
        )


def init_streaming_models():
    """åˆå§‹åŒ–æµå¼å¤„ç†æ¨¡å‹ï¼ˆå¯åŠ¨æ—¶è°ƒç”¨ä¸€æ¬¡ï¼Œå»¶è¿ŸåŠ è½½ï¼‰
    
    ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆ/workspace/models/damo/...ï¼‰ï¼Œé¿å…é‡å¤ä¸‹è½½ã€‚
    å¦‚æœæœ¬åœ°è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨æ¨¡å‹IDï¼ˆä¼šä» ModelScope ä¸‹è½½æˆ–ä½¿ç”¨ç¼“å­˜ï¼‰ã€‚
    """
    global _streaming_vad_model, _streaming_asr_model, _streaming_punc_model, _streaming_models_initialized
    
    if _streaming_models_initialized:
        logger.info("æµå¼å¤„ç†æ¨¡å‹å·²åˆå§‹åŒ–ï¼Œè·³è¿‡é‡å¤åŠ è½½")
        return
    
    try:
        logger.info("æ­£åœ¨åŠ è½½æµå¼å¤„ç†æ¨¡å‹...")
        logger.info("VADæ¨¡å‹ID: %s, æœ¬åœ°è·¯å¾„: %s", STREAMING_VAD_MODEL, STREAMING_VAD_MODEL_PATH)
        logger.info("ASRæ¨¡å‹ID: %s, æœ¬åœ°è·¯å¾„: %s", STREAMING_ASR_MODEL, STREAMING_ASR_MODEL_PATH)
        logger.info("PUNCæ¨¡å‹ID: %s, æœ¬åœ°è·¯å¾„: %s", STREAMING_PUNC_MODEL, STREAMING_PUNC_MODEL_PATH)
        logger.info("è®¾å¤‡: %s", STREAMING_DEVICE)
        
        # ä½¿ç”¨ _load_model_with_local_path ä¼˜å…ˆä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼Œé¿å…é‡å¤ä¸‹è½½
        _streaming_vad_model = _load_model_with_local_path(
            model_id=STREAMING_VAD_MODEL,
            model_path=STREAMING_VAD_MODEL_PATH,
            device=STREAMING_DEVICE
        )
        logger.info("âœ… VADæ¨¡å‹åŠ è½½å®Œæˆ")
        
        _streaming_asr_model = _load_model_with_local_path(
            model_id=STREAMING_ASR_MODEL,
            model_path=STREAMING_ASR_MODEL_PATH,
            device=STREAMING_DEVICE
        )
        logger.info("âœ… ASRæ¨¡å‹åŠ è½½å®Œæˆ")
        
        _streaming_punc_model = _load_model_with_local_path(
            model_id=STREAMING_PUNC_MODEL,
            model_path=STREAMING_PUNC_MODEL_PATH,
            device=STREAMING_DEVICE
        )
        logger.info("âœ… PUNCæ¨¡å‹åŠ è½½å®Œæˆ")
        
        _streaming_models_initialized = True
        logger.info("âœ… æ‰€æœ‰æµå¼å¤„ç†æ¨¡å‹åŠ è½½å®Œæˆ")
        
    except Exception as e:
        logger.error("âŒ æµå¼å¤„ç†æ¨¡å‹åŠ è½½å¤±è´¥: %s", e, exc_info=True)
        raise


def get_streaming_models():
    """è·å–æµå¼å¤„ç†æ¨¡å‹å®ä¾‹ï¼ˆå¦‚æœæœªåˆå§‹åŒ–åˆ™å…ˆåˆå§‹åŒ–ï¼‰"""
    if not _streaming_models_initialized:
        init_streaming_models()
    return _streaming_vad_model, _streaming_asr_model, _streaming_punc_model


def _init_speaker_diarization_pipeline_global():
    """åˆå§‹åŒ–è¯´è¯äººåˆ†ç¦»æ¨¡å‹ï¼ˆå…¨å±€å•ä¾‹ï¼Œä¼˜å…ˆä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼‰"""
    global _speaker_diarization_pipeline, _speaker_diarization_initialized
    
    if _speaker_diarization_initialized:
        logger.debug("è¯´è¯äººåˆ†ç¦»æ¨¡å‹å·²åˆå§‹åŒ–ï¼Œè·³è¿‡é‡å¤åŠ è½½")
        return _speaker_diarization_pipeline
    
    try:
        from modelscope.pipelines import pipeline
        from modelscope.utils.constant import Tasks
        
        logger.info("æ­£åœ¨åˆå§‹åŒ–è¯´è¯äººåˆ†ç¦»æ¨¡å‹...")
        
        # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼Œé¿å…ä»ModelScopeä¸‹è½½
        # å®¹å™¨å†…è·¯å¾„ï¼š/workspace/models/damo/speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn
        # æœ¬åœ°å¼€å‘è·¯å¾„ï¼šapp/services/models/damo/speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn
        diarization_model_id = 'iic/speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn'
        diarization_model_revision = 'v2.0.4'
        
        # å°è¯•å®¹å™¨å†…è·¯å¾„
        container_path = "/workspace/models/damo/speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn"
        # å°è¯•æœ¬åœ°å¼€å‘è·¯å¾„
        current_dir = os.path.dirname(os.path.abspath(__file__))
        local_path = os.path.join(current_dir, "models", "damo", "speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn")
        
        diarization_model_path = None
        if os.path.exists(container_path):
            diarization_model_path = container_path
            logger.info("âœ… ä½¿ç”¨å®¹å™¨å†…è¯´è¯äººåˆ†ç¦»æ¨¡å‹è·¯å¾„: %s", container_path)
        elif os.path.exists(local_path):
            diarization_model_path = local_path
            logger.info("âœ… ä½¿ç”¨æœ¬åœ°è¯´è¯äººåˆ†ç¦»æ¨¡å‹è·¯å¾„: %s", local_path)
        else:
            logger.warning("âš ï¸ æœ¬åœ°è¯´è¯äººåˆ†ç¦»æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨æ¨¡å‹IDï¼ˆå¯èƒ½ä»ModelScopeä¸‹è½½ï¼‰: %s", diarization_model_id)
        
        # VAD æ¨¡å‹è·¯å¾„ï¼ˆå¤ç”¨å·²æœ‰çš„é€»è¾‘ï¼‰
        vad_model_id = 'iic/speech_fsmn_vad_zh-cn-16k-common-pytorch'
        vad_model_revision = "v2.0.4"
        vad_container_path = "/workspace/models/damo/speech_fsmn_vad_zh-cn-16k-common-pytorch"
        vad_local_path = os.path.join(current_dir, "models", "damo", "speech_fsmn_vad_zh-cn-16k-common-pytorch")
        
        vad_model_path = None
        if os.path.exists(vad_container_path):
            vad_model_path = vad_container_path
            logger.info("âœ… ä½¿ç”¨å®¹å™¨å†…VADæ¨¡å‹è·¯å¾„: %s", vad_container_path)
        elif os.path.exists(vad_local_path):
            vad_model_path = vad_local_path
            logger.info("âœ… ä½¿ç”¨æœ¬åœ°VADæ¨¡å‹è·¯å¾„: %s", vad_local_path)
        else:
            logger.warning("âš ï¸ æœ¬åœ°VADæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨æ¨¡å‹ID: %s", vad_model_id)
        
        # PUNC æ¨¡å‹è·¯å¾„ï¼ˆå¤ç”¨å·²æœ‰çš„é€»è¾‘ï¼‰
        punc_model_id = 'iic/punc_ct-transformer_cn-en-common-vocab471067-large'
        punc_model_revision = "v2.0.4"
        punc_container_path = "/workspace/models/damo/punc_ct-transformer_cn-en-common-vocab471067-large"
        punc_local_path = os.path.join(current_dir, "models", "damo", "punc_ct-transformer_cn-en-common-vocab471067-large")
        
        punc_model_path = None
        if os.path.exists(punc_container_path):
            punc_model_path = punc_container_path
            logger.info("âœ… ä½¿ç”¨å®¹å™¨å†…PUNCæ¨¡å‹è·¯å¾„: %s", punc_container_path)
        elif os.path.exists(punc_local_path):
            punc_model_path = punc_local_path
            logger.info("âœ… ä½¿ç”¨æœ¬åœ°PUNCæ¨¡å‹è·¯å¾„: %s", punc_local_path)
        else:
            logger.warning("âš ï¸ æœ¬åœ°PUNCæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨æ¨¡å‹ID: %s", punc_model_id)
        
        # ModelScope pipeline æ”¯æŒç›´æ¥ä¼ é€’æœ¬åœ°è·¯å¾„ä½œä¸º model å‚æ•°
        model_param = diarization_model_path if diarization_model_path else diarization_model_id
        vad_model_param = vad_model_path if vad_model_path else vad_model_id
        punc_model_param = punc_model_path if punc_model_path else punc_model_id
        
        _speaker_diarization_pipeline = pipeline(
            task=Tasks.auto_speech_recognition,
            model=model_param,
            model_revision=diarization_model_revision if not diarization_model_path else None,  # æœ¬åœ°è·¯å¾„ä¸éœ€è¦revision
            vad_model=vad_model_param,
            vad_model_revision=vad_model_revision if not vad_model_path else None,  # æœ¬åœ°è·¯å¾„ä¸éœ€è¦revision
            punc_model=punc_model_param,
            punc_model_revision=punc_model_revision if not punc_model_path else None,  # æœ¬åœ°è·¯å¾„ä¸éœ€è¦revision
            output_dir="./results",
        )
        _speaker_diarization_initialized = True
        logger.info("âœ… è¯´è¯äººåˆ†ç¦»æ¨¡å‹å·²åŠ è½½ (model=%s, vad_model=%s, punc_model=%s)", 
                   model_param, vad_model_param, punc_model_param)
        return _speaker_diarization_pipeline
    except Exception as e:
        logger.error(f"âŒ è¯´è¯äººåˆ†ç¦»æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}", exc_info=True)
        raise


def get_speaker_diarization_pipeline():
    """è·å–è¯´è¯äººåˆ†ç¦»æ¨¡å‹å®ä¾‹ï¼ˆå¦‚æœæœªåˆå§‹åŒ–åˆ™å…ˆåˆå§‹åŒ–ï¼‰"""
    if not _speaker_diarization_initialized:
        _init_speaker_diarization_pipeline_global()
    return _speaker_diarization_pipeline


def init_speaker_diarization_model():
    """åˆå§‹åŒ–è¯´è¯äººåˆ†ç¦»æ¨¡å‹ï¼ˆå¯åŠ¨æ—¶è°ƒç”¨ä¸€æ¬¡ï¼Œå»¶è¿ŸåŠ è½½ï¼‰
    
    ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆ/workspace/models/damo/...ï¼‰ï¼Œé¿å…é‡å¤ä¸‹è½½ã€‚
    å¦‚æœæœ¬åœ°è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨æ¨¡å‹IDï¼ˆä¼šä» ModelScope ä¸‹è½½æˆ–ä½¿ç”¨ç¼“å­˜ï¼‰ã€‚
    """
    try:
        logger.info("æ­£åœ¨é¢„åŠ è½½è¯´è¯äººåˆ†ç¦»æ¨¡å‹...")
        _init_speaker_diarization_pipeline_global()
        logger.info("âœ… è¯´è¯äººåˆ†ç¦»æ¨¡å‹é¢„åŠ è½½å®Œæˆ")
    except Exception as e:
        logger.error("âŒ è¯´è¯äººåˆ†ç¦»æ¨¡å‹é¢„åŠ è½½å¤±è´¥: %s", e, exc_info=True)
        logger.warning("âš ï¸ æœåŠ¡å°†ç»§ç»­å¯åŠ¨ï¼Œä½†é¦–æ¬¡ä½¿ç”¨æ—¶å¯èƒ½éœ€è¦ç­‰å¾…æ¨¡å‹åŠ è½½")


def _log_audio_statistics(audio_np: np.ndarray, sample_rate: int, context: str = ""):
    """
    æ‰“å°éŸ³é¢‘ç»Ÿè®¡ä¿¡æ¯ï¼Œç”¨äºè¯Šæ–­åŠ¨æ€èŒƒå›´å’Œé¥±å’Œé—®é¢˜
    
    Args:
        audio_np: éŸ³é¢‘æ•°ç»„ï¼ˆfloat32ï¼ŒèŒƒå›´é€šå¸¸ä¸º [-1, 1]ï¼‰
        sample_rate: é‡‡æ ·ç‡
        context: ä¸Šä¸‹æ–‡æè¿°ï¼ˆä¾‹å¦‚ï¼š"base64è§£ç å"ã€"æ¨¡å‹è¾“å…¥å‰"ï¼‰
    """
    if len(audio_np) == 0:
        logger.warning(f"[éŸ³é¢‘ç»Ÿè®¡{context}] éŸ³é¢‘æ•°ç»„ä¸ºç©º")
        return
    
    # åŸºæœ¬å±æ€§
    dtype = audio_np.dtype
    shape = audio_np.shape
    duration_s = len(audio_np) / sample_rate if sample_rate > 0 else 0.0
    
    # ç»Ÿè®¡å€¼
    audio_max = float(np.max(audio_np))
    audio_min = float(np.min(audio_np))
    audio_abs_max = float(np.max(np.abs(audio_np)))
    
    # RMSï¼ˆå‡æ–¹æ ¹ï¼‰
    rms = float(np.sqrt(np.mean(audio_np ** 2)) + 1e-10)
    
    # Clipping ratioï¼š|x| >= 0.999 çš„æ¯”ä¾‹ï¼ˆæ¥è¿‘é¥±å’Œçš„æ¯”ä¾‹ï¼‰
    clipping_mask = np.abs(audio_np) >= 0.999
    clipping_ratio = float(np.sum(clipping_mask) / len(audio_np))
    
    # Dynamic rangeï¼šmax / (rms + 1e-10)
    dynamic_range = audio_abs_max / (rms + 1e-10) if rms > 0 else 0.0
    
    # æ­£è´Ÿå³°å€¼å¯¹ç§°æ€§ï¼ˆæ­£å³°å€¼ - |è´Ÿå³°å€¼|ï¼‰
    peak_symmetry = audio_max - abs(audio_min)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    logger.info(
        f"ğŸ“Š [éŸ³é¢‘ç»Ÿè®¡{context}] "
        f"dtype={dtype}, shape={shape}, sample_rate={sample_rate}Hz, "
        f"duration={duration_s:.3f}s, "
        f"max={audio_max:.6f}, min={audio_min:.6f}, "
        f"RMS={rms:.6f}, "
        f"clipping_ratio={clipping_ratio:.2%} (|x|>=0.999), "
        f"dynamic_range={dynamic_range:.2f}, "
        f"peak_symmetry={peak_symmetry:.6f} (max-|min|)"
    )
    
    # å¦‚æœ clipping æ¯”ä¾‹è¾ƒé«˜ï¼Œè®°å½•è­¦å‘Š
    if clipping_ratio > 0.01:  # 1%
        logger.warning(
            f"âš ï¸ [éŸ³é¢‘ç»Ÿè®¡{context}] æ£€æµ‹åˆ°é«˜clippingæ¯”ä¾‹: {clipping_ratio:.2%} "
            f"(max={audio_max:.6f}, abs_max={audio_abs_max:.6f})"
        )
    
    return {
        "dtype": dtype,
        "shape": shape,
        "sample_rate": sample_rate,
        "duration_s": duration_s,
        "max": audio_max,
        "min": audio_min,
        "rms": rms,
        "clipping_ratio": clipping_ratio,
        "dynamic_range": dynamic_range,
        "peak_symmetry": peak_symmetry
    }


def _dump_clipped_audio(audio_np: np.ndarray, sample_rate: int, context: str = ""):
    """
    å½“æ£€æµ‹åˆ°é«˜clippingæ¯”ä¾‹æ—¶ï¼ŒdumpéŸ³é¢‘ä¸ºWAVæ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
    
    Args:
        audio_np: éŸ³é¢‘æ•°ç»„ï¼ˆfloat32ï¼ŒèŒƒå›´ [-1, 1]ï¼‰
        sample_rate: é‡‡æ ·ç‡
        context: ä¸Šä¸‹æ–‡æè¿°
    """
    try:
        import datetime
        from pathlib import Path
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = Path("/tmp") / "voice_service_debug_audio"
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
        filename = f"clipped_audio_{context}_{timestamp}.wav"
        wav_path = temp_dir / filename
        
        # è½¬æ¢ä¸ºint16å¹¶ä¿å­˜ï¼ˆåªåšå¿…è¦çš„clampï¼Œä¸åšå½’ä¸€åŒ–ï¼‰
        # ç¡®ä¿åœ¨ [-1, 1] èŒƒå›´å†…ï¼Œç„¶åè½¬æ¢ä¸º [-32768, 32767]
        audio_clamped = np.clip(audio_np, -1.0, 1.0)
        audio_int16 = (audio_clamped * 32767.0).astype(np.int16)
        
        # ä¿å­˜WAVæ–‡ä»¶
        with wave.open(str(wav_path), 'wb') as wav_file:
            wav_file.setnchannels(1)  # å•å£°é“
            wav_file.setsampwidth(2)  # 16-bit (2 bytes)
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(audio_int16.tobytes())
        
        logger.info(f"ğŸ’¾ [éŸ³é¢‘dump{context}] å·²ä¿å­˜clippingéŸ³é¢‘åˆ°: {wav_path}")
        return str(wav_path)
    except Exception as e:
        logger.error(f"âŒ [éŸ³é¢‘dump{context}] ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
        return None


def base64_to_audio_np(base64_str: str) -> Tuple[np.ndarray, int]:
    """
    è¾“å…¥ï¼šå‰ç«¯ä¼ æ¥çš„ WAV base64 å­—ç¬¦ä¸²ï¼ˆå‰ç«¯å·²è½¬æ¢ä¸ºWAVæ ¼å¼ï¼‰
    è¾“å‡ºï¼š(æ¨¡å‹å¯è¯†åˆ«çš„ float32 éŸ³é¢‘æ•°ç»„, 16kHzé‡‡æ ·ç‡)
    ä¼˜å…ˆä½¿ç”¨ wave æ¨¡å—ï¼ˆæ— éœ€å¤–éƒ¨ä¾èµ–ï¼‰ï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯• torchaudio
    """
    try:
        # æ­¥éª¤1ï¼šbase64 è§£ç  â†’ äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®
        audio_bytes = base64.b64decode(base64_str.strip())
        if not audio_bytes:
            raise ValueError("base64 è§£ç åä¸ºç©º")

        # æ­¥éª¤2ï¼šä¼˜å…ˆå°è¯•ä½¿ç”¨ wave æ¨¡å—è§£æ WAVï¼ˆæ— éœ€å¤–éƒ¨ä¾èµ–ï¼‰
        try:
            with wave.open(BytesIO(audio_bytes), "rb") as wf:
                orig_sr = wf.getframerate()
                orig_ch = wf.getnchannels()
                orig_sw = wf.getsampwidth()
                n_frames = wf.getnframes()
                wav_data = wf.readframes(n_frames)

            # æ­¥éª¤3ï¼šäºŒè¿›åˆ¶ â†’ numpy æ•°ç»„ï¼ˆæŒ‰ä½æ·±å½’ä¸€åŒ–åˆ° [-1, 1]ï¼‰
            if orig_sw == 1:
                audio_np = np.frombuffer(wav_data, dtype=np.uint8)
                audio_np = (audio_np - 128) / 128.0
            elif orig_sw == 2:
                audio_np = np.frombuffer(wav_data, dtype=np.int16)
                audio_np = audio_np / 32768.0
            elif orig_sw == 4:
                audio_np = np.frombuffer(wav_data, dtype=np.int32)
                audio_np = audio_np / 2147483648.0
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ä½æ·±ï¼š{orig_sw} å­—èŠ‚")

            # æ­¥éª¤4ï¼šå¤šé€šé“ â†’ å•é€šé“
            if orig_ch > 1:
                audio_np = np.mean(audio_np.reshape(-1, orig_ch), axis=1)

            # æ­¥éª¤5ï¼šé‡é‡‡æ · â†’ 16kHzï¼ˆå¦‚æœéœ€è¦ï¼‰
            if orig_sr != STREAMING_TARGET_SAMPLE_RATE:
                # ä½¿ç”¨ scipy.signal.resample è¿›è¡Œé‡é‡‡æ ·ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                try:
                    from scipy import signal
                    num_samples = int(len(audio_np) * STREAMING_TARGET_SAMPLE_RATE / orig_sr)
                    audio_np = signal.resample(audio_np, num_samples)
                except ImportError:
                    # å¦‚æœæ²¡æœ‰ scipyï¼Œä½¿ç”¨ç®€å•çš„çº¿æ€§æ’å€¼ï¼ˆnumpyå®ç°ï¼‰
                    old_length = len(audio_np)
                    new_length = int(old_length * STREAMING_TARGET_SAMPLE_RATE / orig_sr)
                    old_indices = np.linspace(0, old_length - 1, old_length)
                    new_indices = np.linspace(0, old_length - 1, new_length)
                    audio_np = np.interp(new_indices, old_indices, audio_np)
                except Exception as resample_error:
                    # å¦‚æœé‡é‡‡æ ·å¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨åŸé‡‡æ ·ç‡ï¼ˆæ¨¡å‹å¯èƒ½ä¹Ÿèƒ½å¤„ç†ï¼‰
                    logger.warning("æ— æ³•é‡é‡‡æ ·ï¼Œä½¿ç”¨åŸå§‹é‡‡æ ·ç‡ %sHz: %s", orig_sr, resample_error)
                    audio_np = audio_np.astype(np.float32)
                    # åœ¨è¿”å›å‰æ·»åŠ ç»Ÿè®¡æ—¥å¿—
                    stats = _log_audio_statistics(audio_np, orig_sr, "base64è§£ç å")
                    if stats and stats.get("clipping_ratio", 0) > 0.01:
                        _dump_clipped_audio(audio_np, orig_sr, "base64_decode")
                    return audio_np, orig_sr

            # æ­¥éª¤6ï¼šç¡®ä¿æ•°æ®ç±»å‹
            audio_np = audio_np.astype(np.float32)
            # åœ¨è¿”å›å‰æ·»åŠ ç»Ÿè®¡æ—¥å¿—
            stats = _log_audio_statistics(audio_np, STREAMING_TARGET_SAMPLE_RATE, "base64è§£ç å")
            if stats and stats.get("clipping_ratio", 0) > 0.01:
                _dump_clipped_audio(audio_np, STREAMING_TARGET_SAMPLE_RATE, "base64_decode")
            return audio_np, STREAMING_TARGET_SAMPLE_RATE

        except Exception as wave_error:
            # å¦‚æœ wave æ¨¡å—è§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ torchaudioï¼ˆéœ€è¦ torchaudio åº“ï¼‰
            logger.warning("wave æ¨¡å—è§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ torchaudio: %s", wave_error)
            try:
                import torch
                import torchaudio
                audio_stream = BytesIO(audio_bytes)
                waveform, sample_rate = torchaudio.load(
                    audio_stream,
                    format=None,  # è‡ªåŠ¨è¯†åˆ«æ ¼å¼
                    backend="soundfile"  # ç”¨ soundfile åç«¯
                )
                
                # è½¬å•é€šé“
                if waveform.shape[0] > 1:
                    waveform = torch.mean(waveform, dim=0, keepdim=True)
                
                # é‡é‡‡æ ·
                if sample_rate != STREAMING_TARGET_SAMPLE_RATE:
                    resampler = torchaudio.transforms.Resample(
                        orig_freq=sample_rate,
                        new_freq=STREAMING_TARGET_SAMPLE_RATE,
                        dtype=waveform.dtype
                    )
                    waveform = resampler(waveform)
                    sample_rate = STREAMING_TARGET_SAMPLE_RATE
                
                audio_np = waveform.squeeze().numpy().astype(np.float32)
                # åœ¨è¿”å›å‰æ·»åŠ ç»Ÿè®¡æ—¥å¿—
                stats = _log_audio_statistics(audio_np, STREAMING_TARGET_SAMPLE_RATE, "base64è§£ç å(torchaudio)")
                if stats and stats.get("clipping_ratio", 0) > 0.01:
                    _dump_clipped_audio(audio_np, STREAMING_TARGET_SAMPLE_RATE, "base64_decode_torchaudio")
                return audio_np, STREAMING_TARGET_SAMPLE_RATE
            except Exception as torch_error:
                raise RuntimeError(
                    f"éŸ³é¢‘å¤„ç†å¤±è´¥ï¼šwaveæ¨¡å—é”™è¯¯={wave_error}, torchaudioé”™è¯¯={torch_error}ã€‚"
                    f"è¯·ç¡®ä¿å‰ç«¯å‘é€æ ‡å‡†WAVæ ¼å¼ï¼ˆ16kHzå•å£°é“16bitï¼‰ï¼Œæˆ–å®‰è£…scipy/torchaudioã€‚"
                )

    except Exception as e:
        raise RuntimeError(f"éŸ³é¢‘å¤„ç†å¤±è´¥ï¼š{str(e)}")


class StreamingASRSession:
    """æµå¼ASRä¼šè¯çŠ¶æ€ç®¡ç†ï¼ˆæ¯ä¸ªWebSocketè¿æ¥ä¸€ä¸ªå®ä¾‹ï¼‰"""
    
    def __init__(self):
        # ASR ç›¸å…³çŠ¶æ€
        self.vad_cache = {}
        self.asr_cache = {}
        self.audio_buffer = np.array([], dtype=np.float32)
        self.accumulated_intermediate_text = ""
        self.silence_timer = 0.0
        self.last_voice_time = time.time()
        self.is_completed = False
        self.has_detected_speech = False  # æ ‡è®°æ˜¯å¦æ›¾ç»æ£€æµ‹åˆ°è¿‡è¯­éŸ³ï¼ˆç”¨äºé˜²æ­¢çº¯é™éŸ³è§¦å‘finalizeï¼‰
        self.silence_chunk_count = 0  # å·²ç´¯ç§¯çš„é™éŸ³chunkæ•°é‡ï¼ˆæœ€å¤šä¿ç•™2ä¸ªé™éŸ³chunkï¼‰
        
        # å°¾éŸ³ä¿æŠ¤æœºåˆ¶ç›¸å…³çŠ¶æ€
        self.tail_protection_start_time = None  # å°¾éŸ³ä¿æŠ¤æœŸå¼€å§‹æ—¶é—´ï¼ˆNoneè¡¨ç¤ºæœªè¿›å…¥ä¿æŠ¤æœŸï¼‰
        
        # å‰å‘ä¿æŠ¤æœºåˆ¶ç›¸å…³çŠ¶æ€ï¼ˆé˜²æ­¢ä¸¢å¤±è¯­éŸ³å¼€å¤´ï¼‰
        self.pre_speech_buffer = np.array([], dtype=np.float32)  # å‰å‘ä¿æŠ¤ç¼“å†²åŒºï¼ˆç´¯ç§¯æ£€æµ‹åˆ°è¯­éŸ³ä¹‹å‰çš„chunkï¼‰
        self.pre_speech_max_duration = 0.4  # å‰å‘ä¿æŠ¤æœ€å¤§æ—¶é•¿ï¼ˆ400msï¼Œä¿ç•™1ä¸ªchunkï¼‰
        
        # KWS å”¤é†’ç›¸å…³çŠ¶æ€
        self.mode = "WAITING_FOR_WAKEUP"  # "WAITING_FOR_WAKEUP" æˆ– "WAITING_FOR_ENROLLMENT" æˆ– "WAITING_FOR_ENROLLMENT_CONFIRM" æˆ– "ASR_ACTIVE"
        self.kws_cache = {}  # KWS æ¨¡å‹çš„ cacheï¼ˆç”¨äºæµå¼æ£€æµ‹ï¼‰
        self.kws_vad_cache = {}  # KWS æ¨¡å¼ä¸‹ VAD çš„ cacheï¼ˆä¸ ASR æ¨¡å¼çš„ VAD cache åˆ†å¼€ï¼‰
        self.use_wake = True  # æ˜¯å¦å¯ç”¨å”¤é†’æ¨¡å¼ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        self.is_activated = False  # æ˜¯å¦å·²é€šè¿‡ KWS æ¿€æ´»ï¼ˆç”¨äºæ§åˆ¶æ˜¯å¦å‘é€ ASR ç»“æœï¼‰
        # KWS éŸ³é¢‘ç´¯ç§¯ç›¸å…³ï¼ˆæ»‘åŠ¨çª—å£ï¼Œå›ºå®š1600ms = 4ä¸ª400ms chunkï¼‰
        self.kws_audio_buffer = np.array([], dtype=np.float32)  # KWS éŸ³é¢‘ç´¯ç§¯ç¼“å†²åŒºï¼ˆæ»‘åŠ¨çª—å£ï¼‰
        self.kws_min_duration = 1.6  # KWS æ£€æµ‹æ‰€éœ€çš„æœ€å°éŸ³é¢‘é•¿åº¦ï¼ˆç§’ï¼‰ï¼Œ1600ms = 4ä¸ª400ms chunk
        
        # çƒ­è¯é…ç½®ï¼ˆä½¿ç”¨ SYMS ä½œä¸ºé»˜è®¤çƒ­è¯åˆ—è¡¨ï¼Œä¸ asr_wake ä¿æŒä¸€è‡´ï¼‰
        self.hotwords: Optional[List[str]] = SYMS  # ä¼šè¯çº§åˆ«çš„çƒ­è¯åˆ—è¡¨
        
        # SV å£°çº¹è¯†åˆ«ç›¸å…³çŠ¶æ€
        self.sv_pipeline = None  # å£°çº¹è¯†åˆ«ç®¡é“ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
        # è¯´è¯äººåˆ†ç¦»æ¨¡å‹ä½¿ç”¨å…¨å±€å•ä¾‹ï¼Œä¸éœ€è¦å®ä¾‹å˜é‡
        self.enroll_audio_path: Optional[str] = None  # æ³¨å†Œæ ·æœ¬æ–‡ä»¶è·¯å¾„
        self.enroll_audio_buffer = np.array([], dtype=np.float32)  # æ³¨å†ŒéŸ³é¢‘ç¼“å†²åŒº
        self.is_enrolled = False  # æ˜¯å¦å·²æ³¨å†Œ
        self.min_enroll_seconds = 5.0  # æ³¨å†Œè¦æ±‚çš„æœ€çŸ­æ—¶é•¿ï¼ˆ5ç§’ï¼‰
        self.enroll_has_detected_speech = False  # æ ‡è®°æ˜¯å¦åœ¨enrollmentæ¨¡å¼ä¸‹æ£€æµ‹åˆ°è¿‡è¯­éŸ³ï¼ˆç”¨äºæ§åˆ¶ä½•æ—¶å¼€å§‹ç´¯ç§¯ï¼‰
        self.enroll_first_speech_time = None  # ç¬¬ä¸€æ¬¡æ£€æµ‹åˆ°è¯­éŸ³çš„æ—¶é—´ï¼ˆç”¨äºè®¡ç®—ä»è¯­éŸ³å¼€å§‹ç´¯ç§¯çš„æ—¶é•¿ï¼‰
        self.sv_threshold = 0.40  # å£°çº¹åˆ¤å®šé˜ˆå€¼ï¼ˆå¯è°ƒæ•´ï¼šå€¼è¶Šå°è¶Šå®½æ¾ï¼Œå€¼è¶Šå¤§è¶Šä¸¥æ ¼ï¼‰
        self.use_speaker_verification = True  # æ˜¯å¦å¯ç”¨å£°çº¹éªŒè¯ï¼ˆé»˜è®¤å¯ç”¨ï¼Œç”¨äºæµ‹è¯•ï¼‰
        
        # å®éªŒæ€§ï¼šchunkçº§åˆ«çš„å£°çº¹éªŒè¯ç¼“å†²åŒºï¼ˆç”¨äºå®æ—¶éªŒè¯å®éªŒï¼‰
        self.experimental_sv_buffer = np.array([], dtype=np.float32)  # å®éªŒæ€§éªŒè¯ç¼“å†²åŒºï¼ˆå½“å‰chunkï¼‰
        self.experimental_sv_accumulated_buffer = np.array([], dtype=np.float32)  # ç´¯ç§¯éªŒè¯ç¼“å†²åŒºï¼ˆ1+2+3+...ï¼‰
        self.experimental_sv_min_duration = 1.0  # å®éªŒæ€§éªŒè¯æ‰€éœ€çš„æœ€å°éŸ³é¢‘é•¿åº¦ï¼ˆç§’ï¼‰ï¼Œç´¯ç§¯åˆ°è¿™ä¹ˆé•¿æ‰éªŒè¯
        self.experimental_sv_last_verify_time = 0.0  # ä¸Šæ¬¡éªŒè¯çš„æ—¶é—´æˆ³ï¼ˆç”¨äºæ§åˆ¶éªŒè¯é¢‘ç‡ï¼‰
        self.experimental_sv_verify_interval = 0.4  # éªŒè¯é—´éš”ï¼ˆç§’ï¼‰ï¼Œé¿å…è¿‡äºé¢‘ç¹éªŒè¯
        
    def reset(self):
        """é‡ç½®ä¼šè¯çŠ¶æ€ï¼ˆå‡†å¤‡ä¸‹ä¸€è½®è¯†åˆ«ï¼‰
        
        æ³¨æ„ï¼šæ ¹æ® use_wake å†³å®šé‡ç½®åçš„æ¨¡å¼ï¼š
        - use_wake=True: é‡ç½®åˆ°ç­‰å¾…å”¤é†’æ¨¡å¼
        - use_wake=False: é‡ç½®åˆ° ASR æ¿€æ´»æ¨¡å¼ï¼ˆä¸éœ€è¦å”¤é†’ï¼‰
        """
        self.vad_cache = {}
        self.asr_cache = {}
        self.audio_buffer = np.array([], dtype=np.float32)
        self.accumulated_intermediate_text = ""
        self.silence_timer = 0.0
        self.last_voice_time = time.time()
        self.is_completed = False
        self.has_detected_speech = False  # æ ‡è®°æ˜¯å¦æ›¾ç»æ£€æµ‹åˆ°è¿‡è¯­éŸ³ï¼ˆç”¨äºé˜²æ­¢çº¯é™éŸ³è§¦å‘finalizeï¼‰
        self.silence_chunk_count = 0  # é‡ç½®é™éŸ³chunkè®¡æ•°å™¨
        self.pre_speech_buffer = np.array([], dtype=np.float32)  # é‡ç½®å‰å‘ä¿æŠ¤ç¼“å†²åŒº
        
        # é‡ç½®å°¾éŸ³ä¿æŠ¤çŠ¶æ€
        self.tail_protection_start_time = None
        
        # é‡ç½®æ¿€æ´»çŠ¶æ€
        old_activated = self.is_activated
        self.is_activated = False  # é‡ç½®æ¿€æ´»æ ‡è®°
        if old_activated:
            logger.info("ğŸ”„ [çŠ¶æ€é‡ç½®] KWS æ¿€æ´»çŠ¶æ€å·²æ¸…é™¤: True -> False")
        
        # å®Œå…¨é‡ç½® SV å£°çº¹è¯†åˆ«çŠ¶æ€ï¼ˆåŒ…æ‹¬æ³¨å†ŒçŠ¶æ€ï¼‰
        # æ³¨æ„ï¼šå¯¹è¯ç»“æŸåï¼Œç”¨æˆ·ç¦»å¼€ï¼Œä¸‹ä¸€æ¬¡æ–°ç”¨æˆ·æ¥éœ€è¦é‡æ–°æ³¨å†Œå£°çº¹
        old_enrolled = self.is_enrolled
        old_enroll_path = self.enroll_audio_path
        old_enroll_buffer_len = len(self.enroll_audio_buffer)
        self.is_enrolled = False  # æ¸…ç©ºæ³¨å†ŒçŠ¶æ€
        self.enroll_audio_path = None  # æ¸…ç©ºæ³¨å†Œæ ·æœ¬è·¯å¾„
        self.enroll_audio_buffer = np.array([], dtype=np.float32)  # æ¸…ç©ºæ³¨å†Œç¼“å†²åŒº
        self.enroll_has_detected_speech = False  # é‡ç½®enrollmentè¯­éŸ³æ£€æµ‹æ ‡è®°
        self.enroll_first_speech_time = None  # é‡ç½®enrollmenté¦–æ¬¡è¯­éŸ³æ—¶é—´
        if old_enrolled or old_enroll_path or old_enroll_buffer_len > 0:
            logger.info("ğŸ”„ [çŠ¶æ€é‡ç½®] SV å£°çº¹æ³¨å†ŒçŠ¶æ€å·²å®Œå…¨æ¸…é™¤: is_enrolled=%s->False, enroll_audio_path=%s, buffer=%dæ ·æœ¬ (%.2fs)", 
                       old_enrolled, old_enroll_path, old_enroll_buffer_len, 
                       old_enroll_buffer_len / STREAMING_TARGET_SAMPLE_RATE if old_enroll_buffer_len > 0 else 0.0)
        
        # é‡ç½®å®éªŒæ€§SVéªŒè¯ç¼“å†²åŒº
        old_experimental_sv_buffer_len = len(self.experimental_sv_buffer)
        old_accumulated_buffer_len = len(self.experimental_sv_accumulated_buffer)
        self.experimental_sv_buffer = np.array([], dtype=np.float32)
        self.experimental_sv_accumulated_buffer = np.array([], dtype=np.float32)  # æ¸…ç©ºç´¯ç§¯ç¼“å†²åŒº
        self.experimental_sv_last_verify_time = 0.0
        if old_experimental_sv_buffer_len > 0 or old_accumulated_buffer_len > 0:
            logger.info("ğŸ”„ [çŠ¶æ€é‡ç½®] å®éªŒæ€§SVéªŒè¯ç¼“å†²åŒºå·²æ¸…ç©º: chunk=%dæ ·æœ¬ (%.2fs), ç´¯ç§¯=%dæ ·æœ¬ (%.2fs)", 
                       old_experimental_sv_buffer_len, old_experimental_sv_buffer_len / STREAMING_TARGET_SAMPLE_RATE,
                       old_accumulated_buffer_len, old_accumulated_buffer_len / STREAMING_TARGET_SAMPLE_RATE)
        
        # æ ¹æ® use_wake å†³å®šé‡ç½®åçš„æ¨¡å¼
        if self.use_wake:
            self.mode = "WAITING_FOR_WAKEUP"
            old_kws_buffer_len = len(self.kws_audio_buffer)
            self.kws_cache = {}
            self.kws_vad_cache = {}  # æ¸…ç©º KWS æ¨¡å¼çš„ VAD cacheï¼ˆè™½ç„¶ä¸å†ä½¿ç”¨ï¼Œä½†ä¿ç•™å®šä¹‰ï¼‰
            # é‡ç½® KWS éŸ³é¢‘ç´¯ç§¯ç›¸å…³çŠ¶æ€
            self.kws_audio_buffer = np.array([], dtype=np.float32)
            if old_kws_buffer_len > 0:
                logger.info("ğŸ”„ [çŠ¶æ€é‡ç½®] KWS éŸ³é¢‘ç¼“å†²åŒºå·²æ¸…ç©º: %d æ ·æœ¬ (%.2fs), cacheå·²æ¸…é™¤", 
                           old_kws_buffer_len, old_kws_buffer_len / STREAMING_TARGET_SAMPLE_RATE)
        else:
            self.mode = "ASR_ACTIVE"  # ä¸å¯ç”¨å”¤é†’ï¼Œç›´æ¥è¿›å…¥ ASR æ¨¡å¼
            old_kws_buffer_len = len(self.kws_audio_buffer)
            self.kws_cache = {}
            self.kws_vad_cache = {}  # æ¸…ç©º KWS æ¨¡å¼çš„ VAD cacheï¼ˆè™½ç„¶ä¸å†ä½¿ç”¨ï¼Œä½†ä¿ç•™å®šä¹‰ï¼‰
            # æ¸…ç©º KWS éŸ³é¢‘ç´¯ç§¯ç›¸å…³çŠ¶æ€
            self.kws_audio_buffer = np.array([], dtype=np.float32)
            if old_kws_buffer_len > 0:
                logger.info("ğŸ”„ [çŠ¶æ€é‡ç½®] KWS éŸ³é¢‘ç¼“å†²åŒºå·²æ¸…ç©º: %d æ ·æœ¬ (%.2fs), cacheå·²æ¸…é™¤", 
                           old_kws_buffer_len, old_kws_buffer_len / STREAMING_TARGET_SAMPLE_RATE)
    
    def set_use_wake(self, use_wake: bool):
        """
        è®¾ç½®æ˜¯å¦å¯ç”¨å”¤é†’æ¨¡å¼
        
        Args:
            use_wake: True è¡¨ç¤ºå¯ç”¨å”¤é†’æ¨¡å¼ï¼ŒFalse è¡¨ç¤ºç›´æ¥è¿›å…¥ ASR æ¨¡å¼
        """
        self.use_wake = use_wake
        if not use_wake:
            # å¦‚æœç¦ç”¨å”¤é†’ï¼Œç›´æ¥åˆ‡æ¢åˆ° ASR æ¨¡å¼
            if self.mode == "WAITING_FOR_WAKEUP":
                self.mode = "ASR_ACTIVE"
                self.kws_cache = {}
                logger.info("å·²ç¦ç”¨å”¤é†’æ¨¡å¼ï¼Œåˆ‡æ¢åˆ° ASR æ¨¡å¼")
        else:
            # å¦‚æœå¯ç”¨å”¤é†’ï¼Œä¸”å½“å‰åœ¨ ASR æ¨¡å¼ï¼Œåˆ‡æ¢åˆ°ç­‰å¾…å”¤é†’æ¨¡å¼ï¼ˆå–æ¶ˆæ¿€æ´»çŠ¶æ€ï¼‰
            # è¿™æ˜¯å‰ç«¯ä¸»åŠ¨è¦æ±‚å–æ¶ˆæ¿€æ´»çŠ¶æ€ï¼Œæ— è®º is_completed çŠ¶æ€å¦‚ä½•
            if self.mode == "ASR_ACTIVE":
                old_activated = self.is_activated
                old_kws_buffer_len = len(self.kws_audio_buffer)
                self.mode = "WAITING_FOR_WAKEUP"
                self.kws_cache = {}
                self.kws_vad_cache = {}
                self.kws_audio_buffer = np.array([], dtype=np.float32)
                self.is_activated = False  # å–æ¶ˆæ¿€æ´»çŠ¶æ€
                logger.info("ğŸ”„ [çŠ¶æ€åˆ‡æ¢] å·²å¯ç”¨å”¤é†’æ¨¡å¼ï¼Œå–æ¶ˆæ¿€æ´»çŠ¶æ€ï¼Œåˆ‡æ¢åˆ°ç­‰å¾…å”¤é†’æ¨¡å¼")
                if old_activated:
                    logger.info("ğŸ”„ [çŠ¶æ€æ¸…é™¤] KWS æ¿€æ´»çŠ¶æ€å·²æ¸…é™¤: True -> False")
                if old_kws_buffer_len > 0:
                    logger.info("ğŸ”„ [çŠ¶æ€æ¸…é™¤] KWS éŸ³é¢‘ç¼“å†²åŒºå·²æ¸…ç©º: %d æ ·æœ¬ (%.2fs), cacheå·²æ¸…é™¤", 
                               old_kws_buffer_len, old_kws_buffer_len / STREAMING_TARGET_SAMPLE_RATE)
    
    def reset_asr_state(self):
        """
        åªé‡ç½® ASR ç›¸å…³çŠ¶æ€ï¼Œä¸æ”¹å˜æ¨¡å¼å’Œæ¿€æ´»çŠ¶æ€
        ç”¨äº finalize() åå‡†å¤‡ä¸‹ä¸€å¥è¯çš„è¯†åˆ«
        """
        self.vad_cache = {}
        self.asr_cache = {}
        self.audio_buffer = np.array([], dtype=np.float32)
        self.accumulated_intermediate_text = ""
        self.silence_timer = 0.0
        self.last_voice_time = time.time()
        self.is_completed = False
        self.has_detected_speech = False  # æ ‡è®°æ˜¯å¦æ›¾ç»æ£€æµ‹åˆ°è¿‡è¯­éŸ³ï¼ˆç”¨äºé˜²æ­¢çº¯é™éŸ³è§¦å‘finalizeï¼‰
        self.silence_chunk_count = 0  # é‡ç½®é™éŸ³chunkè®¡æ•°å™¨
        self.pre_speech_buffer = np.array([], dtype=np.float32)  # é‡ç½®å‰å‘ä¿æŠ¤ç¼“å†²åŒº
        self.tail_protection_start_time = None  # é‡ç½®å°¾éŸ³ä¿æŠ¤çŠ¶æ€
        # æ³¨æ„ï¼šä¸é‡ç½® is_activatedï¼Œä¿æŒæ¿€æ´»çŠ¶æ€
        logger.debug("å·²é‡ç½® ASR çŠ¶æ€ï¼Œå‡†å¤‡ä¸‹ä¸€å¥è¯è¯†åˆ«ï¼ˆæ¨¡å¼: %s, æ¿€æ´»: %sï¼‰", 
                    self.mode, self.is_activated)
    
    async def process_wakeup_chunk(self, audio_np: np.ndarray) -> bool:
        """
        ç®€åŒ–çš„KWSå”¤é†’æ£€æµ‹ï¼ˆæ»‘åŠ¨çª—å£ï¼Œå›ºå®š1600ms = 4ä¸ª400ms chunkï¼‰
        
        æµç¨‹ï¼š
        1. ç›´æ¥ç´¯ç§¯æ‰€æœ‰chunkåˆ°kws_audio_bufferï¼ˆä¸ä¾èµ–VADåˆ¤æ–­æ˜¯å¦æœ‰å£°éŸ³ï¼‰
        2. æ»‘åŠ¨çª—å£ï¼šå¦‚æœè¶…è¿‡1600msï¼ˆ4ä¸ªchunkï¼‰ï¼Œåªä¿ç•™æœ€æ–°çš„1600msï¼ˆFIFOé˜Ÿåˆ—ï¼‰
        3. å¦‚æœè¾¾åˆ°1600msï¼ˆ4ä¸ªchunkï¼‰ï¼Œç«‹å³è§¦å‘KWSæ£€æµ‹
        4. KWSæ¨¡å‹è‡ªå·±ä¼šåˆ¤æ–­éŸ³é¢‘ä¸­æ˜¯å¦æœ‰å”¤é†’è¯
        
        Args:
            audio_np: numpyæ•°ç»„ï¼Œfloat32ï¼Œ16kHzï¼Œå•å£°é“ï¼ˆå‰ç«¯å‘é€çš„400ms chunkï¼‰
            
        Returns:
            bool: True è¡¨ç¤ºæ£€æµ‹åˆ°å”¤é†’è¯ï¼ŒFalse è¡¨ç¤ºæœªæ£€æµ‹åˆ°
        """
        try:
            # 1. ç›´æ¥ç´¯ç§¯æ‰€æœ‰chunkï¼ˆä¸ä¾èµ–VADåˆ¤æ–­æ˜¯å¦æœ‰å£°éŸ³ï¼‰
            # KWSæ¨¡å‹è‡ªå·±ä¼šåˆ¤æ–­éŸ³é¢‘ä¸­æ˜¯å¦æœ‰å”¤é†’è¯
            
            # âš ï¸ éŸ³é‡æ£€æµ‹å’Œæ—¥å¿—ï¼ˆç”¨äºè°ƒè¯•éŸ³é‡ä¸ä¸€è‡´é—®é¢˜ï¼‰
            audio_energy = np.mean(np.abs(audio_np))
            audio_max = np.max(np.abs(audio_np))
            audio_rms = np.sqrt(np.mean(audio_np ** 2))
            logger.debug("KWS chunkéŸ³é‡æ£€æµ‹: energy=%.6f, max=%.6f, rms=%.6f, len=%dæ ·æœ¬ (%.2fms)", 
                       audio_energy, audio_max, audio_rms, len(audio_np), len(audio_np) / STREAMING_TARGET_SAMPLE_RATE * 1000)
            
            self.kws_audio_buffer = np.concatenate([self.kws_audio_buffer, audio_np])
            
            # 2. æ»‘åŠ¨çª—å£ï¼šå¦‚æœè¶…è¿‡1600msï¼ˆ4ä¸ªchunkï¼‰ï¼Œåªä¿ç•™æœ€æ–°çš„1600msï¼ˆFIFOé˜Ÿåˆ—ï¼‰
            # æ–°æ¥ä¸€ä¸ªchunkï¼Œå¦‚æœè¶…è¿‡1600msï¼Œä¸¢æ‰æœ€æ—§çš„chunkï¼Œä¿ç•™æœ€æ–°çš„1600ms
            target_samples = int(self.kws_min_duration * STREAMING_TARGET_SAMPLE_RATE)  # 1600ms = 25600 samples
            if len(self.kws_audio_buffer) > target_samples:
                old_buffer_len = len(self.kws_audio_buffer)
                self.kws_audio_buffer = self.kws_audio_buffer[-target_samples:]  # åªä¿ç•™æœ€æ–°çš„1600ms
                logger.debug("KWSæ»‘åŠ¨çª—å£ - è¶…è¿‡1600msï¼Œä¿ç•™æœ€æ–°1600ms: %dæ ·æœ¬ -> %dæ ·æœ¬ (%.2fs -> %.2fs)", 
                           old_buffer_len, len(self.kws_audio_buffer),
                           old_buffer_len / STREAMING_TARGET_SAMPLE_RATE,
                           len(self.kws_audio_buffer) / STREAMING_TARGET_SAMPLE_RATE)
            
            # 3. æ£€æŸ¥æ˜¯å¦è¾¾åˆ°1600msï¼ˆ4ä¸ªchunkï¼Œè§¦å‘æ£€æµ‹ï¼‰
            buffer_duration = len(self.kws_audio_buffer) / STREAMING_TARGET_SAMPLE_RATE
            if buffer_duration >= self.kws_min_duration:  # 1600ms
                logger.info("KWS éŸ³é¢‘ç´¯ç§¯è¾¾åˆ° 1600ms (%.2fs, 4ä¸ªchunk)ï¼Œè§¦å‘æ£€æµ‹", buffer_duration)
                return await self._perform_kws_detection()
            
            # 4. å¦‚æœè¿˜æ²¡æœ‰è¾¾åˆ°1600msï¼Œç»§ç»­ç­‰å¾…
            logger.debug("KWSæ¨¡å¼ - ç´¯ç§¯éŸ³é¢‘: å½“å‰é•¿åº¦=%.2fs (éœ€è¦â‰¥%.2fsæ‰æ£€æµ‹ï¼Œå½“å‰chunkæ•°: %.1f)", 
                       buffer_duration, self.kws_min_duration, buffer_duration / 0.4)
            return False
                
        except Exception as e:
            logger.error("KWS å”¤é†’æ£€æµ‹å¼‚å¸¸: %s", e, exc_info=True)
            # å¼‚å¸¸æ—¶æ¸…ç©ºç¼“å†²åŒºï¼Œé¿å…æ— é™ç´¯ç§¯
            old_buffer_len = len(self.kws_audio_buffer)
            self.kws_audio_buffer = np.array([], dtype=np.float32)
            if old_buffer_len > 0:
                logger.info("ğŸ”„ [KWSæ¸…é™¤] å¼‚å¸¸æ—¶ KWS éŸ³é¢‘ç¼“å†²åŒºå·²æ¸…ç©º: %d æ ·æœ¬ (%.2fs)", 
                           old_buffer_len, old_buffer_len / STREAMING_TARGET_SAMPLE_RATE)
            return False
    
    async def _perform_kws_detection(self) -> bool:
        """
        æ‰§è¡Œ KWS æ£€æµ‹ï¼ˆä½¿ç”¨ç´¯ç§¯çš„éŸ³é¢‘ï¼‰
        
        Returns:
            bool: True è¡¨ç¤ºæ£€æµ‹åˆ°å”¤é†’è¯ï¼ŒFalse è¡¨ç¤ºæœªæ£€æµ‹åˆ°
        """
        if len(self.kws_audio_buffer) == 0:
            return False
        
        try:
            # è·å– KWS æ¨¡å‹å®ä¾‹
            _, kws_model_instance = get_models()
            
            if kws_model_instance is None:
                logger.error("KWS æ¨¡å‹å®ä¾‹ä¸º Noneï¼Œæ— æ³•è¿›è¡Œå”¤é†’æ£€æµ‹")
                return False
            
            buffer_duration = len(self.kws_audio_buffer) / STREAMING_TARGET_SAMPLE_RATE
            
            # âš ï¸ éŸ³é‡æ£€æµ‹å’Œæ—¥å¿—ï¼ˆç”¨äºè°ƒè¯•KWSæ£€æµ‹ä¸ç¨³å®šé—®é¢˜ï¼‰
            buffer_energy = np.mean(np.abs(self.kws_audio_buffer))
            buffer_max = np.max(np.abs(self.kws_audio_buffer))
            buffer_rms = np.sqrt(np.mean(self.kws_audio_buffer ** 2))
            buffer_peak_db = 20 * np.log10(buffer_max + 1e-10)  # é¿å…log(0)
            buffer_rms_db = 20 * np.log10(buffer_rms + 1e-10)
            
            logger.info("KWS æ£€æµ‹ - è¾“å…¥éŸ³é¢‘: shape=%s, æ—¶é•¿=%.2fs, energy=%.6f, max=%.6f (%.2f dB), rms=%.6f (%.2f dB)", 
                       self.kws_audio_buffer.shape, buffer_duration,
                       buffer_energy, buffer_max, buffer_peak_db, buffer_rms, buffer_rms_db)
            
            # è°ƒç”¨ KWS æ¨¡å‹ï¼ˆä½¿ç”¨ç´¯ç§¯çš„å®Œæ•´éŸ³é¢‘ï¼Œä¸ä½¿ç”¨ cacheï¼Œå› ä¸ºè¿™æ˜¯å®Œæ•´çš„ä¸€æ®µï¼‰
            res = kws_model_instance.generate(
                input=self.kws_audio_buffer,
                cache={},  # æ¯æ¬¡æ£€æµ‹ä½¿ç”¨æ–°çš„ cacheï¼Œå› ä¸ºè¿™æ˜¯å®Œæ•´çš„ä¸€æ®µéŸ³é¢‘
                is_final=True  # ä½¿ç”¨ is_final=True è¡¨ç¤ºè¿™æ˜¯å®Œæ•´çš„ä¸€æ®µ
            )
            
            logger.debug("KWS æ£€æµ‹ - è¿”å›ç»“æœç±»å‹: %s, å†…å®¹: %s", type(res), res)
            
            # è§£æ KWS ç»“æœ
            if not (isinstance(res, (list, tuple)) and len(res) > 0):
                logger.debug("KWS ç»“æœæ ¼å¼å¼‚å¸¸: ä¸æ˜¯åˆ—è¡¨æˆ–å…ƒç»„ï¼Œæˆ–ä¸ºç©º")
                # æ¸…ç©º bufferï¼Œå‡†å¤‡ä¸‹ä¸€è½®
                old_buffer_len = len(self.kws_audio_buffer)
                self.kws_audio_buffer = np.array([], dtype=np.float32)
                self.kws_cache = {}  # æ¸…ç©º cache
                if old_buffer_len > 0:
                    logger.info("ğŸ”„ [KWSæ¸…é™¤] KWS ç»“æœæ ¼å¼å¼‚å¸¸ï¼Œå·²æ¸…ç©ºç¼“å†²åŒº: %d æ ·æœ¬ (%.2fs), cacheå·²æ¸…é™¤", 
                               old_buffer_len, old_buffer_len / STREAMING_TARGET_SAMPLE_RATE)
                return False
            
            if not isinstance(res[0], dict):
                logger.debug("KWS ç»“æœæ ¼å¼å¼‚å¸¸: ç¬¬ä¸€ä¸ªå…ƒç´ ä¸æ˜¯å­—å…¸ï¼Œç±»å‹: %s", type(res[0]))
                old_buffer_len = len(self.kws_audio_buffer)
                self.kws_audio_buffer = np.array([], dtype=np.float32)
                self.kws_cache = {}
                if old_buffer_len > 0:
                    logger.info("ğŸ”„ [KWSæ¸…é™¤] KWS ç»“æœæ ¼å¼å¼‚å¸¸ï¼Œå·²æ¸…ç©ºç¼“å†²åŒº: %d æ ·æœ¬ (%.2fs), cacheå·²æ¸…é™¤", 
                               old_buffer_len, old_buffer_len / STREAMING_TARGET_SAMPLE_RATE)
                return False
            
            # æå– text å­—æ®µ
            wake_field = res[0].get("text", None)
            if wake_field is None:
                logger.debug("KWS ç»“æœä¸­æ—  'text' å­—æ®µï¼Œkeys: %s", list(res[0].keys()) if isinstance(res[0], dict) else "N/A")
                old_buffer_len = len(self.kws_audio_buffer)
                self.kws_audio_buffer = np.array([], dtype=np.float32)
                self.kws_cache = {}
                if old_buffer_len > 0:
                    logger.info("ğŸ”„ [KWSæ¸…é™¤] KWS ç»“æœä¸­æ—  'text' å­—æ®µï¼Œå·²æ¸…ç©ºç¼“å†²åŒº: %d æ ·æœ¬ (%.2fs), cacheå·²æ¸…é™¤", 
                               old_buffer_len, old_buffer_len / STREAMING_TARGET_SAMPLE_RATE)
                return False
            
            # å…¼å®¹ text å¯èƒ½ä¸ºå­—ç¬¦ä¸²æˆ–åˆ—è¡¨çš„æƒ…å†µ
            wake_text = None
            if isinstance(wake_field, str):
                wake_text = wake_field
            elif isinstance(wake_field, (list, tuple)) and len(wake_field) > 0:
                first = wake_field[0]
                if isinstance(first, dict):
                    wake_text = first.get("text")
                else:
                    wake_text = str(first)
            else:
                wake_text = str(wake_field)
            
            logger.info("KWS æ£€æµ‹ - æå–çš„å”¤é†’æ–‡æœ¬: '%s' (éŸ³é¢‘é•¿åº¦: %.2fs)", wake_text, buffer_duration)
            
            # åˆ¤æ–­æ˜¯å¦å”¤é†’æˆåŠŸï¼šéç©ºä¸”ä¸ç­‰äº 'rejected'
            if wake_text and wake_text != "rejected":
                logger.info("âœ… KWS å”¤é†’æˆåŠŸ: '%s' (éŸ³é¢‘é•¿åº¦: %.2fs) - å°†åˆ‡æ¢åˆ°ASR_ACTIVEæ¨¡å¼ï¼Œå½“å‰chunkå°†è¢«è·³è¿‡", wake_text, buffer_duration)
                
                # å”¤é†’æˆåŠŸï¼Œå…ˆä¿å­˜éŸ³é¢‘ï¼ˆåœ¨æ¸…ç©º buffer ä¹‹å‰ï¼‰
                await self._save_kws_audio()
                
                # âœ… ä¿®æ”¹ï¼šKWSå”¤é†’åï¼Œä¸å†è½¬ç§»bufferåˆ°enroll_audio_bufferï¼Œç›´æ¥æ¸…ç©ºKWS buffer
                # enroll_audio_bufferå°†ä»WAITING_FOR_ENROLLMENTæ¨¡å¼å¼€å§‹ï¼Œé€šè¿‡VADæ£€æµ‹åˆ°å£°éŸ³åæ‰å¼€å§‹ç´¯ç§¯
                old_kws_buffer_len = len(self.kws_audio_buffer)
                if old_kws_buffer_len > 0:
                    logger.info("ğŸ”„ [KWSæ¸…é™¤] KWSå”¤é†’æˆåŠŸï¼Œæ¸…ç©ºKWSéŸ³é¢‘ç¼“å†²åŒº: %dæ ·æœ¬ (%.2fs)", 
                               old_kws_buffer_len, buffer_duration)
                
                # ä¿å­˜åæ¸…ç©º KWS buffer å’Œ cacheï¼Œå‡†å¤‡ä¸‹ä¸€è½®
                self.kws_audio_buffer = np.array([], dtype=np.float32)
                self.kws_cache = {}  # æ¸…ç©º KWS æ¨¡å‹ cache
                self.kws_vad_cache = {}  # æ¸…ç©º KWS æ¨¡å¼çš„ VAD cache
                logger.info("ğŸ”„ [KWSæ¸…é™¤] KWS å”¤é†’æˆåŠŸï¼Œå·²ä¿å­˜éŸ³é¢‘å¹¶æ¸…ç©ºKWSç¼“å†²åŒº: %d æ ·æœ¬ (%.2fs), cacheå·²æ¸…é™¤", 
                           old_kws_buffer_len, buffer_duration)
                
                # âœ… å…³é”®ä¿®å¤ï¼šKWSæˆåŠŸç¬é—´ï¼Œæ¸…ç©ºæ‰€æœ‰ASRç›¸å…³çŠ¶æ€
                # ç¡®ä¿ç¬¬ä¸€å¥è¯ï¼ˆåŒ…å«å”¤é†’è¯ï¼‰ä¸å‚ä¸ASRè¯†åˆ«
                old_audio_buffer_len = len(self.audio_buffer)
                old_accumulated_text = self.accumulated_intermediate_text
                self.audio_buffer = np.array([], dtype=np.float32)  # æ¸…ç©ºASRéŸ³é¢‘ç¼“å†²åŒº
                self.vad_cache = {}  # æ¸…ç©ºASRä¾èµ–çš„VAD cache
                self.asr_cache = {}  # æ¸…ç©ºASR cache
                self.accumulated_intermediate_text = ""  # æ¸…ç©ºç´¯ç§¯çš„ä¸­é—´æ–‡æœ¬
                self.silence_timer = 0.0  # é‡ç½®é™é»˜è®¡æ—¶å™¨
                self.last_voice_time = time.time()  # é‡ç½®æœ€åè¯­éŸ³æ—¶é—´
                self.tail_protection_start_time = None  # æ¸…ç©ºå°¾éŸ³ä¿æŠ¤çŠ¶æ€
                self.is_completed = False  # é‡ç½®å®Œæˆæ ‡è®°
                
                if old_audio_buffer_len > 0 or old_accumulated_text:
                    logger.info("ğŸ”„ [KWSæ¿€æ´»] å·²æ¸…ç©ºæ‰€æœ‰ASRç›¸å…³çŠ¶æ€: audio_buffer=%dæ ·æœ¬ (%.2fs), accumulated_text='%s', vad_cacheå·²æ¸…ç©º, asr_cacheå·²æ¸…ç©º", 
                               old_audio_buffer_len, old_audio_buffer_len / STREAMING_TARGET_SAMPLE_RATE if old_audio_buffer_len > 0 else 0.0,
                               old_accumulated_text)
                else:
                    logger.info("ğŸ”„ [KWSæ¿€æ´»] ASRç›¸å…³çŠ¶æ€ä¸ºç©ºï¼ˆæ­£å¸¸ï¼ŒWAITING_FOR_WAKEUPæ¨¡å¼ä¸‹ä¸ç´¯ç§¯ASRï¼‰")
                
                return True
            else:
                # å”¤é†’å¤±è´¥ï¼Œæ¸…ç©º buffer å’Œ cacheï¼Œå‡†å¤‡ä¸‹ä¸€è½®
                old_buffer_len = len(self.kws_audio_buffer)
                self.kws_audio_buffer = np.array([], dtype=np.float32)
                self.kws_cache = {}  # æ¸…ç©º KWS æ¨¡å‹ cache
                self.kws_vad_cache = {}  # æ¸…ç©º KWS æ¨¡å¼çš„ VAD cache
                logger.info("ğŸ”„ [KWSæ¸…é™¤] KWS å”¤é†’å¤±è´¥ï¼Œå·²æ¸…ç©ºç¼“å†²åŒº: %d æ ·æœ¬ (%.2fs), cacheå·²æ¸…é™¤", 
                           old_buffer_len, buffer_duration)
                logger.debug("KWS å”¤é†’å¤±è´¥: æ–‡æœ¬='%s' (ç©ºæˆ– rejected)", wake_text)
                return False
                
        except Exception as e:
            logger.error("KWS æ£€æµ‹æ‰§è¡Œå¼‚å¸¸: %s", e, exc_info=True)
            # æ¸…ç©º buffer å’Œ cache
            self.kws_audio_buffer = np.array([], dtype=np.float32)
            self.kws_cache = {}  # æ¸…ç©º KWS æ¨¡å‹ cache
            self.kws_vad_cache = {}  # æ¸…ç©º KWS æ¨¡å¼çš„ VAD cache
            return False
    
    async def _save_kws_audio(self):
        """
        ä¿å­˜ KWS æ£€æµ‹éŸ³é¢‘åˆ°æœ¬åœ°æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•å’ŒéªŒè¯ï¼‰
        
        ä¿å­˜è·¯å¾„ï¼š/workspace/voice-service/generated/kws_detection_audio/
        å®¿ä¸»æœºè·¯å¾„ï¼š./generated/kws_detection_audio/
        """
        if len(self.kws_audio_buffer) == 0:
            logger.warning("KWS éŸ³é¢‘ç¼“å†²åŒºä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜")
            return
        
        try:
            from datetime import datetime
            from pathlib import Path
            import wave
            
            # 1. åˆ›å»ºä¿å­˜ç›®å½•
            save_dir = Path("/workspace/voice-service/generated/kws_detection_audio")
            save_dir.mkdir(parents=True, exist_ok=True)
            
            # 2. ç”Ÿæˆæ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]  # ç²¾ç¡®åˆ°æ¯«ç§’
            wav_filename = f"kws_detection_{timestamp}.wav"
            wav_file_path = save_dir / wav_filename
            
            # 3. éŸ³é‡æ£€æµ‹å’Œæ—¥å¿—ï¼ˆç”¨äºè°ƒè¯•éŸ³é‡ä¸ä¸€è‡´é—®é¢˜ï¼‰
            buffer_duration = len(self.kws_audio_buffer) / STREAMING_TARGET_SAMPLE_RATE
            buffer_energy = np.mean(np.abs(self.kws_audio_buffer))
            buffer_max = np.max(np.abs(self.kws_audio_buffer))
            buffer_rms = np.sqrt(np.mean(self.kws_audio_buffer ** 2))
            buffer_peak_db = 20 * np.log10(buffer_max + 1e-10)  # é¿å…log(0)
            buffer_rms_db = 20 * np.log10(buffer_rms + 1e-10)
            
            logger.info("ğŸ“Š [KWSéŸ³é¢‘] ä¿å­˜å‰éŸ³é‡æ£€æµ‹: energy=%.6f, max=%.6f (%.2f dB), rms=%.6f (%.2f dB), len=%dæ ·æœ¬ (%.2fs)", 
                       buffer_energy, buffer_max, buffer_peak_db, buffer_rms, buffer_rms_db,
                       len(self.kws_audio_buffer), buffer_duration)
            
            # 4. å°† numpy float32 æ•°ç»„è½¬æ¢ä¸º int16 å¹¶ä¿å­˜ä¸º WAV
            # åªåšå¿…è¦çš„ clamp åˆ° [-1, 1]ï¼Œä¸åšå½’ä¸€åŒ–ï¼Œç¡®ä¿åŠ¨æ€èŒƒå›´ä¸è¢«å‹ç¼©
            audio_clamped = np.clip(self.kws_audio_buffer, -1.0, 1.0)
            audio_int16 = (audio_clamped * 32767.0).astype(np.int16)
            
            # 5. ä½¿ç”¨ wave æ¨¡å—ä¿å­˜ WAV æ–‡ä»¶
            with wave.open(str(wav_file_path), 'wb') as wav_file:
                wav_file.setnchannels(1)  # å•å£°é“
                wav_file.setsampwidth(2)  # 16-bit (2 bytes)
                wav_file.setframerate(STREAMING_TARGET_SAMPLE_RATE)  # 16kHz
                wav_file.writeframes(audio_int16.tobytes())
            
            buffer_duration = len(self.kws_audio_buffer) / STREAMING_TARGET_SAMPLE_RATE
            file_size = os.path.getsize(wav_file_path)
            logger.info("âœ… å·²ä¿å­˜ KWS æ£€æµ‹éŸ³é¢‘: %s (æ—¶é•¿: %.2fs, å¤§å°: %d å­—èŠ‚, %.2f KB)", 
                       wav_file_path, buffer_duration, file_size, file_size / 1024)
            logger.info("ğŸ“ å®¿ä¸»æœºè·¯å¾„: ./generated/kws_detection_audio/%s", wav_filename)
            
        except Exception as e:
            logger.error("ä¿å­˜ KWS æ£€æµ‹éŸ³é¢‘å¤±è´¥: %s", e, exc_info=True)
    
    def process_chunk(self, audio_np: np.ndarray) -> Dict[str, Any]:
        """
        å¤„ç†ä¸€ä¸ªéŸ³é¢‘ç‰‡æ®µï¼Œè¿”å›ä¸­é—´ç»“æœ
        
        Args:
            audio_np: numpyæ•°ç»„ï¼Œfloat32ï¼Œ16kHzï¼Œå•å£°é“
            
        Returns:
            dict: {
                "is_speech": bool,  # æ˜¯å¦æ£€æµ‹åˆ°è¯­éŸ³
                "intermediate_text": str,  # ç´¯ç§¯çš„ä¸­é—´è¯†åˆ«æ–‡æœ¬
                "should_finalize": bool  # æ˜¯å¦åº”è¯¥è§¦å‘æœ€ç»ˆè¯†åˆ«ï¼ˆé™é»˜â‰¥1ç§’ï¼‰
            }
        """
        vad_model, asr_model, _ = get_streaming_models()
        current_time = time.time()
        
        # åœ¨è¿›å…¥æ¨¡å‹å‰æ·»åŠ éŸ³é¢‘ç»Ÿè®¡æ—¥å¿—
        stats = _log_audio_statistics(audio_np, STREAMING_TARGET_SAMPLE_RATE, "æ¨¡å‹è¾“å…¥å‰(process_chunk)")
        if stats and stats.get("clipping_ratio", 0) > 0.01:
            _dump_clipped_audio(audio_np, STREAMING_TARGET_SAMPLE_RATE, "process_chunk")
        
        # 1. VADæ£€æµ‹ï¼ˆåŒé‡æ ‡å‡†ï¼šèƒ½é‡æ£€æµ‹ + VADæ¨¡å‹ï¼‰
        audio_energy = np.mean(np.abs(audio_np))
        audio_max = np.max(np.abs(audio_np))
        
        # èƒ½é‡æ£€æµ‹
        if STREAMING_VAD_USE_AND_LOGIC:
            # "ä¸"é€»è¾‘ï¼šåŒæ—¶æ»¡è¶³å¹³å‡èƒ½é‡å’Œæœ€å¤§å€¼é˜ˆå€¼æ‰è®¤ä¸ºæ˜¯è¯­éŸ³ï¼ˆæ›´ä¸¥æ ¼ï¼‰
            is_speech_energy = audio_energy > STREAMING_VAD_ENERGY_THRESHOLD and audio_max > STREAMING_VAD_MAX_THRESHOLD
        else:
            # "æˆ–"é€»è¾‘ï¼šæ»¡è¶³ä»»ä¸€æ¡ä»¶å°±è®¤ä¸ºæ˜¯è¯­éŸ³ï¼ˆè¾ƒå®½æ¾ï¼‰
            is_speech_energy = audio_energy > STREAMING_VAD_ENERGY_THRESHOLD or audio_max > STREAMING_VAD_MAX_THRESHOLD
        
        # VADæ¨¡å‹æ£€æµ‹
        is_speech_vad = False
        try:
            # åŠ¨æ€è®¡ç®— chunk_sizeï¼ˆæ¯«ç§’ï¼‰ï¼ŒåŒ¹é…å®é™…éŸ³é¢‘é•¿åº¦
            chunk_duration_ms = len(audio_np) / STREAMING_TARGET_SAMPLE_RATE * 1000
            vad_res = vad_model.generate(
                input=audio_np,
                cache=self.vad_cache,
                is_final=False,
                chunk_size=int(chunk_duration_ms)
            )
            
            # æ£€æŸ¥VADè¿”å›æ ¼å¼
            if isinstance(vad_res, list) and len(vad_res) > 0:
                vad_item = vad_res[0]
                if isinstance(vad_item, dict):
                    value = vad_item.get("value", [])
                    if isinstance(value, list):
                        is_speech_vad = len(value) > 0
                    elif isinstance(value, str):
                        is_speech_vad = value.lower() == "speech"
        except Exception as vad_error:
            logger.warning("VADæ£€æµ‹å¼‚å¸¸ï¼ˆä½¿ç”¨èƒ½é‡æ£€æµ‹ï¼‰: %s", vad_error)
        
        # ç»¼åˆåˆ¤æ–­
        # is_speech = is_speech_energy or is_speech_vad
        is_speech = is_speech_energy
        
        
        # âš ï¸ åœ¨ASR_ACTIVEæ¨¡å¼ä¸‹è¾“å‡ºæ¯ä¸ªchunkçš„VADæ£€æµ‹ç»“æœæ—¥å¿—
        if self.mode == "ASR_ACTIVE":
            chunk_duration = len(audio_np) / STREAMING_TARGET_SAMPLE_RATE
            chunk_duration_ms = chunk_duration * 1000
            logger.info(
                "ğŸ“Š [VADæ£€æµ‹] chunkæ£€æµ‹ç»“æœ: "
                "is_speech=%s (energy=%s, vad=%s), "
                "energy=%.6f (é˜ˆå€¼=%.2f), max=%.6f (é˜ˆå€¼=%.2f), "
                "chunk_len=%dæ ·æœ¬ (%.2fms, %.3fs), "
                "èƒ½é‡æ£€æµ‹é€»è¾‘=%s, æœ€ç»ˆåˆ¤æ–­=OR",
                is_speech,
                is_speech_energy,
                is_speech_vad,
                audio_energy,
                STREAMING_VAD_ENERGY_THRESHOLD,
                audio_max,
                STREAMING_VAD_MAX_THRESHOLD,
                len(audio_np),
                chunk_duration_ms,
                chunk_duration,
                "AND" if STREAMING_VAD_USE_AND_LOGIC else "OR"
            )
        
        
        # 2. SV å£°çº¹æ³¨å†Œé€»è¾‘ï¼ˆå¦‚æœå¯ç”¨ä¸”æœªæ³¨å†Œï¼Œä¸”å·²é€šè¿‡ KWS æ¿€æ´»ï¼‰
        # å®‰å…¨è¦æ±‚ï¼šå£°çº¹æ³¨å†Œå¿…é¡»åœ¨ KWS æ¿€æ´»åæ‰å…è®¸ï¼Œé˜²æ­¢æœªæˆæƒæ³¨å†Œ
        if self.use_speaker_verification and not self.is_enrolled and is_speech and self.is_activated:
            # ç´¯ç§¯æ³¨å†ŒéŸ³é¢‘ï¼ˆåªç´¯ç§¯æœ‰è¯­éŸ³çš„ç‰‡æ®µï¼‰
            self.enroll_audio_buffer = np.concatenate([self.enroll_audio_buffer, audio_np])
            enroll_duration = len(self.enroll_audio_buffer) / STREAMING_TARGET_SAMPLE_RATE
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ³¨å†Œæ—¶é•¿è¦æ±‚ï¼ˆ4ç§’ï¼‰
            if enroll_duration >= self.min_enroll_seconds:
                enroll_path = self._save_enroll_sample()
                if enroll_path:
                    self.enroll_audio_path = enroll_path
                    old_enrolled = self.is_enrolled
                    self.is_enrolled = True
                    old_buffer_len = len(self.enroll_audio_buffer)
                    logger.info(f"âœ… å£°çº¹æ³¨å†Œå®Œæˆï¼š{enroll_path} ({enroll_duration:.2f}s)")
                    # æ¸…ç©ºæ³¨å†Œç¼“å†²åŒº
                    self.enroll_audio_buffer = np.array([], dtype=np.float32)
                    logger.info("ğŸ”„ [SVæ¸…é™¤] å£°çº¹æ³¨å†Œç¼“å†²åŒºå·²æ¸…ç©º: %d æ ·æœ¬ (%.2fs), æ³¨å†ŒçŠ¶æ€: %s -> True", 
                               old_buffer_len, enroll_duration, old_enrolled)
        elif self.use_speaker_verification and not self.is_enrolled and is_speech and not self.is_activated:
            # æœªæ¿€æ´»æ—¶ï¼Œæ¸…ç©ºä»»ä½•ç´¯ç§¯çš„æ³¨å†ŒéŸ³é¢‘ï¼Œé˜²æ­¢æœªæˆæƒæ³¨å†Œ
            if len(self.enroll_audio_buffer) > 0:
                old_buffer_len = len(self.enroll_audio_buffer)
                logger.warning("âš ï¸ æ£€æµ‹åˆ°æœªæ¿€æ´»çŠ¶æ€ä¸‹çš„å£°çº¹æ³¨å†Œå°è¯•ï¼Œå·²æ¸…ç©ºæ³¨å†Œç¼“å†²åŒºï¼ˆå®‰å…¨ä¿æŠ¤ï¼‰")
                self.enroll_audio_buffer = np.array([], dtype=np.float32)
                logger.info("ğŸ”„ [SVæ¸…é™¤] æœªæ¿€æ´»çŠ¶æ€ä¸‹çš„æ³¨å†Œç¼“å†²åŒºå·²æ¸…ç©º: %d æ ·æœ¬ (%.2fs)", 
                           old_buffer_len, old_buffer_len / STREAMING_TARGET_SAMPLE_RATE)
        
        # 3. æ›´æ–°é™é»˜è®¡æ—¶å™¨å’ŒéŸ³é¢‘ç´¯ç§¯ï¼ˆä¼˜åŒ–ï¼šç´¯ç§¯æ‰€æœ‰chunkï¼Œä¿æŒéŸ³é¢‘è¿ç»­æ€§ï¼‰
        # âœ… æ”¹è¿›é€»è¾‘ï¼š
        # 1. åªæœ‰æ£€æµ‹åˆ°è¯­éŸ³åï¼Œæ‰å¼€å§‹ç´¯ç§¯bufferï¼ˆé˜²æ­¢çº¯é™éŸ³è¿›å…¥bufferï¼‰
        # 2. æ£€æµ‹åˆ°è¯­éŸ³åï¼Œç´¯ç§¯æ‰€æœ‰chunkï¼ˆåŒ…æ‹¬é™éŸ³ï¼‰ï¼Œä¿æŒéŸ³é¢‘è¿ç»­æ€§
        # 3. åªæœ‰é•¿æ—¶é—´é™éŸ³ï¼ˆ2ç§’ï¼‰æ‰è§¦å‘finalize
        # 4. âš ï¸ å‰å‘ä¿æŠ¤æœºåˆ¶ï¼šæ£€æµ‹åˆ°è¯­éŸ³æ—¶ï¼Œå°†å‰å‘ä¿æŠ¤ç¼“å†²åŒºçš„å†…å®¹ä¹Ÿç´¯ç§¯åˆ°audio_bufferï¼ˆé˜²æ­¢ä¸¢å¤±è¯­éŸ³å¼€å¤´ï¼‰
        # è¿™æ ·å¯ä»¥ä¿æŒéŸ³é¢‘å®Œå…¨è¿ç»­ï¼Œæé«˜ASRè¯†åˆ«æ•ˆæœ
        # çŸ­æ—¶é—´çš„åœé¡¿ï¼ˆå¦‚800msï¼‰ä¼šè¢«ä¿ç•™åœ¨éŸ³é¢‘ä¸­ï¼Œæœ‰åŠ©äºè¯†åˆ«å‡†ç¡®æ€§
        
        # æ›´æ–°é™é»˜è®¡æ—¶å™¨å’Œè¯­éŸ³æ£€æµ‹æ ‡è®°
        if is_speech:
            # æ£€æµ‹åˆ°è¯­éŸ³ï¼šé‡ç½®é™é»˜è®¡æ—¶å™¨ï¼Œæ ‡è®°å·²æ£€æµ‹åˆ°è¯­éŸ³
            self.silence_timer = 0.0
            self.last_voice_time = current_time
            self.has_detected_speech = True  # æ ‡è®°å·²æ£€æµ‹åˆ°è¯­éŸ³
            self.silence_chunk_count = 0  # é‡ç½®é™éŸ³chunkè®¡æ•°å™¨ï¼ˆæ–°çš„è¯­éŸ³å¼€å§‹ï¼‰
            
            # âš ï¸ å‰å‘ä¿æŠ¤æœºåˆ¶ï¼šå¦‚æœå‰å‘ä¿æŠ¤ç¼“å†²åŒºæœ‰å†…å®¹ï¼Œå…ˆç´¯ç§¯åˆ°audio_bufferï¼ˆé˜²æ­¢ä¸¢å¤±è¯­éŸ³å¼€å¤´ï¼‰
            if len(self.pre_speech_buffer) > 0:
                old_pre_buffer_len = len(self.pre_speech_buffer)
                old_audio_buffer_len = len(self.audio_buffer)
                # è®°å½•æ‹¼æ¥å‰çš„ç»Ÿè®¡
                if old_audio_buffer_len > 0:
                    stats_before = _log_audio_statistics(self.audio_buffer, STREAMING_TARGET_SAMPLE_RATE, "æ‹¼æ¥å‰(audio_buffer)")
                stats_pre = _log_audio_statistics(self.pre_speech_buffer, STREAMING_TARGET_SAMPLE_RATE, "æ‹¼æ¥å‰(pre_speech_buffer)")
                
                self.audio_buffer = np.concatenate([self.audio_buffer, self.pre_speech_buffer])
                
                # è®°å½•æ‹¼æ¥åçš„ç»Ÿè®¡
                stats_after = _log_audio_statistics(self.audio_buffer, STREAMING_TARGET_SAMPLE_RATE, "æ‹¼æ¥å(audio_buffer+pre_speech)")
                
                logger.info("ğŸ”§ [å‰å‘ä¿æŠ¤] æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå°†å‰å‘ä¿æŠ¤ç¼“å†²åŒºç´¯ç§¯åˆ°audio_buffer: %dæ ·æœ¬ (%.2fs) + %dæ ·æœ¬ (%.2fs) -> %dæ ·æœ¬ (%.2fs)", 
                           old_audio_buffer_len, old_audio_buffer_len / STREAMING_TARGET_SAMPLE_RATE,
                           old_pre_buffer_len, old_pre_buffer_len / STREAMING_TARGET_SAMPLE_RATE,
                           len(self.audio_buffer), len(self.audio_buffer) / STREAMING_TARGET_SAMPLE_RATE)
                # æ¸…ç©ºå‰å‘ä¿æŠ¤ç¼“å†²åŒº
                self.pre_speech_buffer = np.array([], dtype=np.float32)
            
            # ç´¯ç§¯å½“å‰è¯­éŸ³chunk
            old_audio_buffer_len = len(self.audio_buffer)
            # è®°å½•æ‹¼æ¥å‰çš„ç»Ÿè®¡
            if old_audio_buffer_len > 0:
                stats_before = _log_audio_statistics(self.audio_buffer, STREAMING_TARGET_SAMPLE_RATE, "æ‹¼æ¥å‰(audio_buffer)")
            stats_chunk = _log_audio_statistics(audio_np, STREAMING_TARGET_SAMPLE_RATE, "æ‹¼æ¥å‰(å½“å‰chunk)")
            
            self.audio_buffer = np.concatenate([self.audio_buffer, audio_np])
            
            # è®°å½•æ‹¼æ¥åçš„ç»Ÿè®¡
            stats_after = _log_audio_statistics(self.audio_buffer, STREAMING_TARGET_SAMPLE_RATE, "æ‹¼æ¥å(audio_buffer+chunk)")
            
            # éªŒè¯æ‹¼æ¥æ˜¯å¦æ­£ç¡®ï¼šæ£€æŸ¥æ‹¼æ¥åçš„å‰éƒ¨åˆ†å’ŒåŸaudio_bufferæ˜¯å¦ä¸€è‡´
            if old_audio_buffer_len > 0:
                original_part = self.audio_buffer[:old_audio_buffer_len]
                new_part = self.audio_buffer[old_audio_buffer_len:]
                if not np.array_equal(original_part, self.audio_buffer[:old_audio_buffer_len]):
                    logger.error("âŒ [éŸ³é¢‘æŸåæ£€æµ‹] æ‹¼æ¥åaudio_bufferçš„å‰éƒ¨åˆ†ä¸åŸå§‹ä¸ä¸€è‡´ï¼")
                elif not np.array_equal(new_part, audio_np):
                    logger.error("âŒ [éŸ³é¢‘æŸåæ£€æµ‹] æ‹¼æ¥åaudio_bufferçš„åéƒ¨åˆ†ä¸æ–°chunkä¸ä¸€è‡´ï¼")
                else:
                    logger.debug("âœ… [éŸ³é¢‘æŸåæ£€æµ‹] æ‹¼æ¥éªŒè¯é€šè¿‡ï¼ŒéŸ³é¢‘æ•°æ®ä¿æŒä¸€è‡´")
        else:
            # æ£€æµ‹åˆ°é™éŸ³ï¼š
            if self.has_detected_speech:
                # å·²ç»æ£€æµ‹åˆ°è¿‡è¯­éŸ³ï¼Œç´¯ç§¯å‰2ä¸ªé™éŸ³chunkï¼Œåç»­é™éŸ³chunkä¸å†ç´¯ç§¯
                if self.silence_chunk_count < 2:
                    # å‰2ä¸ªé™éŸ³chunkï¼šç´¯ç§¯åˆ°audio_buffer
                    self.audio_buffer = np.concatenate([self.audio_buffer, audio_np])
                    self.silence_chunk_count += 1
                    logger.debug("ğŸ”‡ [é™éŸ³å¤„ç†] ç´¯ç§¯ç¬¬%dä¸ªé™éŸ³chunk: %dæ ·æœ¬ (%.2fs)", 
                               self.silence_chunk_count, len(audio_np), len(audio_np) / STREAMING_TARGET_SAMPLE_RATE)
                else:
                    # ç¬¬3ä¸ªåŠä»¥åçš„é™éŸ³chunkï¼šä¸å†ç´¯ç§¯ï¼Œåªæ›´æ–°é™é»˜è®¡æ—¶å™¨
                    logger.debug("ğŸ”‡ [é™éŸ³å¤„ç†] è·³è¿‡åç»­é™éŸ³chunkï¼ˆå·²ç´¯ç§¯2ä¸ªï¼‰: %dæ ·æœ¬ (%.2fs)", 
                               len(audio_np), len(audio_np) / STREAMING_TARGET_SAMPLE_RATE)
            
                # æ›´æ–°é™é»˜è®¡æ—¶å™¨ï¼ˆä»æœ€åä¸€æ¬¡æ£€æµ‹åˆ°è¯­éŸ³çš„æ—¶é—´å¼€å§‹è®¡ç®—ï¼‰
                self.silence_timer = current_time - self.last_voice_time
            else:
                # ä»æœªæ£€æµ‹åˆ°è¿‡è¯­éŸ³ï¼Œç´¯ç§¯åˆ°å‰å‘ä¿æŠ¤ç¼“å†²åŒºï¼ˆé˜²æ­¢ä¸¢å¤±è¯­éŸ³å¼€å¤´ï¼‰
                # å‰å‘ä¿æŠ¤ç¼“å†²åŒºä½¿ç”¨æ»‘åŠ¨çª—å£ï¼Œåªä¿ç•™æœ€æ–°çš„400msï¼ˆ1ä¸ªchunkï¼‰
                self.pre_speech_buffer = np.concatenate([self.pre_speech_buffer, audio_np])
                target_samples = int(self.pre_speech_max_duration * STREAMING_TARGET_SAMPLE_RATE)  # 400ms
                if len(self.pre_speech_buffer) > target_samples:
                    # åªä¿ç•™æœ€æ–°çš„400msï¼ˆFIFOé˜Ÿåˆ—ï¼‰
                    self.pre_speech_buffer = self.pre_speech_buffer[-target_samples:]
                self.silence_timer = 0.0
        
        # 4. æµå¼ASRï¼ˆä»…å¤„ç†è¯­éŸ³ç‰‡æ®µï¼‰
        # æ³¨é‡Šï¼šä¸å†è¿›è¡Œæµå¼ASRä¸­é—´è¯†åˆ«ï¼ŒchunkåªåšVADæ£€æµ‹å’ŒéŸ³é¢‘ç´¯ç§¯
        # æœ€ç»ˆè¯†åˆ«åœ¨ finalize() ä¸­è¿›è¡Œï¼ˆä½¿ç”¨å®Œæ•´çš„ audio_bufferï¼‰
        intermediate_text = ""  # ä¸å†ç´¯ç§¯ä¸­é—´ç»“æœï¼Œå§‹ç»ˆè¿”å›ç©ºå­—ç¬¦ä¸²
        # if is_speech:
        #     try:
        #         asr_res = asr_model.generate(
        #             input=audio_np,
        #             cache=self.asr_cache,
        #             is_final=False,
        #             chunk_size=STREAMING_CHUNK_SIZE,
        #             encoder_chunk_look_back=STREAMING_ENCODER_CHUNK_LOOK_BACK,
        #             decoder_chunk_look_back=STREAMING_DECODER_CHUNK_LOOK_BACK
        #         )
        #         
        #         # æå–æ–‡æœ¬
        #         new_text = ""
        #         if isinstance(asr_res, list) and len(asr_res) > 0:
        #             asr_item = asr_res[0]
        #             if isinstance(asr_item, dict):
        #                 new_text = asr_item.get("text", "")
        #                 if not new_text and "value" in asr_item:
        #                     value = asr_item.get("value", "")
        #                     if isinstance(value, str):
        #                         new_text = value
        #                     elif isinstance(value, list) and len(value) > 0:
        #                         first_val = value[0]
        #                         if isinstance(first_val, dict):
        #                             new_text = first_val.get("text", "")
        #             elif isinstance(asr_item, str):
        #                 new_text = asr_item
        #         elif isinstance(asr_res, dict):
        #             new_text = asr_res.get("text", "")
        #             if not new_text and "value" in asr_res:
        #                 value = asr_res.get("value", "")
        #                 if isinstance(value, str):
        #                     new_text = value
        #         
        #         new_text = new_text.strip() if new_text else ""
        #         
        #         # æ™ºèƒ½åˆå¹¶ç´¯ç§¯æ–‡æœ¬
        #         if new_text:
        #             if not self.accumulated_intermediate_text:
        #                 self.accumulated_intermediate_text = new_text
        #             elif new_text == self.accumulated_intermediate_text:
        #                 pass  # æ–‡æœ¬æœªå˜åŒ–
        #             elif new_text.startswith(self.accumulated_intermediate_text):
        #                 # æ–°æ–‡æœ¬æ˜¯ç´¯ç§¯æ–‡æœ¬çš„æ‰©å±•
        #                 self.accumulated_intermediate_text = new_text
        #             elif self.accumulated_intermediate_text.startswith(new_text):
        #                 # æ–°æ–‡æœ¬æ˜¯ç´¯ç§¯æ–‡æœ¬çš„å‰ç¼€ï¼ˆæ¨¡å‹ä¿®æ­£ï¼‰
        #                 self.accumulated_intermediate_text = new_text
        #             else:
        #                 # æ–°æ–‡æœ¬ä¸ç´¯ç§¯æ–‡æœ¬æ²¡æœ‰åŒ…å«å…³ç³»ï¼Œå¯èƒ½æ˜¯æ¨¡å‹é‡æ–°è¯†åˆ«
        #                 if len(new_text) > len(self.accumulated_intermediate_text) * 0.5:
        #                     self.accumulated_intermediate_text = new_text
        #         
        #         intermediate_text = self.accumulated_intermediate_text
        #         
        #     except Exception as asr_error:
        #         logger.error("ASRä¸­é—´è¯†åˆ«å¼‚å¸¸: %s", asr_error, exc_info=True)
        
        # 5. æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘æœ€ç»ˆè¯†åˆ«
        # âœ… æ”¹è¿›ï¼šç´¯ç§¯æ‰€æœ‰chunkåï¼Œåªéœ€è¦æ£€æŸ¥é™é»˜æ—¶é—´æ˜¯å¦è¾¾åˆ°é˜ˆå€¼
        # ä¸éœ€è¦å°¾éŸ³ä¿æŠ¤æœŸçš„åˆ¤æ–­ï¼Œå› ä¸ºæ‰€æœ‰chunkéƒ½å·²ç´¯ç§¯
        # âš ï¸ å…³é”®ä¿®å¤ï¼šåªæœ‰åœ¨æ›¾ç»æ£€æµ‹åˆ°è¿‡è¯­éŸ³çš„æƒ…å†µä¸‹ï¼Œæ‰å…è®¸è§¦å‘finalize
        # è¿™æ ·å¯ä»¥é˜²æ­¢çº¯é™éŸ³ï¼ˆä»æœªæœ‰è¯­éŸ³ï¼‰è§¦å‘finalize
        should_finalize = (self.silence_timer >= STREAMING_SILENCE_THRESHOLD and 
                          len(self.audio_buffer) > 0 and
                          self.has_detected_speech)  # å¿…é¡»æ›¾ç»æ£€æµ‹åˆ°è¿‡è¯­éŸ³
        
        # è°ƒè¯•æ—¥å¿—ï¼šæ‰“å° should_finalize çš„ä¸‰ä¸ªæ¡ä»¶å€¼ï¼ˆä½¿ç”¨ INFO çº§åˆ«ç¡®ä¿è¾“å‡ºï¼‰
        # æ³¨é‡Šï¼šæš‚æ—¶å…³é—­ should_finalize æ¡ä»¶æ£€æŸ¥æ—¥å¿—ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
        # logger.info(
        #     "[should_finalize] æ¡ä»¶æ£€æŸ¥: tail_protection=None(%s), silence_timer>=%.1f(%s, å®é™…=%.3fs), audio_buffer>0(%s, å®é™…=%dæ ·æœ¬, %.2fs), should_finalize=%s",
        #     condition1,
        #     STREAMING_SILENCE_THRESHOLD,
        #     condition2,
        #     self.silence_timer,
        #     condition3,
        #     len(self.audio_buffer),
        #     len(self.audio_buffer) / STREAMING_TARGET_SAMPLE_RATE if len(self.audio_buffer) > 0 else 0.0,
        #     should_finalize
        # )
        
        # 6. å®éªŒæ€§ï¼šchunkçº§åˆ«çš„å£°çº¹éªŒè¯ï¼ˆä»…åœ¨æœ‰è¯­éŸ³ä¸”å·²æ³¨å†Œä¸”å·²æ¿€æ´»æ—¶ï¼‰
        if (self.use_speaker_verification and self.is_enrolled and self.is_activated and 
            self.enroll_audio_path and is_speech):
            # ç´¯ç§¯éŸ³é¢‘åˆ°å®éªŒæ€§éªŒè¯ç¼“å†²åŒºï¼ˆå½“å‰chunkï¼‰
            self.experimental_sv_buffer = np.concatenate([self.experimental_sv_buffer, audio_np])
            buffer_duration = len(self.experimental_sv_buffer) / STREAMING_TARGET_SAMPLE_RATE
            
            # åŒæ—¶ç´¯ç§¯åˆ°ç´¯ç§¯ç¼“å†²åŒºï¼ˆ1+2+3+...ï¼‰
            self.experimental_sv_accumulated_buffer = np.concatenate([self.experimental_sv_accumulated_buffer, audio_np])
            accumulated_duration = len(self.experimental_sv_accumulated_buffer) / STREAMING_TARGET_SAMPLE_RATE
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å°éªŒè¯æ—¶é•¿ï¼Œä¸”è·ç¦»ä¸Šæ¬¡éªŒè¯å·²è¿‡è¶³å¤Ÿæ—¶é—´
            time_since_last_verify = current_time - self.experimental_sv_last_verify_time
            if (buffer_duration >= self.experimental_sv_min_duration and 
                time_since_last_verify >= self.experimental_sv_verify_interval):
                # æ‰§è¡ŒåŒæ­¥éªŒè¯ï¼šéªŒè¯å½“å‰chunkå’Œç´¯ç§¯chunks
                try:
                    # 1. éªŒè¯å½“å‰chunk
                    is_verified_chunk = self._verify_speaker_sync(self.experimental_sv_buffer, "chunk")
                    
                    # 2. éªŒè¯ç´¯ç§¯chunksï¼ˆå¦‚æœç´¯ç§¯ç¼“å†²åŒºè¶³å¤Ÿé•¿ï¼‰
                    is_verified_accumulated = None
                    if accumulated_duration >= self.experimental_sv_min_duration:
                        is_verified_accumulated = self._verify_speaker_sync(self.experimental_sv_accumulated_buffer, "accumulated")
                    
                    # æ¸…ç©ºå½“å‰chunkç¼“å†²åŒºï¼Œå‡†å¤‡ä¸‹ä¸€è½®éªŒè¯ï¼ˆç´¯ç§¯ç¼“å†²åŒºä¸æ¸…ç©ºï¼‰
                    self.experimental_sv_buffer = np.array([], dtype=np.float32)
                    self.experimental_sv_last_verify_time = current_time
                except Exception as e:
                    logger.error(f"âŒ [å®éªŒæ€§SVéªŒè¯] éªŒè¯å¼‚å¸¸: {e}", exc_info=True)
                    # éªŒè¯å¤±è´¥æ—¶ä¹Ÿæ¸…ç©ºå½“å‰chunkç¼“å†²åŒºï¼Œé¿å…ç´¯ç§¯è¿‡å¤š
                    self.experimental_sv_buffer = np.array([], dtype=np.float32)
        elif not is_speech:
            # é™éŸ³æ—¶ï¼Œå¦‚æœå½“å‰chunkç¼“å†²åŒºæœ‰å†…å®¹ä½†ä¸å¤Ÿé•¿ï¼Œä¹Ÿæ¸…ç©ºï¼ˆé¿å…ç´¯ç§¯æ— æ•ˆéŸ³é¢‘ï¼‰
            if len(self.experimental_sv_buffer) > 0:
                buffer_duration = len(self.experimental_sv_buffer) / STREAMING_TARGET_SAMPLE_RATE
                if buffer_duration < self.experimental_sv_min_duration:
                    self.experimental_sv_buffer = np.array([], dtype=np.float32)
        
        return {
            "is_speech": is_speech,
            "intermediate_text": intermediate_text,
            "should_finalize": should_finalize
        }




    async def finalize(self) -> str:
        """
        æœ€ç»ˆè¯†åˆ«ï¼šä½¿ç”¨è¯´è¯äººåˆ†ç¦»æ¨¡å‹è¿›è¡Œ ASR è¯†åˆ«å’Œè¯´è¯äººåˆ†ç¦»
        
        æµç¨‹ï¼š
        1. å°† audio_buffer (numpy float32) ä¿å­˜ä¸º WAV æ–‡ä»¶åˆ°æŒ‚è½½ç›®å½•
           ä¿å­˜è·¯å¾„ï¼š/workspace/voice-service/generated/asr_final_audio/
           å®¿ä¸»æœºè·¯å¾„ï¼š./generated/asr_final_audio/
        2. è°ƒç”¨è¯´è¯äººåˆ†ç¦»æ¨¡å‹ï¼ˆModelScope pipelineï¼‰è¿›è¡Œ ASR è¯†åˆ«å’Œè¯´è¯äººåˆ†ç¦»
        3. æŒ‰ speaker ID åˆ†ç»„ï¼ŒåŒä¸€ speaker çš„å¥å­æŒ‰æ—¶é—´æˆ³æ’åºæ‹¼æ¥
        4. å¯¹æ¯ä¸ª speaker è¿›è¡Œ SV å£°çº¹éªŒè¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        5. é€‰æ‹©ç­–ç•¥ï¼š
           - å•ä¸ª speakerï¼šç›´æ¥éªŒè¯ï¼Œé€šè¿‡è¿”å›æ–‡æœ¬ï¼Œå¤±è´¥è¿”å› __SV_VERIFICATION_FAILED__
           - å¤šä¸ª speakerï¼šé€‰æ‹©åˆ†æ•°æœ€é«˜çš„ï¼Œå¦‚æœéƒ½ä½äºé˜ˆå€¼åˆ™è¿”å› __SV_VERIFICATION_FAILED__
           - æœªå¯ç”¨ SVï¼šè¿”å›æ‰€æœ‰ speaker çš„æ–‡æœ¬æ‹¼æ¥
        
        æ³¨æ„ï¼š
        - å¦‚æœ audio_buffer ä¸ºç©ºï¼Œä½¿ç”¨ç´¯ç§¯çš„ä¸­é—´ç»“æœä½œä¸ºåå¤‡
        - WAV æ–‡ä»¶ä¼šä¿ç•™åœ¨æŒ‚è½½ç›®å½•ä¸­ï¼Œæ–¹ä¾¿åœ¨å®¿ä¸»æœºæŸ¥çœ‹å’Œè°ƒè¯•
        - åœ¨finalizeå‰æ¸…ç©ºå®éªŒæ€§SVéªŒè¯çš„ç´¯ç§¯ç¼“å†²åŒº
        - ä¸´æ—¶ speaker éŸ³é¢‘æ–‡ä»¶ä¼šåœ¨éªŒè¯åè‡ªåŠ¨æ¸…ç†
        
        Returns:
            str: æœ€ç»ˆè¯†åˆ«æ–‡æœ¬ï¼ˆå¸¦æ ‡ç‚¹ï¼‰æˆ–ç‰¹æ®Šæ ‡è¯†ï¼ˆ__SV_VERIFICATION_FAILED__ ç­‰ï¼‰
        """
        # âš ï¸ åœ¨finalizeå‰æ¸…ç©ºç´¯ç§¯ç¼“å†²åŒºï¼ˆæ¯æ¬¡finalizeåé‡æ–°å¼€å§‹ç´¯ç§¯ï¼‰
        if len(self.experimental_sv_accumulated_buffer) > 0:
            old_accumulated_len = len(self.experimental_sv_accumulated_buffer)
            self.experimental_sv_accumulated_buffer = np.array([], dtype=np.float32)
            logger.info("ğŸ”„ [finalizeå‰æ¸…ç©º] å®éªŒæ€§SVç´¯ç§¯ç¼“å†²åŒºå·²æ¸…ç©º: %dæ ·æœ¬ (%.2fs)", 
                       old_accumulated_len, old_accumulated_len / STREAMING_TARGET_SAMPLE_RATE)
        
        if len(self.audio_buffer) == 0:
            # å¦‚æœaudio_bufferä¸ºç©ºï¼Œä½¿ç”¨ç´¯ç§¯çš„ä¸­é—´ç»“æœ
            final_text = self.accumulated_intermediate_text
            logger.warning("audio_bufferä¸ºç©ºï¼Œä½¿ç”¨ç´¯ç§¯ä¸­é—´ç»“æœ: '%s'", final_text)
            if final_text and final_text.strip():
                return final_text.strip()
            else:
                # audio_bufferä¸ºç©ºä¸”ä¸­é—´ç»“æœä¹Ÿä¸ºç©ºï¼Œè¿”å›ç‰¹æ®Šæ ‡è¯†
                return "__ASR_RESULT_EMPTY__"
        
        
        # 1) æ‹¿åˆ°æœ€ç»ˆè¦è¯†åˆ«çš„éŸ³é¢‘
        audio = self.audio_buffer  # æˆ–è€… np.concatenate(self.audio_chunks)

        # 2) åœ¨è¿›å…¥æ¨¡å‹å‰æ·»åŠ è¯¦ç»†çš„éŸ³é¢‘ç»Ÿè®¡æ—¥å¿—å’ŒæŸåæ£€æµ‹
        sr = 16000  # é¡¹ç›®é‡Œæœ€ç»ˆå†™ wav çš„é‡‡æ ·ç‡
        
        # è¯¦ç»†åˆ†æ audio_bufferï¼šæ£€æŸ¥æ˜¯å¦æœ‰æŸåã€æº¢å‡ºã€NaNç­‰
        if len(audio) > 0:
            # æ£€æŸ¥æ˜¯å¦æœ‰ NaN æˆ– Inf
            has_nan = np.isnan(audio).any()
            has_inf = np.isinf(audio).any()
            if has_nan or has_inf:
                logger.error(f"âŒ [éŸ³é¢‘æŸåæ£€æµ‹] audio_bufferåŒ…å«å¼‚å¸¸å€¼: NaN={has_nan}, Inf={has_inf}")
            
            # æ£€æŸ¥æ˜¯å¦è¶…å‡º [-1, 1] èŒƒå›´
            max_val = np.max(audio)
            min_val = np.min(audio)
            if max_val > 1.0 or min_val < -1.0:
                out_of_range_count = np.sum((audio > 1.0) | (audio < -1.0))
                logger.warning(f"âš ï¸ [éŸ³é¢‘æŸåæ£€æµ‹] audio_bufferè¶…å‡º[-1,1]èŒƒå›´: max={max_val:.6f}, min={min_val:.6f}, è¶…å‡ºèŒƒå›´æ ·æœ¬æ•°={out_of_range_count} (å æ¯”={out_of_range_count/len(audio)*100:.2f}%)")
            
            # æ£€æŸ¥æ•°æ®ç±»å‹
            if audio.dtype != np.float32:
                logger.warning(f"âš ï¸ [éŸ³é¢‘æŸåæ£€æµ‹] audio_bufferæ•°æ®ç±»å‹å¼‚å¸¸: {audio.dtype}, æœŸæœ›: float32")
        
        stats = _log_audio_statistics(audio, sr, "æ¨¡å‹è¾“å…¥å‰(finalize)")
        if stats and stats.get("clipping_ratio", 0) > 0.01:
            _dump_clipped_audio(audio, sr, "finalize")
        
        # ä¿ç•™åŸæœ‰çš„ç®€å•æ—¥å¿—ï¼ˆç”¨äºå…¼å®¹ï¼‰
        duration_s = len(audio) / float(sr) if sr else 0.0
        peak = float(np.max(np.abs(audio))) if len(audio) else 0.0
        
        def _rms(x: np.ndarray) -> float:
            x = x.astype(np.float32)
            return float(np.sqrt(np.mean(x * x)) + 1e-12)
        
        rms = _rms(audio) if len(audio) else 0.0

        logger.info(
            "[FINALIZE][AUDIO] dur=%.3fs, len=%d, sr=%d, peak=%.6f, rms=%.6f",
            duration_s, len(audio), sr, peak, rms
        )
            
        
        # ä¿å­˜ WAV æ–‡ä»¶åˆ°æŒ‚è½½ç›®å½•ï¼ˆæ–¹ä¾¿åœ¨å®¿ä¸»æœºæŸ¥çœ‹ï¼‰
        wav_file_path = None
        try:
            # 1. åˆ›å»ºä¿å­˜ç›®å½•ï¼ˆä½¿ç”¨ Docker æŒ‚è½½çš„ generated ç›®å½•ï¼‰
            from datetime import datetime
            from pathlib import Path
            
            # ä½¿ç”¨æŒ‚è½½çš„ generated ç›®å½•ï¼š/workspace/voice-service/generated
            # å¯¹åº”å®¿ä¸»æœºçš„ ./generated ç›®å½•
            save_dir = Path("/workspace/voice-service/generated/asr_final_audio")
            save_dir.mkdir(parents=True, exist_ok=True)
            
            # 2. ç”Ÿæˆæ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]  # ç²¾ç¡®åˆ°æ¯«ç§’
            wav_filename = f"asr_final_{timestamp}.wav"
            wav_file_path = save_dir / wav_filename
            
            logger.info("ä¿å­˜ WAV æ–‡ä»¶åˆ°: %s (éŸ³é¢‘é•¿åº¦: %.2fs)", 
                       wav_file_path, len(self.audio_buffer) / STREAMING_TARGET_SAMPLE_RATE)
            
            # 3. å°† numpy float32 æ•°ç»„è½¬æ¢ä¸º int16 å¹¶ä¿å­˜ä¸º WAV
            # audio_buffer æ˜¯ float32ï¼ŒèŒƒå›´ [-1, 1]ï¼Œéœ€è¦è½¬æ¢ä¸º int16
            # åªåšå¿…è¦çš„ clamp åˆ° [-1, 1]ï¼Œä¸åšå½’ä¸€åŒ–ï¼Œç¡®ä¿åŠ¨æ€èŒƒå›´ä¸è¢«å‹ç¼©
            
            # è®°å½•å†™å…¥å‰çš„ç»Ÿè®¡
            stats_before_write = _log_audio_statistics(self.audio_buffer, STREAMING_TARGET_SAMPLE_RATE, "å†™å…¥WAVå‰")
            
            audio_clamped = np.clip(self.audio_buffer, -1.0, 1.0)
            
            # æ£€æŸ¥ clamp æ˜¯å¦æœ‰å½±å“ï¼ˆå¦‚æœåŸå§‹æ•°æ®è¶…å‡ºèŒƒå›´ï¼Œclamp ä¼šæ”¹å˜æ•°æ®ï¼‰
            clamped_count = np.sum((self.audio_buffer != audio_clamped))
            if clamped_count > 0:
                logger.warning(f"âš ï¸ [WAVå†™å…¥] clampæ”¹å˜äº†{clamped_count}ä¸ªæ ·æœ¬ (å æ¯”={clamped_count/len(self.audio_buffer)*100:.2f}%)")
                # æ‰¾å‡ºè¢« clamp çš„å€¼
                out_of_range = (self.audio_buffer > 1.0) | (self.audio_buffer < -1.0)
                if np.any(out_of_range):
                    out_max = np.max(self.audio_buffer[out_of_range])
                    out_min = np.min(self.audio_buffer[out_of_range])
                    logger.warning(f"  è¶…å‡ºèŒƒå›´çš„å€¼: max={out_max:.6f}, min={out_min:.6f}")
            
            audio_int16 = (audio_clamped * 32767.0).astype(np.int16)
            
            # æ£€æŸ¥è½¬æ¢åçš„ int16 æ˜¯å¦æº¢å‡º
            int16_max = np.max(audio_int16)
            int16_min = np.min(audio_int16)
            if int16_max > 32767 or int16_min < -32768:
                logger.error(f"âŒ [WAVå†™å…¥] int16è½¬æ¢åæº¢å‡º: max={int16_max}, min={int16_min}")
            
            # ä½¿ç”¨ wave æ¨¡å—ä¿å­˜ WAV æ–‡ä»¶
            with wave.open(str(wav_file_path), 'wb') as wav_file:
                wav_file.setnchannels(1)  # å•å£°é“
                wav_file.setsampwidth(2)  # 16-bit (2 bytes)
                wav_file.setframerate(STREAMING_TARGET_SAMPLE_RATE)  # 16kHz
                wav_file.writeframes(audio_int16.tobytes())
            
            file_size = os.path.getsize(wav_file_path)
            logger.info("âœ… å·²ä¿å­˜éŸ³é¢‘æ–‡ä»¶: %s (å¤§å°: %d å­—èŠ‚, %.2f KB)", 
                       wav_file_path, file_size, file_size / 1024)
            logger.info("ğŸ“ å®¿ä¸»æœºè·¯å¾„: ./generated/asr_final_audio/%s", wav_filename)
            
            # 4. è°ƒç”¨è¯´è¯äººåˆ†ç¦»æ¨¡å‹è¿›è¡Œ ASR è¯†åˆ«å’Œè¯´è¯äººåˆ†ç¦»ï¼ˆä½¿ç”¨å…¨å±€å•ä¾‹ï¼‰
            speaker_diarization_pipeline = get_speaker_diarization_pipeline()
            
            # åˆ†æéŸ³é¢‘é•¿åº¦ï¼Œè°ƒæ•´ batch_size_s å‚æ•°ä»¥ä¼˜åŒ–è¯´è¯äººåˆ†ç¦»
            audio_duration = len(self.audio_buffer) / STREAMING_TARGET_SAMPLE_RATE
            logger.info(f"ğŸ” [è¯´è¯äººåˆ†ç¦»] éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f}s, å‡†å¤‡è°ƒç”¨æ¨¡å‹")
            
            # å¯¹äºè¾ƒçŸ­çš„éŸ³é¢‘ï¼Œä½¿ç”¨æ›´å°çš„ batch_size_s å¯ä»¥æé«˜è¯´è¯äººåˆ†ç¦»çš„ç²¾åº¦
            # åŸå§‹å‚æ•° batch_size_s=300 å¯èƒ½å¤ªå¤§ï¼Œå¯¼è‡´æ‰€æœ‰ç‰‡æ®µè¢«åˆå¹¶åˆ°åŒä¸€ä¸ª batch
            # å°è¯•ä½¿ç”¨æ›´å°çš„å€¼ï¼Œè®©æ¨¡å‹èƒ½å¤Ÿæ›´ç»†è‡´åœ°åˆ†ææ¯ä¸ªç‰‡æ®µ
            if audio_duration < 30:
                batch_size_s = 60  # çŸ­éŸ³é¢‘ä½¿ç”¨æ›´å°çš„ batch
            elif audio_duration < 60:
                batch_size_s = 120
            else:
                batch_size_s = 300  # é•¿éŸ³é¢‘ä½¿ç”¨åŸå§‹å€¼
            
            logger.info(f"ğŸ” [è¯´è¯äººåˆ†ç¦»] ä½¿ç”¨å‚æ•°: batch_size_s={batch_size_s}, batch_size_token_threshold_s=40")
            
            rec_result = speaker_diarization_pipeline(
                str(wav_file_path), 
                batch_size_s=batch_size_s, 
                batch_size_token_threshold_s=40
            )
            
            # 5. è§£æè¯´è¯äººåˆ†ç¦»ç»“æœ
            if not rec_result or not isinstance(rec_result, list) or len(rec_result) == 0:
                logger.error("è¯´è¯äººåˆ†ç¦»æ¨¡å‹è¿”å›ç©ºç»“æœ")
                final_text = "__ASR_RESULT_EMPTY__"
            else:
                # è¯¦ç»†æ‰“å°åŸå§‹è¿”å›ç»“æœç»“æ„ï¼ˆç”¨äºè¯Šæ–­ï¼‰
                logger.info(f"ğŸ” [è¯´è¯äººåˆ†ç¦»] åŸå§‹è¿”å›ç»“æœç±»å‹: {type(rec_result)}, é•¿åº¦: {len(rec_result)}")
                logger.info(f"ğŸ” [è¯´è¯äººåˆ†ç¦»] è¿”å›ç»“æœç»“æ„: {rec_result}")
                
                result_dict = rec_result[0]
                logger.info(f"ğŸ” [è¯´è¯äººåˆ†ç¦»] result_dict ç±»å‹: {type(result_dict)}, é”®: {result_dict.keys() if isinstance(result_dict, dict) else 'N/A'}")
                
                sentence_info_list = result_dict.get('sentence_info', [])
                
                if not sentence_info_list:
                    logger.warning("sentence_info ä¸ºç©ºï¼Œæ— è¯†åˆ«ç»“æœ")
                    logger.info(f"ğŸ” [è¯´è¯äººåˆ†ç¦»] result_dict å®Œæ•´å†…å®¹: {result_dict}")
                    final_text = "__ASR_RESULT_EMPTY__"
                else:
                    logger.info(f"è¯´è¯äººåˆ†ç¦»ç»“æœ: å…± {len(sentence_info_list)} ä¸ªå¥å­")
                    
                    # è¯¦ç»†æ‰“å°æ¯ä¸ªå¥å­çš„å®Œæ•´ä¿¡æ¯ï¼ˆç”¨äºè¯Šæ–­ï¼‰
                    # åŒæ—¶åˆ†ææ—¶é—´æˆ³é—´éš”ï¼Œè¯†åˆ«å¯èƒ½çš„è¯´è¯äººåˆ‡æ¢ç‚¹
                    logger.info(f"ğŸ” [è¯´è¯äººåˆ†ç¦»] å¥å­æ—¶é—´æˆ³åˆ†æï¼ˆç”¨äºè¯†åˆ«è¯´è¯äººåˆ‡æ¢ï¼‰:")
                    prev_end = None
                    for idx, sentence in enumerate(sentence_info_list):
                        logger.info(f"ğŸ” [è¯´è¯äººåˆ†ç¦»] å¥å­ {idx}: {sentence}")
                        logger.info(f"    - ç±»å‹: {type(sentence)}")
                        if isinstance(sentence, dict):
                            logger.info(f"    - é”®: {sentence.keys()}")
                            # å°è¯•æ‰€æœ‰å¯èƒ½çš„ speaker ID å­—æ®µå
                            spk_fields = ['spk', 'speaker', 'speaker_id', 'spk_id', 'spkid']
                            for field in spk_fields:
                                if field in sentence:
                                    logger.info(f"    - {field} = {sentence[field]} (ç±»å‹: {type(sentence[field])})")
                            
                            # åˆ†ææ—¶é—´æˆ³é—´éš”
                            start_ms = sentence.get('start', 0)
                            end_ms = sentence.get('end', 0)
                            start_s = start_ms / 1000.0
                            end_s = end_ms / 1000.0
                            
                            if prev_end is not None:
                                gap_ms = start_ms - prev_end
                                gap_s = gap_ms / 1000.0
                                logger.info(f"    - ä¸å‰ä¸€å¥çš„é—´éš”: {gap_ms}ms ({gap_s:.2f}s)")
                                # å¦‚æœé—´éš”è¾ƒå¤§ï¼ˆ>500msï¼‰ï¼Œå¯èƒ½æ˜¯è¯´è¯äººåˆ‡æ¢
                                if gap_ms > 500:
                                    logger.warning(f"    âš ï¸ æ£€æµ‹åˆ°å¤§é—´éš” ({gap_ms}ms)ï¼Œå¯èƒ½æ˜¯è¯´è¯äººåˆ‡æ¢ç‚¹ï¼Œä½†æ¨¡å‹ä»è¯†åˆ«ä¸ºåŒä¸€speaker")
                            
                            logger.info(f"    - æ—¶é—´èŒƒå›´: {start_ms}ms ({start_s:.2f}s) - {end_ms}ms ({end_s:.2f}s),  duration={end_s-start_s:.2f}s")
                            prev_end = end_ms
                    
                    # 6. æŒ‰ speaker ID åˆ†ç»„ï¼ˆå°è¯•å¤šç§å¯èƒ½çš„å­—æ®µåï¼‰
                    speaker_groups = {}
                    prev_end = None
                    current_speaker_id = 0
                    
                    # åˆ†ææ—¶é—´æˆ³é—´éš”ï¼Œå¦‚æœæ‰€æœ‰å¥å­éƒ½æ˜¯åŒä¸€ä¸ª speakerï¼Œå°è¯•åŸºäºæ—¶é—´é—´éš”æ¨æ–­ä¸åŒçš„è¯´è¯äºº
                    all_same_speaker = True
                    unique_speakers = set()
                    
                    for sentence in sentence_info_list:
                        if not isinstance(sentence, dict):
                            logger.warning(f"âš ï¸ å¥å­ä¸æ˜¯å­—å…¸ç±»å‹: {type(sentence)}, å€¼: {sentence}")
                            continue
                        
                        # å°è¯•å¤šç§å¯èƒ½çš„å­—æ®µåè·å– speaker ID
                        spk_id = None
                        for field in ['spk', 'speaker', 'speaker_id', 'spk_id', 'spkid']:
                            if field in sentence:
                                spk_id = sentence[field]
                                logger.debug(f"ä»å­—æ®µ '{field}' è·å– speaker ID: {spk_id}")
                                break
                        
                        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å€¼ 0
                        if spk_id is None:
                            logger.warning(f"âš ï¸ æœªæ‰¾åˆ° speaker ID å­—æ®µï¼Œå¥å­å†…å®¹: {sentence}")
                            spk_id = 0
                        
                        unique_speakers.add(spk_id)
                        
                        # æ£€æŸ¥æ˜¯å¦éœ€è¦åŸºäºæ—¶é—´é—´éš”é‡æ–°åˆ†é… speaker ID
                        start_ms = sentence.get('start', 0)
                        gap_ms = (start_ms - prev_end) if prev_end is not None else 0
                        
                        # å¦‚æœæ‰€æœ‰å¥å­éƒ½æ˜¯åŒä¸€ä¸ª speakerï¼ˆæ¨¡å‹è¯†åˆ«å¤±è´¥ï¼‰ï¼Œä¸”é—´éš”è¾ƒå¤§ï¼ˆ>800msï¼‰ï¼Œå°è¯•åˆ†é…æ–°çš„ speaker ID
                        # è¿™æ˜¯ä¸€ä¸ªå¯å‘å¼æ–¹æ³•ï¼Œç”¨äºå¼¥è¡¥æ¨¡å‹è¯´è¯äººåˆ†ç¦»çš„ä¸è¶³
                        if len(unique_speakers) == 1 and gap_ms > 800:
                            # é—´éš”è¾ƒå¤§ï¼Œå¯èƒ½æ˜¯ä¸åŒçš„è¯´è¯äººï¼Œåˆ†é…æ–°çš„ speaker ID
                            new_spk_id = current_speaker_id + 1
                            logger.warning(f"âš ï¸ [è¯´è¯äººåˆ†ç¦»å¯å‘å¼] æ£€æµ‹åˆ°å¤§é—´éš” ({gap_ms}ms)ï¼ŒåŸspeaker={spk_id}ï¼Œå°è¯•åˆ†é…æ–°speaker={new_spk_id}")
                            # æ³¨æ„ï¼šè¿™é‡Œä¸ä¿®æ”¹åŸå§‹ sentenceï¼Œè€Œæ˜¯ä½¿ç”¨æ–°çš„ ID è¿›è¡Œåˆ†ç»„
                            spk_id = new_spk_id
                            current_speaker_id = new_spk_id
                        else:
                            current_speaker_id = max(current_speaker_id, spk_id)
                        
                        prev_end = sentence.get('end', 0)
                        
                        # ç¡®ä¿ spk_id æ˜¯å¯å“ˆå¸Œçš„ç±»å‹ï¼ˆè½¬æ¢ä¸º int æˆ– strï¼‰
                        if isinstance(spk_id, (int, str)):
                            spk_id_key = spk_id
                        else:
                            logger.warning(f"âš ï¸ Speaker ID ç±»å‹å¼‚å¸¸: {type(spk_id)}, å€¼: {spk_id}, è½¬æ¢ä¸ºå­—ç¬¦ä¸²")
                            spk_id_key = str(spk_id)
                        
                        if spk_id_key not in speaker_groups:
                            speaker_groups[spk_id_key] = []
                        speaker_groups[spk_id_key].append(sentence)
                        
                        logger.debug(f"å°†å¥å­æ·»åŠ åˆ° Speaker {spk_id_key}: æ–‡æœ¬='{sentence.get('text', 'N/A')}', å¼€å§‹={sentence.get('start', 'N/A')}, ç»“æŸ={sentence.get('end', 'N/A')}")
                    
                    # å¦‚æœåº”ç”¨äº†å¯å‘å¼è§„åˆ™ï¼Œè®°å½•è­¦å‘Š
                    if len(unique_speakers) == 1 and len(speaker_groups) > 1:
                        logger.warning(f"âš ï¸ [è¯´è¯äººåˆ†ç¦»å¯å‘å¼] æ¨¡å‹è¯†åˆ«åˆ° {len(unique_speakers)} ä¸ªå”¯ä¸€speakerï¼Œä½†åŸºäºæ—¶é—´é—´éš”æ¨æµ‹ä¸º {len(speaker_groups)} ä¸ªä¸åŒè¯´è¯äºº")
                    
                    # å¯¹æ¯ä¸ª speaker çš„åˆ†æ®µæŒ‰æ—¶é—´æˆ³æ’åº
                    logger.info(f"ğŸ” [è¯´è¯äººåˆ†ç¦»] è¯†åˆ«åˆ°çš„ Speaker æ•°é‡: {len(speaker_groups)}")
                    for spk_id in speaker_groups:
                        speaker_groups[spk_id].sort(key=lambda x: x.get('start', 0))
                        logger.info(f"Speaker {spk_id}: {len(speaker_groups[spk_id])} ä¸ªå¥å­")
                        # æ‰“å°æ¯ä¸ªå¥å­çš„è¯¦ç»†ä¿¡æ¯
                        for idx, sent in enumerate(speaker_groups[spk_id]):
                            logger.info(f"  - å¥å­ {idx}: æ–‡æœ¬='{sent.get('text', 'N/A')}', "
                                      f"æ—¶é—´=[{sent.get('start', 'N/A'):.2f}s, {sent.get('end', 'N/A'):.2f}s], "
                                      f"speakerå­—æ®µ={sent.get('spk', 'N/A')}/{sent.get('speaker', 'N/A')}/{sent.get('speaker_id', 'N/A')}")
                    
                    # 7. SV å£°çº¹éªŒè¯ï¼ˆå¦‚æœå¯ç”¨ä¸”å·²æ³¨å†Œï¼Œä¸”å·²é€šè¿‡ KWS æ¿€æ´»ï¼‰
                    if self.use_speaker_verification and self.is_enrolled and self.enroll_audio_path:
                        if not self.is_activated:
                            logger.warning("âš ï¸ æœªæ¿€æ´»çŠ¶æ€ä¸‹ä¸å…è®¸å£°çº¹éªŒè¯ï¼ˆå®‰å…¨ä¿æŠ¤ï¼‰ï¼Œè·³è¿‡ ASR è¯†åˆ«")
                            final_text = "__SV_NOT_ACTIVATED__"
                        else:
                            speaker_scores = {}
                            temp_files_to_cleanup = []  # è®°å½•éœ€è¦æ¸…ç†çš„ä¸´æ—¶æ–‡ä»¶
                            
                            try:
                                for spk_id, sentences in speaker_groups.items():
                                    # æå–è¯¥ speaker çš„éŸ³é¢‘
                                    speaker_audio = self._extract_speaker_audio(self.audio_buffer, sentences)
                                    
                                    if len(speaker_audio) == 0:
                                        logger.warning(f"âš ï¸ Speaker {spk_id} éŸ³é¢‘ä¸ºç©ºï¼Œè·³è¿‡éªŒè¯")
                                        continue
                                    
                                    # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
                                    temp_audio_path = self._save_temp_speaker_audio(speaker_audio, spk_id)
                                    temp_files_to_cleanup.append(temp_audio_path)
                                    
                                    # SV éªŒè¯ï¼ˆè¿”å›åˆ†æ•°ï¼‰
                                    is_verified, score = await self._verify_speaker_with_score(temp_audio_path)
                                    speaker_scores[spk_id] = {
                                        'score': score if score is not None else -1.0,
                                        'is_verified': is_verified,
                                        'sentences': sentences
                                    }
                                    logger.info(f"ğŸ” Speaker {spk_id} SVéªŒè¯: is_verified={is_verified}, score={score if score is not None else 'N/A'}")
                                
                                # 8. é€‰æ‹©ç­–ç•¥
                                if len(speaker_scores) == 0:
                                    logger.warning("æ‰€æœ‰ speaker éªŒè¯å¤±è´¥æˆ–éŸ³é¢‘ä¸ºç©º")
                                    final_text = "__SV_VERIFICATION_FAILED__"
                                elif len(speaker_scores) == 1:
                                    # å•ä¸ª speaker
                                    spk_id = list(speaker_scores.keys())[0]
                                    if speaker_scores[spk_id]['is_verified']:
                                        # æ‹¼æ¥æ–‡æœ¬
                                        final_text = ''.join([s['text'] for s in speaker_scores[spk_id]['sentences']])
                                        logger.info(f"âœ… å•ä¸ª Speaker {spk_id} éªŒè¯é€šè¿‡ï¼Œè¿”å›æ–‡æœ¬")
                                    else:
                                        logger.warning(f"âŒ å•ä¸ª Speaker {spk_id} éªŒè¯å¤±è´¥ (score={speaker_scores[spk_id]['score']})")
                                        final_text = "__SV_VERIFICATION_FAILED__"
                                else:
                                    # å¤šä¸ª speakerï¼šé€‰æ‹©åˆ†æ•°æœ€é«˜çš„
                                    best_spk_id = max(speaker_scores.keys(), key=lambda k: speaker_scores[k]['score'])
                                    best_score = speaker_scores[best_spk_id]['score']
                                    
                                    if best_score >= self.sv_threshold:
                                        # åˆ†æ•°æœ€é«˜çš„é€šè¿‡é˜ˆå€¼ï¼Œè¿”å›è¯¥ speaker çš„æ–‡æœ¬
                                        final_text = ''.join([s['text'] for s in speaker_scores[best_spk_id]['sentences']])
                                        logger.info(f"âœ… é€‰æ‹© Speaker {best_spk_id} (åˆ†æ•°: {best_score:.4f}, é˜ˆå€¼: {self.sv_threshold})")
                                        
                                        # è®°å½•æ‰€æœ‰ speaker çš„åˆ†æ•°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                                        for spk_id, info in speaker_scores.items():
                                            logger.debug(f"  Speaker {spk_id}: score={info['score']:.4f}, is_verified={info['is_verified']}")
                                    else:
                                        # æ‰€æœ‰ speaker éƒ½ä½äºé˜ˆå€¼
                                        logger.warning(f"âš ï¸ æ‰€æœ‰ speaker åˆ†æ•°éƒ½ä½äºé˜ˆå€¼ (æœ€é«˜: {best_score:.4f} < {self.sv_threshold})")
                                        final_text = "__SV_VERIFICATION_FAILED__"
                                
                            finally:
                                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                                for temp_file in temp_files_to_cleanup:
                                    try:
                                        if os.path.exists(temp_file):
                                            os.remove(temp_file)
                                            logger.debug(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_file}")
                                    except Exception as e:
                                        logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {temp_file}, {e}")
                    else:
                        # æœªå¯ç”¨ SVï¼Œæ‹¼æ¥æ‰€æœ‰ speaker çš„æ–‡æœ¬ï¼ˆæŒ‰ speaker ID æ’åºï¼‰
                        all_texts = []
                        for spk_id in sorted(speaker_groups.keys()):
                            sentences = speaker_groups[spk_id]
                            text = ''.join([s['text'] for s in sentences])
                            all_texts.append(text)
                        final_text = ''.join(all_texts)
                        logger.info(f"æœªå¯ç”¨SVï¼Œè¿”å›æ‰€æœ‰ speaker çš„æ–‡æœ¬: {len(speaker_groups)} ä¸ª speaker")
            
        except Exception as e:
            logger.error("æœ€ç»ˆè¯†åˆ«å¼‚å¸¸: %s", e, exc_info=True)
            # å¦‚æœæœ€ç»ˆè¯†åˆ«å¤±è´¥ï¼Œè¿”å›ç©ºç»“æœæ ‡è¯†
            final_text = "__ASR_RESULT_EMPTY__"
        
        finally:
            # æ³¨æ„ï¼šWAV æ–‡ä»¶ä¿ç•™åœ¨æŒ‚è½½ç›®å½•ä¸­ï¼Œä¸åˆ é™¤ï¼Œæ–¹ä¾¿åœ¨å®¿ä¸»æœºæŸ¥çœ‹
            # å¦‚æœéœ€è¦æ¸…ç†æ—§æ–‡ä»¶ï¼Œå¯ä»¥å®šæœŸæ¸…ç† ./generated/asr_final_audio/ ç›®å½•
            pass
        
        # æœ€åæ£€æŸ¥ï¼šå¦‚æœfinal_textä¸ºç©ºï¼Œè¿”å›ç‰¹æ®Šæ ‡è¯†ï¼Œé¿å…è¿”å›ç©ºå­—ç¬¦ä¸²
        if not final_text or not final_text.strip():
            return "__ASR_RESULT_EMPTY__"
        
        # âš ï¸ æ£€æŸ¥ï¼šå¦‚æœç»“æœåªåŒ…å«æ ‡ç‚¹ç¬¦å·å’Œè¯­æ°”è¯ï¼Œè§†ä¸ºæ— æ•ˆç»“æœ
        cleaned_text = final_text.strip()
        
        # å®šä¹‰è¯­æ°”è¯é›†åˆï¼ˆåŒ…æ‹¬å•ä¸ªå’Œé‡å¤çš„è¯­æ°”è¯ï¼‰
        interjections = {"å—¯", "å“ˆ", "å“¼", "å™—", "ç °", "å‘€", "å—·", "å•Š", "å“¦", "é¢", "å‘ƒ", "è¯¶", "å”‰", "å“"}
        
        # ç§»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·å’Œç©ºç™½å­—ç¬¦ï¼Œåªä¿ç•™æ±‰å­—å’Œå­—æ¯æ•°å­—
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼ˆä¿ç•™ä¸­æ–‡å­—ç¬¦ã€å­—æ¯ã€æ•°å­—ï¼‰
        text_without_punct = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹ã€ˆã€‰ã€Œã€ã€ã€ã€”ã€•ã€–ã€—â€¦â€”ï½Â·\s]', '', cleaned_text)
        
        # æ£€æŸ¥æ˜¯å¦åªåŒ…å«è¯­æ°”è¯
        if text_without_punct:
            # å¦‚æœå»é™¤æ ‡ç‚¹åè¿˜æœ‰å†…å®¹ï¼Œæ£€æŸ¥æ˜¯å¦å…¨æ˜¯è¯­æ°”è¯
            # å°†æ–‡æœ¬æŒ‰å­—ç¬¦åˆ†å‰²ï¼Œæ£€æŸ¥æ¯ä¸ªå­—ç¬¦æ˜¯å¦éƒ½æ˜¯è¯­æ°”è¯
            # è¿™æ ·å¯ä»¥è¿‡æ»¤"å—¯å—¯"ã€"å“ˆå“ˆ"ã€"å—¯å—¯å—¯"ç­‰é‡å¤è¯­æ°”è¯
            chars = list(text_without_punct)
            if all(char in interjections for char in chars):
                logger.info("ğŸ”§ [æ— æ•ˆç»“æœè¿‡æ»¤] è¯†åˆ«ç»“æœåªåŒ…å«è¯­æ°”è¯å’Œæ ‡ç‚¹: '%s' -> è§†ä¸ºç©ºç»“æœ", cleaned_text)
                return "__ASR_RESULT_EMPTY__"
        else:
            # å»é™¤æ ‡ç‚¹åä¸ºç©ºï¼Œè¯´æ˜åªæœ‰æ ‡ç‚¹ç¬¦å·
            logger.info("ğŸ”§ [æ— æ•ˆç»“æœè¿‡æ»¤] è¯†åˆ«ç»“æœåªåŒ…å«æ ‡ç‚¹ç¬¦å·: '%s' -> è§†ä¸ºç©ºç»“æœ", cleaned_text)
            return "__ASR_RESULT_EMPTY__"
        
        return cleaned_text
    
    def _init_sv_pipeline(self):
        """å»¶è¿Ÿåˆå§‹åŒ–å£°çº¹è¯†åˆ«æ¨¡å‹ï¼ˆä¼˜å…ˆä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼‰"""
        if self.sv_pipeline is None:
            try:
                from modelscope.pipelines import pipeline
                
                # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼Œé¿å…ä»ModelScopeä¸‹è½½
                # å®¹å™¨å†…è·¯å¾„ï¼š/workspace/models/damo/speech_campplus_sv_zh-cn_16k-common
                # æœ¬åœ°å¼€å‘è·¯å¾„ï¼šapp/services/models/damo/speech_campplus_sv_zh-cn_16k-common
                sv_model_id = 'iic/speech_campplus_sv_zh-cn_16k-common'
                sv_model_revision = 'v1.0.0'
                
                # å°è¯•å®¹å™¨å†…è·¯å¾„
                container_path = "/workspace/models/damo/speech_campplus_sv_zh-cn_16k-common"
                # å°è¯•æœ¬åœ°å¼€å‘è·¯å¾„
                current_dir = os.path.dirname(os.path.abspath(__file__))
                local_path = os.path.join(current_dir, "models", "damo", "speech_campplus_sv_zh-cn_16k-common")
                
                sv_model_path = None
                if os.path.exists(container_path):
                    sv_model_path = container_path
                    logger.info("âœ… ä½¿ç”¨å®¹å™¨å†…SVæ¨¡å‹è·¯å¾„: %s", container_path)
                elif os.path.exists(local_path):
                    sv_model_path = local_path
                    logger.info("âœ… ä½¿ç”¨æœ¬åœ°SVæ¨¡å‹è·¯å¾„: %s", local_path)
                else:
                    logger.warning("âš ï¸ æœ¬åœ°SVæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨æ¨¡å‹IDï¼ˆå¯èƒ½ä»ModelScopeä¸‹è½½ï¼‰: %s", sv_model_id)
                
                # ModelScope pipeline æ”¯æŒç›´æ¥ä¼ é€’æœ¬åœ°è·¯å¾„ä½œä¸º model å‚æ•°
                model_param = sv_model_path if sv_model_path else sv_model_id
                self.sv_pipeline = pipeline(
                    task='speaker-verification',
                    model=model_param,
                    model_revision=sv_model_revision if not sv_model_path else None  # æœ¬åœ°è·¯å¾„ä¸éœ€è¦revision
                )
                logger.info("âœ… å£°çº¹è¯†åˆ«æ¨¡å‹å·²åŠ è½½ (model=%s)", model_param)
            except Exception as e:
                logger.error(f"âŒ å£°çº¹è¯†åˆ«æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}", exc_info=True)
                raise
        return self.sv_pipeline
    
    
    def _extract_speaker_audio(self, audio_np: np.ndarray, sentence_list: List[Dict], sample_rate: int = 16000) -> np.ndarray:
        """
        ä»å®Œæ•´éŸ³é¢‘ä¸­æå–å¹¶æ‹¼æ¥æŸä¸ª speaker çš„æ‰€æœ‰åˆ†æ®µ
        
        Args:
            audio_np: å®Œæ•´éŸ³é¢‘ï¼ˆnumpy float32æ•°ç»„ï¼‰
            sentence_list: è¯¥ speaker çš„æ‰€æœ‰å¥å­ï¼ˆå·²æŒ‰æ—¶é—´æˆ³æ’åºï¼‰
            sample_rate: é‡‡æ ·ç‡ï¼ˆé»˜è®¤16000ï¼‰
        
        Returns:
            æ‹¼æ¥åçš„éŸ³é¢‘ç‰‡æ®µï¼ˆnumpy float32æ•°ç»„ï¼‰
        """
        segments = []
        for sentence in sentence_list:
            start_ms = sentence.get('start', 0)
            end_ms = sentence.get('end', 0)
            
            # è¾¹ç•Œæ£€æŸ¥
            if start_ms < 0 or end_ms <= start_ms:
                logger.warning(f"âš ï¸ æ— æ•ˆæ—¶é—´æˆ³: start={start_ms}ms, end={end_ms}ms")
                continue
            
            # è½¬æ¢ä¸ºé‡‡æ ·ç‚¹
            start_sample = int(start_ms * sample_rate / 1000)
            end_sample = int(end_ms * sample_rate / 1000)
            
            # è¾¹ç•Œæ£€æŸ¥ï¼ˆé¿å…è¶Šç•Œï¼‰
            start_sample = max(0, min(start_sample, len(audio_np)))
            end_sample = max(start_sample, min(end_sample, len(audio_np)))
            
            if start_sample < end_sample:
                segment = audio_np[start_sample:end_sample]
                segments.append(segment)
                logger.debug(f"æå–åˆ†æ®µ: {start_ms}ms-{end_ms}ms ({start_sample}-{end_sample}æ ·æœ¬, {len(segment)/sample_rate:.2f}s)")
        
        if not segments:
            return np.array([], dtype=np.float32)
        
        # æ‹¼æ¥æ‰€æœ‰åˆ†æ®µ
        concatenated = np.concatenate(segments)
        logger.debug(f"æ‹¼æ¥å®Œæˆ: {len(segments)}ä¸ªåˆ†æ®µ, æ€»é•¿åº¦={len(concatenated)/sample_rate:.2f}s")
        return concatenated
    
    def _save_temp_speaker_audio(self, audio_np: np.ndarray, spk_id: int) -> str:
        """
        ä¿å­˜ speaker çš„ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ç”¨äº SV éªŒè¯
        
        Args:
            audio_np: éŸ³é¢‘æ•°æ®ï¼ˆnumpy float32æ•°ç»„ï¼‰
            spk_id: speaker ID
        
        Returns:
            ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        """
        from datetime import datetime
        from pathlib import Path
        
        save_dir = Path("/workspace/voice-service/generated/sv_speaker_segments")
        save_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
        temp_filename = f"speaker_{spk_id}_{timestamp}.wav"
        temp_path = save_dir / temp_filename
        
        # è½¬æ¢ä¸º int16 å¹¶ä¿å­˜
        # åªåšå¿…è¦çš„ clamp åˆ° [-1, 1]ï¼Œä¸åšå½’ä¸€åŒ–ï¼Œç¡®ä¿åŠ¨æ€èŒƒå›´ä¸è¢«å‹ç¼©
        audio_clamped = np.clip(audio_np, -1.0, 1.0)
        audio_int16 = (audio_clamped * 32767.0).astype(np.int16)
        with wave.open(str(temp_path), 'wb') as wav_file:
            wav_file.setnchannels(1)
            wav_file.setsampwidth(2)
            wav_file.setframerate(STREAMING_TARGET_SAMPLE_RATE)
            wav_file.writeframes(audio_int16.tobytes())
        
        logger.debug(f"ä¿å­˜ Speaker {spk_id} ä¸´æ—¶éŸ³é¢‘: {temp_path} ({len(audio_np)/STREAMING_TARGET_SAMPLE_RATE:.2f}s)")
        return str(temp_path)
    
    async def _verify_speaker_with_score(self, current_audio_path: str) -> Tuple[bool, Optional[float]]:
        """å£°çº¹éªŒè¯ï¼šè¿”å›éªŒè¯ç»“æœå’Œåˆ†æ•°"""
        try:
            sv_pipeline = self._init_sv_pipeline()
            
            # è°ƒç”¨å£°çº¹éªŒè¯
            sv_res = sv_pipeline([self.enroll_audio_path, current_audio_path])
            
            # è§£æéªŒè¯ç»“æœ
            verdict_text, score = self._parse_sv_result(sv_res)
            
            # åˆ¤å®šæ˜¯å¦é€šè¿‡
            is_verified = self._is_sv_verified(verdict_text, score)
            
            if is_verified:
                logger.info(f"âœ… å£°çº¹éªŒè¯é€šè¿‡ (text={verdict_text}, score={score})")
            else:
                logger.warning(f"âŒ å£°çº¹éªŒè¯å¤±è´¥ (text={verdict_text}, score={score})")
            
            return is_verified, score
            
        except Exception as e:
            logger.error(f"âŒ å£°çº¹éªŒè¯å¼‚å¸¸ï¼š{e}", exc_info=True)
            return False, None
    
    def _save_enroll_sample(self) -> Optional[str]:
        """ä¿å­˜æ³¨å†Œæ ·æœ¬ä¸º WAV æ–‡ä»¶"""
        try:
            from datetime import datetime
            from pathlib import Path
            
            save_dir = Path("/workspace/voice-service/generated/sv_enroll")
            save_dir.mkdir(parents=True, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
            enroll_path = save_dir / f"enroll_{timestamp}.wav"
            
            # è½¬æ¢ä¸º int16 å¹¶ä¿å­˜
            # åªåšå¿…è¦çš„ clamp åˆ° [-1, 1]ï¼Œä¸åšå½’ä¸€åŒ–ï¼Œç¡®ä¿åŠ¨æ€èŒƒå›´ä¸è¢«å‹ç¼©
            audio_clamped = np.clip(self.enroll_audio_buffer, -1.0, 1.0)
            audio_int16 = (audio_clamped * 32767.0).astype(np.int16)
            with wave.open(str(enroll_path), 'wb') as wav_file:
                wav_file.setnchannels(1)
                wav_file.setsampwidth(2)
                wav_file.setframerate(STREAMING_TARGET_SAMPLE_RATE)
                wav_file.writeframes(audio_int16.tobytes())
            
            logger.info(f"âœ… æ³¨å†Œæ ·æœ¬å·²ä¿å­˜ï¼š{enroll_path}")
            return str(enroll_path)
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ³¨å†Œæ ·æœ¬å¤±è´¥ï¼š{e}", exc_info=True)
            return None
    
    def _verify_speaker_sync(self, audio_buffer: np.ndarray, buffer_type: str = "chunk") -> bool:
        """å®éªŒæ€§ï¼šåŒæ­¥ç‰ˆæœ¬çš„å£°çº¹éªŒè¯ï¼ˆç”¨äºchunkçº§åˆ«çš„å®æ—¶éªŒè¯ï¼‰
        
        å‚æ•°:
            audio_buffer: è¦éªŒè¯çš„éŸ³é¢‘ç¼“å†²åŒºï¼ˆnumpyæ•°ç»„ï¼‰
            buffer_type: ç¼“å†²åŒºç±»å‹ï¼ˆ"chunk" æˆ– "accumulated"ï¼‰ï¼Œç”¨äºæ—¥å¿—æ ‡è¯†
        
        æ³¨æ„ï¼šè¿™æ˜¯å®éªŒæ€§åŠŸèƒ½ï¼Œç”¨äºåœ¨process_chunkä¸­å®æ—¶éªŒè¯å£°çº¹
        """
        if len(audio_buffer) == 0:
            logger.warning(f"ğŸ”¬ [å®éªŒæ€§SVéªŒè¯] {buffer_type}ç¼“å†²åŒºä¸ºç©ºï¼Œè·³è¿‡éªŒè¯")
            return False
        
        if not self.enroll_audio_path or not os.path.exists(self.enroll_audio_path):
            logger.warning(f"ğŸ”¬ [å®éªŒæ€§SVéªŒè¯] æ³¨å†Œæ ·æœ¬ä¸å­˜åœ¨ï¼Œè·³è¿‡éªŒè¯")
            return False
        
        try:
            # 1. ä¿å­˜å®éªŒæ€§éªŒè¯ç¼“å†²åŒºä¸ºä¸´æ—¶æ–‡ä»¶
            from datetime import datetime
            from pathlib import Path
            import wave
            
            save_dir = Path("/workspace/voice-service/generated/sv_experimental")
            save_dir.mkdir(parents=True, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
            temp_audio_path = save_dir / f"experimental_sv_{buffer_type}_{timestamp}.wav"
            
            # è½¬æ¢ä¸º int16 å¹¶ä¿å­˜
            # åªåšå¿…è¦çš„ clamp åˆ° [-1, 1]ï¼Œä¸åšå½’ä¸€åŒ–ï¼Œç¡®ä¿åŠ¨æ€èŒƒå›´ä¸è¢«å‹ç¼©
            audio_clamped = np.clip(audio_buffer, -1.0, 1.0)
            audio_int16 = (audio_clamped * 32767.0).astype(np.int16)
            with wave.open(str(temp_audio_path), 'wb') as wav_file:
                wav_file.setnchannels(1)
                wav_file.setsampwidth(2)
                wav_file.setframerate(STREAMING_TARGET_SAMPLE_RATE)
                wav_file.writeframes(audio_int16.tobytes())
            
            # 2. åˆå§‹åŒ–SV pipelineï¼ˆåŒæ­¥ï¼‰
            sv_pipeline = self._init_sv_pipeline()
            
            # 3. è°ƒç”¨å£°çº¹éªŒè¯
            sv_res = sv_pipeline([self.enroll_audio_path, str(temp_audio_path)])
            
            # 4. è§£æéªŒè¯ç»“æœ
            verdict_text, score = self._parse_sv_result(sv_res)
            
            # 5. åˆ¤å®šæ˜¯å¦é€šè¿‡
            is_verified = self._is_sv_verified(verdict_text, score)
            
            # 6. è¾“å‡ºè¯¦ç»†çš„éªŒè¯ä¿¡æ¯ï¼ˆç”¨äºæµ‹è¯•chunkçº§åˆ«éªŒè¯çš„å¯è¡Œæ€§ï¼‰
            buffer_duration = len(audio_buffer) / STREAMING_TARGET_SAMPLE_RATE
            logger.info(
                f"ğŸ”¬ [å®éªŒæ€§SVéªŒè¯] {buffer_type}éªŒè¯è¯¦æƒ…: "
                "ç»“æœ=%s, verdict=%s, score=%.5f, é˜ˆå€¼=%.2f, "
                "éŸ³é¢‘é•¿åº¦=%.2fs, æ³¨å†Œæ ·æœ¬=%s, å½“å‰éŸ³é¢‘=%s",
                "é€šè¿‡" if is_verified else "å¤±è´¥",
                verdict_text if verdict_text else "N/A",
                score if score is not None else float('nan'),
                self.sv_threshold,
                buffer_duration,
                self.enroll_audio_path,
                str(temp_audio_path)
            )
            
            # 7. æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¯é€‰ï¼Œä¿ç•™ç”¨äºè°ƒè¯•ï¼‰
            # os.remove(str(temp_audio_path))
            
            return is_verified
            
        except Exception as e:
            logger.error(f"âŒ [å®éªŒæ€§SVéªŒè¯] éªŒè¯å¼‚å¸¸ï¼š{e}", exc_info=True)
            return False
    
    async def _verify_speaker(self, current_audio_path: str) -> bool:
        """å£°çº¹éªŒè¯ï¼šæ¯”å¯¹æ³¨å†Œæ ·æœ¬å’Œå½“å‰éŸ³é¢‘"""
        try:
            sv_pipeline = self._init_sv_pipeline()
            
            # è°ƒç”¨å£°çº¹éªŒè¯
            sv_res = sv_pipeline([self.enroll_audio_path, current_audio_path])
            
            # è§£æéªŒè¯ç»“æœ
            verdict_text, score = self._parse_sv_result(sv_res)
            
            # åˆ¤å®šæ˜¯å¦é€šè¿‡
            is_verified = self._is_sv_verified(verdict_text, score)
            
            if is_verified:
                logger.info(f"âœ… å£°çº¹éªŒè¯é€šè¿‡ (text={verdict_text}, score={score})")
            else:
                logger.warning(f"âŒ å£°çº¹éªŒè¯å¤±è´¥ (text={verdict_text}, score={score})")
            
            return is_verified
            
        except Exception as e:
            logger.error(f"âŒ å£°çº¹éªŒè¯å¼‚å¸¸ï¼š{e}", exc_info=True)
            # éªŒè¯å¼‚å¸¸æ—¶ï¼Œå¯ä»¥é€‰æ‹©ç»§ç»­ ASR æˆ–è·³è¿‡
            # è¿™é‡Œé€‰æ‹©è·³è¿‡ï¼ˆæ›´å®‰å…¨ï¼‰
            return False
    
    def _parse_sv_result(self, sv_res: Any) -> Tuple[Optional[str], Optional[float]]:
        """è§£æå£°çº¹éªŒè¯ç»“æœ"""
        verdict_text = None
        score = None
        
        if isinstance(sv_res, dict):
            verdict_text = sv_res.get('text')
            for k in ('score', 'similarity', 'sim'):
                if k in sv_res:
                    try:
                        score = float(sv_res[k])
                        break
                    except Exception:
                        pass
        elif isinstance(sv_res, (list, tuple)) and sv_res:
            first = sv_res[0]
            if isinstance(first, dict):
                verdict_text = first.get('text')
                for k in ('score', 'similarity', 'sim'):
                    if k in first:
                        try:
                            score = float(first[k])
                            break
                        except Exception:
                            pass
            elif isinstance(first, str):
                verdict_text = first
            elif isinstance(first, (int, float)):
                score = float(first)
        
        if isinstance(verdict_text, str):
            verdict_text = verdict_text.strip().lower()
        
        return verdict_text, score
    

    def _is_sv_verified(self, verdict_text, score):
        if score is None:
            return False

        # å¼ºé€šè¿‡
        if score >= self.sv_threshold:
            return True

        # å¼ºæ‹’ç»
        if score < self.sv_threshold:
            return False

        # æ¨¡ç³ŠåŒºé—´ï¼Œç”¨ text è¾…åŠ©
        if verdict_text == 'yes':
            return True
        if verdict_text == 'no':
            return False

        return False
