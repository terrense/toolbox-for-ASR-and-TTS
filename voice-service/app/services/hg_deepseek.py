from openai import OpenAI
from typing import List, Dict, Any, Callable, Optional
import time
import re
import json
import logging
import os
import traceback

logger = logging.getLogger(__name__)
# deepseek_with_context_no_heuristic.py

# å°è¯•å¯¼å…¥ httpxï¼ˆç”¨äºå¼ºåˆ¶ HTTP/1.1ï¼‰
try:
    import httpx
except Exception:
    httpx = None

# ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®ï¼ˆä¸å†ä¾èµ–é…ç½®æ–‡ä»¶ï¼‰
ai_model_config = {
    'api_key': os.getenv('AI_MODEL_API_KEY', 'GHVHTT9meytovgGA3eAotzAfmeSE_5CLA1NVJ0cOWPVEGWc8sw'),
    'base_url': os.getenv('AI_MODEL_BASE_URL', 'http://172.24.27.11:5105/v1'),
    'model_name': os.getenv('AI_MODEL_MODEL_NAME', 'Qwen3-32B')
}

logger.info("é…ç½®åŠ è½½å®Œæˆ:")
logger.info("  API Key: %s...", ai_model_config.get('api_key', 'æœªè®¾ç½®')[:20])
logger.info("  Base URL: %s", ai_model_config.get('base_url', 'æœªè®¾ç½®'))
logger.info("  Model Name: %s", ai_model_config.get('model_name', 'æœªè®¾ç½®'))
print("="*50)


#====== é…ç½®åŒºï¼ˆAPI_KEYï¼‰ ======
client = OpenAI(
    base_url='http://172.24.27.11:4457/v1',
    api_key='eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIyZWIwYjliZGZkNGI0NjJhOTczM2UzODAyNDM1ZWZlYyIsIm1ldGhvZHMiOiJQT1NUIiwiaWF0IjoiMTc1NDUzMTgyMiIsImV4cCI6IjE3NTQ1MzU0MjIifQ.JiNIZPgvfAFQIl0shSghYJQe1Sf_xzANTcVlFCK97EWNNp8wpXx9MSlchVAJXSyER-3_Z_0nAgN5dNGrTO8zyWUkUwJZ4qdrXLbGcANCuyOaK2UHfaRJFVhKwWYU32B1sj16dWvTzd6OQ-xUxFSH2RH4kDAyy1sYYUsgByFZELVwgZNmL6MqbRgYbtFmR8CnLQ6hutkTLfn9tlIxpahW1JJCWBXUphoECB4RfmwcmAh0Khv5F030TFcRc-UsLt7qLA-v2-34ITXZwrZkLBFAtf75_00Q9TNEyX1YHnvylKtzxVL8uwV4gITLB7zsqhf5QMGK1s1BaUNspQUh-owCVA',  # å¯†é’¥
)
MODEL = 'ds-v3-085'

# -------qwen-------
# client = OpenAI(
#     # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx",
#     base_url='https://dashscope.aliyuncs.com/compatible-mode/v1',
#     api_key='sk-56690a31e6cf4ff3a466b7d2dccda6bc',
# )
# #MODEL = 'qwen-plus'
# MODEL = 'qwen2.5-32b-instruct'

# client = OpenAI(
#     api_key='eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIyZWIwYjliZGZkNGI0NjJhOTczM2UzODAyNDM1ZWZlYyIsIm1ldGhvZHMiOiJQT1NUIiwiaWF0IjoiMTc1NDAxNzc3NCIsImV4cCI6IjE3NTQwMjEzNzQifQ.zlPOn8hmjzyzW9uh2e7Z0Uw1P4nHugz7JeEQeY0yiQuxARPoD5uhQi41NFYIZQZZJ0oErWWw0hZ1iDAWhnW1ICxXAaxqdCa0t130TYnPHNP6tdrqoMXCfShjd7JOKMBPb7wqFO4MgddGtLyixW2aPgD32FSBsTEAKQYIJaMOxbgwexsQzotbwe54-w4BfGKHn9WrQSDAVqzI-T1zVpyaRU6e9gaQjpv8mYKQ51hwhkl_xJCP6qSfHwJOTgpH4kVvefckRl56OgzFsRBHIRJuUXV3QpkDEcocBAxNzANMwuhBx4KCR1NDSZJyLg1r8ija5ejR3TaHrBtknJiX220TFg',  # å¯†é’¥
#     base_url='http://172.24.27.11:5104/v1/chat/completions',
# )
# MODEL = 'Qwen2.5-VL-72B-Instruct-hg'

# ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
client = OpenAI(
    api_key=ai_model_config.get('api_key', 'eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIyZWIwYjliZGZkNGI0NjJhOTczM2UzODAyNDM1ZWZlYyIsIm1ldGhvZHMiOiJQT1NUIiwiaWF0IjoiMTc1Nzk4ODA3MyIsImV4cCI6IjE3NTc5OTE2NzMifQ.mQ-g1g5ICkZ_8_kFEx-AABgPvYGrtGOsZCcz0ad6pSicmw6H6SMLFl6iq3-Q9WERN9GK70jIzssQdOlsuw7IFz4pd52hwL5n73Ha8ujAQndLMvlCaqt7gaZGI7E9NqqwY6yba3O3IBMiG7rqxp50kACBw0U4XmZZ7LV0RA--3jRCUF5pv5-ksBAVMb6d-yL5HEDp9FHgggfV_1EGC3hxjw-E4lUyvCuzUjMWNj9NNqa9Sy7pJSPNfeLCgg1QOFTKyJlUxb_Snu0GZ3NAtYBi8Woka-18DXswhZf7FNyPxz5Nlq0yQXveqfxyujaFAMRDUYolGn7bZnyQbQbf3QdGVw'),
    base_url=ai_model_config.get('base_url', 'http://172.24.27.11:5105/v1'),
)
MODEL = ai_model_config.get('model_name', 'Qwen3-32B')

DEBUG = False

# =====================================================

# ====== prompt æ„å»º ======



PROMPT_HEADER = (
    "è¯·ä»¥ n o t h i n k æ¨¡å¼å·¥ä½œï¼šä¸è¦è¾“å‡ºæ¨ç†è¿‡ç¨‹ã€è§£é‡Šã€é¢å¤–æ–‡å­—ï¼›åªè¾“å‡ºæœ€ç»ˆ JSONã€‚\n"
    "ä½ æ˜¯åŒ»é™¢å†…çš„å°±åŒ»é¢„é—®è¯Šä¸é™¢å†…æµç¨‹/å¯¼èˆªé—®è¯¢åŠ©æ‰‹ï¼ˆhospital pre-triage & in-hospital navigationï¼‰ã€‚\n\n"

    "å”¯ä¸€ç›®æ ‡ï¼šå¯¹è¾“å…¥çš„ä¸­æ–‡ ASR æ–‡æœ¬åšâ€œæœ€å°å¿…è¦çº é”™â€ï¼Œä¿®æ­£æ˜æ˜¾é”™è¯¯ï¼Œä½¿å…¶åœ¨åŒ»é™¢é—®è¯¢åœºæ™¯ä¸‹æ›´è‡ªç„¶ã€æ¸…æ™°ã€å¯ç†è§£ã€‚\n"
    "é‡ç‚¹ä»»åŠ¡ï¼šå¤„ç†åŒéŸ³/è¿‘éŸ³è¯¯è¯†åˆ«ï¼ˆhomophonesï¼‰ï¼Œå¹¶ä¼˜å…ˆä½¿ç”¨æˆ‘æä¾›çš„ã€çƒ­è¯åˆ—è¡¨ã€‘æ¥çº æ­£ã€‚\n\n"

    "ç¡¬è§„åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š\n"
    "1) æœ€å°ç¼–è¾‘ä¼˜å…ˆï¼ˆminimal editï¼‰ï¼šåªæ”¹æ˜æ˜¾é”™è¯¯ç‰‡æ®µï¼Œå°½é‡ä¿ç•™åŸå¥ç»“æ„ä¸ä¿¡æ¯ï¼›ä¸è¦éšæ„æ”¹å†™æ•´å¥ã€‚\n"
    "2) è¯­ä¹‰ç±»å‹å®ˆæ’ï¼ˆdo not change symptom categoryï¼‰ï¼š\n"
    "   - ä¸è¦ä¸ºäº†å‘½ä¸­çƒ­è¯è€Œæ”¹å˜ç—‡çŠ¶/äº‹ä»¶ç±»å‹ã€‚\n"
    "   - å°¤å…¶æ˜¯â€œå‡ºè¡€ç›¸å…³â€è¯ï¼šå¿…é¡»æ ¹æ®ä¸Šä¸‹æ–‡åˆ¤æ–­æ˜¯å’¯è¡€/å‘•è¡€/é»‘ä¾¿/è¡€ä¾¿ç­‰ï¼Œä¸èƒ½éšæ„æ›¿æ¢ã€‚\n"
    "3) çƒ­è¯ä¼˜å…ˆï¼ˆhighest priorityï¼‰ï¼šè‹¥æŸå¤„ç–‘ä¼¼åŒéŸ³è¯¯è¯†åˆ«ï¼Œä¸”çƒ­è¯åˆ—è¡¨ä¸­å­˜åœ¨è¯»éŸ³ç›¸è¿‘ä¸”è¯­ä¹‰æ›´åˆç†çš„å€™é€‰ï¼Œä¼˜å…ˆæ›¿æ¢ä¸ºè¯¥çƒ­è¯ã€‚\n"
    "4) çƒ­è¯æƒé‡è§„åˆ™ï¼šçƒ­è¯åˆ—è¡¨çš„æ¯ä¸€è¡Œå¯èƒ½å½¢å¦‚ â€œè¯è¯­ æƒé‡â€ã€‚\n"
    "   - æƒé‡ä¸ºæ­£ï¼šå€™é€‰å†²çªæ—¶ä¼˜å…ˆé€‰æ‹©æƒé‡æ›´é«˜è€…ï¼›\n"
    "   - æƒé‡ä¸ºè´Ÿï¼šè¯¥è¯ä¸ºç¦æ­¢è¯ï¼Œç¦æ­¢è¾“å‡ºåˆ° correctedï¼›\n"
    "   - corrected ä¸­ä¸å¾—åŒ…å«æƒé‡æ•°å­—ã€‚\n"
    "5) è‹¥çƒ­è¯ä¸­æ²¡æœ‰åˆç†å€™é€‰ï¼Œæ‰åšå¸¸è§„ä¸­æ–‡çº é”™ï¼›ä»éœ€éµå®ˆæœ€å°ç¼–è¾‘ä¸è¯­ä¹‰ç±»å‹å®ˆæ’ã€‚\n"
    "6) è¯­ä¹‰å®ˆæ’ï¼ˆç¡¬è§„åˆ™ï¼‰ï¼š\n"
    " - éƒ¨ä½å®ˆæ’ï¼šè‹¥åŸå¥æˆ–é‚»è¿‘å¥åŒ…å«â€œèƒ¸/å‰èƒ¸/å·¦å‰èƒ¸/èƒ¸é—·/èƒ¸ç—›/å’³å—½/å‘¼å¸å›°éš¾â€ç­‰çº¿ç´¢ï¼Œåˆ™çº é”™ååº”ä¼˜å…ˆä¿æŒä¸ºèƒ¸éƒ¨/å‘¼å¸ç³»ç»Ÿç›¸å…³è¡¨è¾¾ï¼›\n"
    " é™¤éåŸå¥æ˜ç¡®æåˆ°â€œè…¹/è‚šå­/èƒƒ/æ‹‰è‚šå­/æ’ä¾¿/æ¶å¿ƒå‘•åâ€ç­‰çº¿ç´¢ï¼Œå¦åˆ™ç¦æ­¢æŠŠç–¼ç—›æ”¹æˆâ€œè…¹ç—›â€ã€‚\n"
    " - å‡ºè¡€ç±»å‹å®ˆæ’ï¼šè‹¥å‡ºè¡€ç›¸å…³ç‰‡æ®µä¸â€œå’³å—½/å’³ç—°/èƒ¸éƒ¨ä¸é€‚â€ç›¸é‚»ï¼Œä¼˜å…ˆçº æ­£ä¸ºâ€œå’¯è¡€/å’³è¡€â€ï¼›\n"
    " - è§£å‰–éƒ¨ä½å®ˆæ’ï¼šé™¤éç”¨æˆ·åŸå¥ä¸­æ˜ç¡®å‡ºç°æŸä¸ªèº«ä½“éƒ¨ä½ï¼ˆå¦‚è„š/è…¿/æ‰‹/èƒŒ/è…°ï¼‰ï¼Œå¦åˆ™ç¦æ­¢åœ¨çº é”™åæ–°å¢è¯¥éƒ¨ä½è¯ï¼›ç–¼ç—›æè¿°ä¼˜å…ˆç”¨â€œç–¼ç—›æ€§è´¨è¯â€ï¼ˆç»ç—›/åˆºç—›/é—·ç—›/å‹æ¦¨ç—›ï¼‰è€Œä¸æ˜¯æ–°å¢éƒ¨ä½è¯ã€‚\n"
    " è‹¥ä¸â€œå‘•å/èƒƒ/æ’ä¾¿/é»‘ä¾¿/è¡€ä¾¿â€ç›¸é‚»ï¼Œæ‰å¯çº æ­£ä¸ºâ€œå‘•è¡€/é»‘ä¾¿/è¡€ä¾¿â€ã€‚\n"
    "- è‹¥æ— æ³•ç¡®å®šï¼Œåº”å®å¯ä¿ç•™åŸç‰‡æ®µï¼ˆæˆ–åšæ›´ä¿å®ˆçš„çº é”™ï¼‰ï¼Œä¸è¦æ“…è‡ªæ›¿æ¢ä¸ºå¦ä¸€ç±»ç—‡çŠ¶ã€‚\n"
    "7) ç–¼ç—›çŸ­è¯­ç±»å‹åˆ¤å®šï¼ˆç”¨äºæ¶ˆæ­§ï¼Œå¿…é¡»æ‰§è¡Œï¼‰ï¼š\n"
    "   - å½“å‡ºç°â€œXç—›/â€¦ç—›â€çš„ç‰‡æ®µæ—¶ï¼Œå…ˆåˆ¤æ–­ X å±äºå“ªä¸€ç±»ï¼š\n"
    "     A. èº«ä½“éƒ¨ä½ç±»ï¼ˆbody-partï¼‰â†’ ä¾‹å¦‚â€œè„šç—›/è…¹ç—›/èƒ¸ç—›/è€³ç—›/å…³èŠ‚ç—›â€ç­‰ï¼›\n"
    "     B. ç–¼ç—›æ€§è´¨ç±»ï¼ˆpain-qualityï¼‰â†’ ä¾‹å¦‚â€œç»ç—›/åˆºç—›/é—·ç—›/èƒ€ç—›/å‹æ¦¨æ ·ç–¼ç—›â€ç­‰ã€‚\n"
    "   - åˆ¤å®šä¾æ®åªèƒ½ä½¿ç”¨â€œå±€éƒ¨ç»“æ„ + åŸå¥ä¿¡æ¯â€ï¼Œä¸å¾—å‡­ç©ºçŒœæµ‹ï¼š\n"
    "     â€¢ è‹¥åŸå¥å·²ç»å‡ºç°æ˜ç¡®éƒ¨ä½è¯ï¼ˆå¦‚â€œèƒ¸/è…¹/è„š/è…¿/è€³/è…°/èƒŒ/å…³èŠ‚â€ç­‰ï¼‰å¹¶åœ¨åŒä¸€å¥æˆ–ç›¸é‚»çŸ­è¯­ä¸­æŒ‡å‘åŒä¸€å¤„ç–¼ç—›ï¼Œåˆ™ä¼˜å…ˆè¾“å‡ºéƒ¨ä½ç±»ï¼›\n"
    "     â€¢ è‹¥åŸå¥åŒæ—¶å‡ºç°â€œé’ˆåˆºæ ·/é—·èƒ€/å‹æ¦¨æ ·/çƒ§ç¼æ ·â€ç­‰æ€§è´¨æè¿°ï¼Œä¸”è¯¥â€œXç—›â€ç”¨äºæè¿°æ„Ÿè§‰æ€§è´¨ï¼ˆå¦‚â€œé‚£ç§___çš„æ„Ÿè§‰â€ï¼‰ï¼Œä¼˜å…ˆè¾“å‡ºæ€§è´¨ç±»ï¼ˆå¦‚ç»ç—›/åˆºç—›/é—·ç—›/èƒ€ç—›ï¼‰ã€‚\n"
    "   - å¯¹åŒéŸ³æ­§ä¹‰å¿…é¡»åšä¿å®ˆé€‰æ‹©ï¼š\n"
    "     â€¢ å½“ â€œè„šç—›/ç»ç—›â€ è¿™ç±»åŒéŸ³å€™é€‰åŒæ—¶åˆç†æ—¶ï¼Œä¼˜å…ˆé€‰æ‹©ä¸åŸå¥æ•´ä½“ä¸€è‡´ä¸”â€œæ–°å¢ä¿¡æ¯æ›´å°‘â€çš„é‚£ä¸ªï¼›æˆ‘çš„è„šç—›éå¸¸è„šç—› -> æˆ‘çš„è„šç—›éå¸¸ç»ç—›ï¼Œè€Œä¸æ˜¯ç–¼ç—›ï¼Œå› ä¸ºæ‹¼éŸ³è¦å°½é‡ç›¸ä¼¼ï¼\n"
    "     â€¢ è‹¥ä»æ— æ³•å¯é åˆ¤æ–­ï¼Œæ”¹ä¸ºæ›´ä¸­æ€§çš„è¡¨è¾¾ï¼šâ€œç–¼ç—›/ç—›æ„Ÿ/ä¸é€‚â€ï¼Œä¸è¦å¼ºè¡Œé€‰ä¸€ä¸ªå…·ä½“è¯ã€‚\n"
    "8) å»é™¤æ˜æ˜¾å¼‚å¸¸æ ‡ç‚¹ï¼šå¦‚å¥é¦–å­¤ç«‹æ ‡ç‚¹ã€é‡å¤é€—å·ç­‰ï¼›ä½†ä¸è¦è¿‡åº¦æ–‡å­¦åŒ–æ¶¦è‰²ã€‚\n"
    "9) åŠ ä¸€ä¸ªå¼ºåˆ¶çº¦æŸï¼šæ‹¼éŸ³xiaohuçš„å•è¯æ¯”å¦‚å°æˆ·ï¼Œå°è™ï¼Œå°èƒ¡å¿…é¡»éƒ½æ”¹æˆå°æŠ¤ï¼Œå¹¶ä¸”å°æŠ¤å°æŠ¤æœ€åæ˜¾ç¤ºä¸€éå³å¯ã€‚\n\n"

    "è¾“å‡ºå¿…é¡»ä¸¥æ ¼ä¸º JSONï¼ˆåªè¾“å‡º JSONï¼Œä¸è¦ä»£ç å—ï¼‰ï¼š\n"
    "{\n"
    "  \"corrected\": \"...\",\n"
    "  \"changed\": true_or_false\n"
    "}\n"
)


def build_prompt(context: List[Dict[str, str]], options: List[str], original: str) -> str:
    ctx_lines = []
    for m in context:
        role = m.get("role", "")
        content = m.get("content", "")
        ctx_lines.append(f"{role}: {content}")
    ctx_text = "\n".join(ctx_lines)
    options_text = "\n".join(f"- {opt}" for opt in options)

    prompt = (
        PROMPT_HEADER
        + "ä¸Šä¸‹æ–‡ï¼ˆè¿‘å¯¹è¯å†å²ï¼‰ï¼š\n"
        + ctx_text
        + "\n\nå½“å‰å¯é€‰é¡¹ï¼š\n"
        + options_text
        + "\n\nè¯·ä¿®æ­£çš„åŸå¥ï¼š\n"
        + f"'{original}'\n"
    )
    return prompt


# ====== å¤å†™çš„è¾…åŠ©å‡½æ•°ï¼ˆç‹¬ç«‹éƒ¨ç½²ï¼Œä¸ä¾èµ– shared æ¨¡å—ï¼‰ ======

def _get_voice_model_config() -> dict:
    """
    è·å–æ¨¡å‹é…ç½®ï¼ˆvoice-service ç‹¬ç«‹ç‰ˆæœ¬ï¼‰
    ä¼˜å…ˆçº§ï¼šç¯å¢ƒå˜é‡ > é»˜è®¤å€¼
    """
    return {
        "base_url": os.getenv("AI_MODEL_BASE_URL", "http://172.24.27.11:5105/v1"),
        "api_key": os.getenv("AI_MODEL_API_KEY", "eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIyZWIwYjliZGZkNGI0NjJhOTczM2UzODAyNDM1ZWZlYyIsIm1ldGhvZHMiOiJQT1NUIiwiaWF0IjoiMTc1Nzk4ODA3MyIsImV4cCI6IjE3NTc5OTE2NzMifQ.mQ-g1g5ICkZ_8_kFEx-AABgPvYGrtGOsZCcz0ad6pSicmw6H6SMLFl6iq3-Q9WERN9GK70jIzssQdOlsuw7IFz4pd52hwL5n73Ha8ujAQndLMvlCaqt7gaZGI7E9NqqwY6yba3O3IBMiG7rqxp50kACBw0U4XmZZ7LV0RA--3jRCUF5pv5-ksBAVMb6d-yL5HEDp9FHgggfV_1EGC3hxjw-E4lUyvCuzUjMWNj9NNqa9Sy7pJSPNfeLCgg1QOFTKyJlUxb_Snu0GZ3NAtYBi8Woka-18DXswhZf7FNyPxz5Nlq0yQXveqfxyujaFAMRDUYolGn7bZnyQbQbf3QdGVw"),
        "model_name": os.getenv("AI_MODEL_MODEL_NAME", "Qwen3-32B"),
    }


def _extract_json_from_text_voice(content: str) -> Optional[Any]:
    """Try multiple strategies to parse JSON from a model's text content."""
    if not content:
        return None
    # 1) Direct parse
    try:
        return json.loads(content)
    except Exception:
        pass
    # 2) ```json ... ``` block
    m = re.search(r"```json\s*(.*?)\s*```", content, re.S | re.I)
    if m:
        try:
            return json.loads(m.group(1))
        except Exception:
            pass
    # 3) Strip common fences
    stripped = re.sub(r"```json|```", "", content).strip()
    if stripped:
        try:
            return json.loads(stripped)
        except Exception:
            pass
    # 4) Fallback: first outermost JSON-looking braces
    m2 = re.search(r"\{[\s\S]*\}", content)
    if m2:
        try:
            return json.loads(m2.group(0))
        except Exception:
            pass
    return None


def _with_retries_voice(fn: Callable[[], Any], *, retries: int = 3, base_delay: float = 0.8, model_info: str = '') -> Any:
    """Run a callable with simple exponential backoff retries on transient failures."""
    last_exc: Optional[Exception] = None
    for attempt in range(1, max(1, retries) + 1):
        try:
            return fn()
        except Exception as e:  # Capture and retry transient failures
            logger.error("%s ç¬¬%d/%dæ¬¡å°è¯•è°ƒç”¨å¤±è´¥ï¼š%s", model_info, attempt, retries, e)
            last_exc = e
            if attempt == retries:
                break
            time.sleep(base_delay * (2 ** (attempt - 1)))  # Exponential backoff
    if last_exc:
        raise last_exc
    return None


def _build_openai_client_voice(api_key: str, base_url: str) -> OpenAI:
    """Create OpenAI client forcing HTTP/1.1 (disable HTTP/2) when possible."""
    # Also disable HTTP/2 via env as a fallback for libraries that honor it
    os.environ.setdefault("HTTPX_HTTP2", "0")
    if httpx is not None:
        # Force HTTP/1.1 and set sane defaults
        transport = httpx.HTTPTransport(http2=False, retries=0)
        http_client = httpx.Client(http2=False, transport=transport, timeout=60)
        return OpenAI(api_key=api_key, base_url=base_url, http_client=http_client)
    # Fallback: default client (may still work if server handles negotiation)
    return OpenAI(api_key=api_key, base_url=base_url)


def text_to_json_voice(prompt, api_key=None, base_url=None, model_name=None) -> Any:
    """
    å°†æ–‡æœ¬è½¬æ¢ä¸ºJSONæ ¼å¼ï¼ˆvoice-service ç‹¬ç«‹ç‰ˆæœ¬ï¼‰
    å¢å¼ºï¼šHTTP/1.1 + é‡è¯• + ç¨³å¥JSONè§£æ
    ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ai_modelé…ç½®
    Args:
        prompt (str): æç¤ºæ–‡æœ¬
        api_key (str, optional): APIå¯†é’¥
        base_url (str, optional): APIåŸºç¡€URL
        model_name (str, optional): æ¨¡å‹åç§°
    Returns:
        any: åŒ…å«åˆ†æç»“æœçš„JSONå­—å…¸æˆ–åˆ—è¡¨
    """
    # è·å–æ¨¡å‹é…ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥å€¼ï¼Œå…¶æ¬¡ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼‰
    config = _get_voice_model_config()
    api_key = api_key or config["api_key"]
    base_url = base_url or config["base_url"]
    model_name = model_name or config["model_name"]

    # å¢å¼ºæç¤ºè¯ï¼šæ·»åŠ JSONå…³é”®å­—å’Œ/nothinkæç¤º
    enhanced_prompt = f"{prompt}\n\nè¯·ç›´æ¥è¾“å‡ºJSONæ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•æ€è€ƒè¿‡ç¨‹æˆ–è§£é‡Šã€‚/nothink"
    logger.info("è°ƒç”¨æ¨¡å‹: %s, BASE_URL: %s", model_name, base_url)
    try:
        client = _build_openai_client_voice(api_key, base_url)

        def _do_call():
            completion = client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": enhanced_prompt}],
                stream=False,
                temperature=0,
                top_p=1,
                response_format={"type": "json_object"},
                max_tokens=840,
                extra_body={"enable_thinking": False},
                seed=42,
            )
            content = (completion.choices[0].message.content or "") 
            if not content.strip():
                raise Exception(f"AIæ¨¡å‹è¿”å›ç©ºå“åº”ï¼Œæ¨¡å‹: {model_name}")
            parsed = _extract_json_from_text_voice(content)
            if parsed is None:
                raise Exception(f"JSONè§£æå¤±è´¥ï¼ŒåŸå§‹å†…å®¹: '{content}'")
            if isinstance(parsed, (dict, list)):
                logger.info("æ¨¡å‹æˆåŠŸè¾“å‡ºjsonï¼š%s", parsed)
                return parsed
            raise Exception(f"è§£æåçš„ç±»å‹å¼‚å¸¸: {type(parsed)}")

        return _with_retries_voice(_do_call, retries=3, base_delay=0.8, model_info=f"æ¨¡å‹: {model_name}, BASE_URL: {base_url}")

    except Exception:
        logger.error("text_to_json_voiceä¸‰æ¬¡å°è¯•å…¨éƒ¨å¤±è´¥ï¼Œæ¨¡å‹: %s, BASE_URL: %s\n%s", model_name, base_url, traceback.format_exc())
        return None


# ====== ç®€åŒ–çš„åŒæ­¥è°ƒç”¨ï¼ˆä¸ä½¿ç”¨æµå¼ï¼‰ ======
def query_final(prompt: str, max_tokens: int = 150) -> str:
    """ä½¿ç”¨text_to_json_voiceè°ƒç”¨LLM APIï¼ˆvoice-service ç‹¬ç«‹ç‰ˆæœ¬ï¼‰"""
    try:
        # ä½¿ç”¨text_to_json_voiceè·å–JSONæ ¼å¼çš„å“åº”
        result = text_to_json_voice(prompt)
        
        if result is None:
            if DEBUG:
                logger.info("text_to_json_voiceè¿”å›None")
            return ""
        
        # å°†JSONç»“æœè½¬æ¢ä¸ºå­—ç¬¦ä¸²è¿”å›
        if isinstance(result, (dict, list)):
            return json.dumps(result, ensure_ascii=False)
        else:
            return str(result)
            
    except Exception as e:
        if DEBUG:
            logger.info("è°ƒç”¨æ¨¡å‹å‘ç”Ÿå¼‚å¸¸ï¼š %s", e)
        return ""

# ====== è§£ææ¨¡å‹è¾“å‡ºï¼ˆç®€åŒ–ç‰ˆï¼‰ ======


def _extract_via_regex(raw: str):
    """ç”¨ç®€å•æ­£åˆ™å°è¯•ä»éä¸¥æ ¼ JSON çš„æ–‡æœ¬ä¸­æŠ“å– corrected å’Œ matchesã€‚"""
    corrected = None
    matches = []
    # corrected
    m = re.search(r'"corrected"\s*:\s*"((?:\\.|[^"\\])*)"', raw, re.S)
    if m:
        corrected = m.group(1).encode('utf-8').decode('unicode_escape') if '\\' in m.group(1) else m.group(1)

    # matches array - æŠ“æ‰€æœ‰åŒå¼•å·å†…å…ƒç´ 
    m2 = re.search(r'"matches"\s*:\s*\[\s*((?:.|\s)*?)\s*\]', raw, re.S)
    if m2:
        inner = m2.group(1)
        items = re.findall(r'"((?:\\.|[^"\\])*)"', inner)
        for it in items:
            val = it.encode('utf-8').decode('unicode_escape') if '\\' in it else it
            matches.append(val)
    return corrected, matches


def parse_model_output(raw: str, original: str = "") -> Dict[str, Any]:
    raw = (raw or "").strip()
    logger.info("ğŸ” å¼€å§‹è§£æLLMè¾“å‡º:")
    logger.info("åŸå§‹è¾“å…¥: %s", repr(raw))
    logger.info("è¾“å…¥é•¿åº¦: %s", len(raw))
    
    # ç”±äºä½¿ç”¨äº†text_to_jsonï¼Œrawå·²ç»æ˜¯JSONå­—ç¬¦ä¸²ï¼Œç›´æ¥è§£æ
    try:
        data = json.loads(raw)
        logger.info("âœ… JSONè§£ææˆåŠŸ: %s", data)
        if isinstance(data, dict):
            matches = data.get("matches", [])
            has_match = bool(matches)
            result = {
                "success": True,
                "corrected": data.get("corrected", original),
                "matches": matches,
                "has_match": has_match,
                "raw": raw,
                "matched_via": "model",
                "error": None,
            }
            logger.info("âœ… è§£æç»“æœ: %s", result)
            return result
    except Exception as e:
        logger.error("âŒ JSONè§£æå¤±è´¥: %s", e)
        pass

    # 2) ç®€å•æ­£åˆ™æŠ“å–
    corr, matches = _extract_via_regex(raw)
    if corr is not None or matches:
        has_match = bool(matches)
        return {
            "success": True,
            "corrected": corr or original,
            "matches": matches or [],
            "has_match": has_match,
            "raw": raw,
            "matched_via": "regex",
            "error": "parsed_via_regex",
        }

    # 3) å…¨éƒ¨å¤±è´¥
    return {
        "success": False,
        "corrected": original,
        "matches": [],
        "has_match": False,
        "raw": raw,
        "matched_via": "none",
        "error": "invalid json from model",
    }

# ====== æ ¡éªŒ/å½’ä¸€åŒ–å·¥å…·ï¼ˆä¿ç•™ç”¨äºéªŒè¯æ¨¡å‹è¿”å›çš„ matchesï¼‰ ======


def normalize_str_for_match(s: str) -> str:
    if not isinstance(s, str):
        return ""
    t = re.sub(r'\s+', '', s)
    return t.lower()

# ====== å¯¹å¤–ä¸»æ¥å£ï¼ˆå·²ç§»é™¤å¯å‘å¼é™çº§ï¼Œçº¯æ¨¡å‹è¿”å› + å®¢æˆ·ç«¯éªŒè¯ï¼‰ ======


def process_with_context(context: List[Dict[str, str]],
                         options: List[str],
                         text: str) -> Dict[str, Any]:
    original = (text or "").strip()
    if not original:
        return {
            "success": False,
            "corrected": "",
            "matches": [],
            "has_match": False,
            "matched_via": "none",
            "raw": "",
            "error": "empty input",
        }

    prompt = build_prompt(context, options, original)
    start_time = time.time()
    raw = query_final(prompt, max_tokens=200)
    end_time = time.time()
    if DEBUG:
        logger.info("Model call time: %.3fs", end_time - start_time)
        logger.info("Raw model output preview: %s", raw[:400])
        print("="*50)
        logger.info("ğŸ” LLMåŸå§‹è¾“å‡º:")
        logger.info("ç±»å‹: %s", type(raw))
        logger.info("é•¿åº¦: %s", len(raw) if raw else 0)
        logger.info("å†…å®¹: %s", repr(raw))
        print("="*50)

    parsed = parse_model_output(raw, original=original)

    # æ ¡éªŒå¹¶å½’ä¸€åŒ–æ¨¡å‹ç»™çš„ matchesï¼ˆè‹¥æœ‰ï¼‰
    if parsed.get("success") and parsed.get("matches"):
        validated = []
        seen = set()
        def norm(x): return normalize_str_for_match(x)
        for m in parsed.get("matches", []):
            if not isinstance(m, str):
                continue
            if m in options:
                cand = m
            else:
                cand = next((o for o in options if norm(m) in norm(o) or norm(o) in norm(m)), None)
            if cand and cand not in seen:
                seen.add(cand)
                validated.append(cand)
        parsed["matches"] = validated
        parsed["has_match"] = bool(validated)
        if parsed["has_match"]:
            parsed["success"] = True
            parsed["matched_via"] = parsed.get("matched_via", "model")
            parsed["error"] = None
            return parsed
        else:
            # å¦‚æœæ¨¡å‹ç»™äº† matches ä½†æ ¡éªŒæœªé€šè¿‡ï¼Œåˆ™ä¸å†å°è¯•ä»»ä½•å¯å‘å¼ï¼Œç›´æ¥è¿”å›æ— åŒ¹é…çš„ç»“æœ
            parsed["matches"] = []
            parsed["has_match"] = False
            parsed["success"] = parsed.get("success", False)
            parsed["matched_via"] = parsed.get("matched_via", "model")
            parsed["error"] = "model_matches_not_validated"
            return parsed

    # è‹¥æ¨¡å‹æœªè¿”å› matches æˆ–è§£æå¤±è´¥ï¼Œåˆ™ç›´æ¥è¿”å› parsedï¼ˆå¯èƒ½æ²¡æœ‰åŒ¹é…ï¼‰
    return {
        "success": parsed.get("success", False),
        "corrected": parsed.get("corrected", original),
        "matches": parsed.get("matches", []),
        "has_match": parsed.get("has_match", False),
        "matched_via": parsed.get("matched_via", "none"),
        "raw": parsed.get("raw", ""),
        "error": parsed.get("error", "no match found"),
    }


def load_hotwords_list() -> List[str]:
    """
    ä» hotwords.txt æ–‡ä»¶åŠ è½½çƒ­è¯åˆ—è¡¨ï¼ˆä»…è¿”å›çƒ­è¯ï¼Œå¿½ç•¥æƒé‡ï¼‰
    
    è¿”å›:
        List[str]: çƒ­è¯åˆ—è¡¨
    """
    hotwords = []
    try:
        # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
        current_dir = os.path.dirname(os.path.abspath(__file__))
        hotwords_file = os.path.join(current_dir, "hotwords.txt")
        
        # å¦‚æœå½“å‰ç›®å½•ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨ç›¸å¯¹è·¯å¾„
        if not os.path.exists(hotwords_file):
            hotwords_file = "app/services/hotwords.txt"
        
        with open(hotwords_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:  # è·³è¿‡ç©ºè¡Œ
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æƒé‡ï¼ˆåŒ…å«ç©ºæ ¼ä¸”æœ€åä¸€éƒ¨åˆ†æ˜¯æ•°å­—ï¼Œå¯èƒ½å¸¦è´Ÿå·ï¼‰
                if ' ' in line:
                    parts = line.rsplit(' ', 1)
                    word = parts[0].strip()
                    weight_str = parts[1].strip()
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°å­—ï¼ˆå¯èƒ½å¸¦è´Ÿå·ï¼‰
                    try:
                        int(weight_str)  # å°è¯•è½¬æ¢ä¸ºæ•´æ•°
                        # å¦‚æœæ˜¯æ•°å­—ï¼Œåˆ™ word æ˜¯çƒ­è¯
                        if word:
                            hotwords.append(word)
                    except ValueError:
                        # å¦‚æœä¸æ˜¯æ•°å­—ï¼Œæ•´è¡Œä½œä¸ºçƒ­è¯
                        if line:
                            hotwords.append(line)
                else:
                    # æ²¡æœ‰ç©ºæ ¼ï¼Œæ•´è¡Œä½œä¸ºçƒ­è¯
                    hotwords.append(line)
        
        logger.info("ä» hotwords.txt åŠ è½½äº† %d ä¸ªçƒ­è¯", len(hotwords))
    except Exception as e:
        logger.error("åŠ è½½çƒ­è¯æ–‡ä»¶å¤±è´¥: %s", e)
        # ä½¿ç”¨é»˜è®¤çƒ­è¯
        hotwords = ["å°æŠ¤", "èƒ¸é—·", "èƒ¸ç—›", "å‘çƒ­", "å‘•å"]
    
    return hotwords


def correct_text_only(latest_context=None, latest_options=None, text=None, DEBUG=False):
    """
    ä»…å¯¹æ–‡æœ¬è¿›è¡Œä¿®æ­£ï¼Œä¸è¿›è¡ŒåŒ¹é…æ“ä½œã€‚
    ä¿®æ­£åŒ…æ‹¬ï¼šé”™åˆ«å­—ã€å‘éŸ³ç›¸ä¼¼ä½†ä¸ç¬¦åˆåŒ»ç–—åœºæ™¯çš„è¯ï¼ˆç»“åˆhotwordsåˆ¤æ–­ï¼‰

    å‚æ•°:
        latest_context (list | None): å†å²ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥ä¸ºç©ºã€‚
        latest_options (list | None): çƒ­è¯åˆ—è¡¨ï¼Œç”¨äºå¸®åŠ©ä¿®æ­£å‘éŸ³ç›¸ä¼¼çš„è¯ã€‚
        text (str | None): åŸå§‹è¯­éŸ³è¯†åˆ«ç»“æœï¼Œå¯ä»¥ä¸ºç©ºã€‚
        DEBUG (bool): æ˜¯å¦è¾“å‡ºè°ƒè¯•ä¿¡æ¯ã€‚

    è¿”å›:
        str: ä¿®æ­£åçš„æ–‡æœ¬
    """
    # å¦‚æœ text ä¸ºç©ºï¼Œç›´æ¥è¿”å›ç©ºå­—ç¬¦ä¸²
    if not text or str(text).strip() == "":
        return ""

    # ç¡®ä¿ context å’Œ options ä¸ä¸ºç©º
    latest_context = latest_context or []
    latest_options = latest_options or []

    # è°ƒç”¨å¤–éƒ¨çº é”™å‡½æ•°
    post_text = process_with_context(latest_context, latest_options, text)
    correct_text = post_text.get("corrected", text)

    if DEBUG:
        logger.info("LLMå¤„ç†å‰çš„æ–‡æœ¬: %s", text)
        logger.info("LLMä¿®æ­£åçš„æ–‡æœ¬: %s", correct_text)

    return correct_text


def correct_text_only(latest_context=None, latest_options=None, text=None, DEBUG=False):
    """
    ä»…å¯¹æ–‡æœ¬è¿›è¡Œä¿®æ­£ï¼Œä¸è¿›è¡ŒåŒ¹é…æ“ä½œã€‚
    ä¿®æ­£åŒ…æ‹¬ï¼šé”™åˆ«å­—ã€å‘éŸ³ç›¸ä¼¼ä½†ä¸ç¬¦åˆåŒ»ç–—åœºæ™¯çš„è¯ï¼ˆç»“åˆhotwordsåˆ¤æ–­ï¼‰

    å‚æ•°:
        latest_context (list | None): å†å²ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥ä¸ºç©ºã€‚
        latest_options (list | None): çƒ­è¯åˆ—è¡¨ï¼Œç”¨äºå¸®åŠ©ä¿®æ­£å‘éŸ³ç›¸ä¼¼çš„è¯ã€‚
        text (str | None): åŸå§‹è¯­éŸ³è¯†åˆ«ç»“æœï¼Œå¯ä»¥ä¸ºç©ºã€‚
        DEBUG (bool): æ˜¯å¦è¾“å‡ºè°ƒè¯•ä¿¡æ¯ã€‚

    è¿”å›:
        str: ä¿®æ­£åçš„æ–‡æœ¬
    """
    # å¦‚æœ text ä¸ºç©ºï¼Œç›´æ¥è¿”å›ç©ºå­—ç¬¦ä¸²
    if not text or str(text).strip() == "":
        return ""

    # ç¡®ä¿ context å’Œ options ä¸ä¸ºç©º
    latest_context = latest_context or []
    latest_options = latest_options or []

    # è°ƒç”¨å¤–éƒ¨çº é”™å‡½æ•°
    post_text = process_with_context(latest_context, latest_options, text)
    correct_text = post_text.get("corrected", text)

    if DEBUG:
        logger.info("LLMå¤„ç†å‰çš„æ–‡æœ¬: %s", text)
        logger.info("LLMä¿®æ­£åçš„æ–‡æœ¬: %s", correct_text)

    return correct_text


def process_speech_result(latest_context=None, latest_options=None, text=None, useQwen=None, DEBUG=False):
    """
    å¤„ç†è¯­éŸ³è¯†åˆ«ç»“æœï¼Œå¹¶æ ¹æ®ä¸Šä¸‹æ–‡å’Œå¯é€‰é¡¹è¿›è¡Œçº æ­£ä¸åŒ¹é…ã€‚

    å‚æ•°:
        latest_context (list | None): å†å²ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥ä¸ºç©ºã€‚
        latest_options (list | None): å¯é€‰é¡¹ï¼Œå¯ä»¥ä¸ºç©ºã€‚
        text (str | None): åŸå§‹è¯­éŸ³è¯†åˆ«ç»“æœï¼Œå¯ä»¥ä¸ºç©ºã€‚

    è¿”å›:
        tuple: (latest_context, latest_options, corrected_text)
    """

    # å¦‚æœ text ä¸ºç©ºï¼Œç›´æ¥è¿”å›ç©ºå­—ç¬¦ä¸²
    if not text or str(text).strip() == "":
        return "", ""

    # ç¡®ä¿ context å’Œ options ä¸ä¸ºç©º
    latest_context = latest_context or []
    latest_options = latest_options or []

    # è°ƒç”¨å¤–éƒ¨çº é”™å‡½æ•°
    post_text = process_with_context(latest_context, latest_options, text)
    correct_text = post_text.get("corrected", text)

    # åŒ¹é…æ„å›¾
    if "matches" in post_text and post_text["matches"]:

        # -----------Qwen--------------
        if useQwen:
            try:
                raw_data = post_text.get("raw", "")
                if raw_data and raw_data.strip():
                    parsed_data = json.loads(raw_data)
                    match_string = '", "'.join(parsed_data.get("matches", []))
                else:
                    match_string = '", "'.join(post_text.get("matches", []))
                logger.info("\033[95m>>>>>>>>>>>>>>>>>>åŸºäºåŸå§‹æ–‡æœ¬_æ„å›¾åŒ¹é…ç»“æœ: %s  \033[0m\n", match_string)
            except (json.JSONDecodeError, KeyError) as e:
                logger.warning("JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨åŒ¹é…: %s", e)
                match_string = '", "'.join(post_text.get("matches", []))
        # ------------deepseek------------------
        else:
            match_string = '", "'.join(post_text["matches"])
    else:
        match_string = ""

    if DEBUG:
        logger.info("\033[95m>>>>>>>>>>>>>>>>>>LLMå¤„ç†å‰çš„è¯­éŸ³è¯†åˆ«ç»“æœ: %s  \033[0m\n", text)
        logger.info("\033[95m>>>>>>>>>>>>>>>>>>LLMä¿®æ­£åçš„è¯­éŸ³è¯†åˆ«ç»“æœ: %s  \033[0m\n", correct_text)
        if match_string:
            logger.info("\033[95m>>>>>>>>>>>>>>>>>>åŸºäºé€‰é¡¹_æ„å›¾åŒ¹é…ç»“æœ: %s  \033[0m\n", match_string)
        else:
            logger.error("\033[91m>>>>>>>>>>>>>>>>>>æœªåŒ¹é…ç»“æœ: æ— åŒ¹é…é¡¹ \033[0m\n")

    return match_string, correct_text






############################################################################################################
# ====== CLI ç¤ºä¾‹ï¼ˆæœ¬åœ°æµ‹è¯•ï¼‰ ======
if __name__ == "__main__":
    # é…ç½®æ—¥å¿—è¾“å‡ºåˆ°æ§åˆ¶å°
    import sys
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        stream=sys.stdout
    )
    
    # è·å–é…ç½®ä¿¡æ¯ï¼ˆä½¿ç”¨text_to_json_voiceçš„é…ç½®é€»è¾‘ï¼‰
    config = _get_voice_model_config()
    base_url = config["base_url"]
    model_name = config["model_name"]
    api_key = config["api_key"]
    
    print("="*80)
    print("ğŸš€ å¼€å§‹æµ‹è¯•è¯­éŸ³è¯†åˆ«ä¿®æ­£åŠŸèƒ½")
    print("="*80)
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"   APIåœ°å€: {base_url}")
    print(f"   æ¨¡å‹åç§°: {model_name}")
    print(f"   APIå¯†é’¥: {api_key[:20] if api_key else 'æœªè®¾ç½®'}...")
    print("="*80)

    # ä» hotwords.txt æ–‡ä»¶åŠ è½½çƒ­è¯åˆ—è¡¨
    hotwords = load_hotwords_list()
    
    # æµ‹è¯•æ¡ˆä¾‹åˆ—è¡¨ - åŒ…å«é”™åˆ«å­—å’Œå‘éŸ³ç›¸ä¼¼ä½†ä¸ç¬¦åˆåŒ»ç–—åœºæ™¯çš„è¯
    # test_cases = [
    #     "æˆ‘çš„çœ¼é•œè‚¿èƒ€çä¸å¼€çœ¼ï¼Œä¸èˆ’æœï¼Œå·²è¿‘æœ‰4å¤©äº†",  # çœ¼é•œâ†’çœ¼ç›ï¼Œå·²è¿‘â†’å·²ç»
    #     "æ‰‹è¢«åˆ«äººèœäº†ä¸€è§‰ï¼Œåˆï¼Œçº¢è‚¿ã€ç–¼ç—›çœ‹ä»€ä¹ˆç§‘",  # èœâ†’è¸©
    #     "è‚šçš®çš®è‚¤æ¨ï¼Œæ€ä¹ˆæï¼Ÿ",  # æ¨â†’ç—’
    #     "çš®è‚¤æ°§å¾—ä¸è¡Œï¼Œè€æ˜¯æƒ³æŒ ",  # æ°§â†’ç—’
    #     "å…„ç—›ï¼Œåƒè¢«çŸ³å¤´å‹ç€ä¸€æ ·",  # å…„â†’èƒ¸
    #     "èƒ¸ç„–æ°”çŸ­ï¼Œçˆ¬æ¥¼æ¢¯å°±å–˜",  # ç„–â†’é—·
    #     "èƒ¸åŠ¨ï¼Œå·¦è¾¹ç–¼å¾—å‰å®³",  # åŠ¨â†’ç—›
    #     "è¯ç–¼ï¼Œç«™ä¹…äº†å°±ç–¼",  # è¯â†’è…°
    #     "å°äº‘ï¼Œæˆ‘çš®å…»ï¼Œæ€ä¹ˆåŠï¼Ÿ",  # çš®å…»â†’çš®è‚¤ç—’
    #     "èƒ¸é—¨ï¼Œæ„Ÿè§‰é€ä¸è¿‡æ°”",  # é—¨â†’é—·
    #     "æˆ‘éœ€è¦æ‰“æ ‘å¶",  # æ ‘å¶â†’è¾“æ¶²ï¼ˆå‘éŸ³ç›¸ä¼¼ä½†ä¸ç¬¦åˆåŒ»ç–—åœºæ™¯ï¼‰
    #     "åŒ»ç”Ÿè®©æˆ‘åƒè¦",  # è¦â†’è¯
    #     "æˆ‘æœ‰ç‚¹å‘ç»•",  # ç»•â†’çƒ­
    #     "è‚šå­ç–¼ï¼Œæƒ³å",  # æ­£ç¡®ï¼Œæµ‹è¯•ä¸ä¿®æ­£
    #     "èƒ¸é—·å¾—æ…Œï¼Œå–˜ä¸ä¸Šæ°”",  # æ­£ç¡®ï¼Œæµ‹è¯•ä¸ä¿®æ­£
    #     "æˆ‘è…°å­ç–¼å¾—å‰å®³ï¼Œå·²ç»ä¸€å‘¨äº†",  # è…°å­â†’è…°
    #     "çš®è‚¤å›½æ˜ï¼Œç—’å¾—å—ä¸äº†",  # å›½æ˜â†’å‘ç—’/ç—’
    #     "å°äº‘å°äº‘ï¼Œæˆ‘å¤´æ™•çœ¼èŠ±",  # æ­£ç¡®
    #     "èƒ¸ç—›å¾—å‰å®³ï¼Œåƒé’ˆæ‰ä¸€æ ·",  # æ­£ç¡®
    #     "è…°é…¸èƒŒç–¼ï¼Œåä¹…äº†å°±éš¾å—",
    #     "æˆ‘æœ€è¿‘ç¥­å¤©ï¼Œå—¯å—¯å•Šå°±æ˜¯ å—“å­æ ·åœ°ä¸è¡Œï¼Œå¾ˆéš¾å—ï¼Œé¢œé¢å¸ƒç­’ï¼Œæµ‘èº«ä¸èˆ’æœ"# æ­£ç¡®
    # ]
    
    test_cases=["ï¼Œå°æˆ·ï¼Œå°èƒ¡ï¼Œæˆ‘æœ€è¿‘ç¥­å¤©ï¼Œï¼Œç¡®å®æœ‰è¿‡å‰§çƒˆçš„å’³ï¼Œæœ‰ä¸€ç‚¹æ²¸ç–¼ã€‚è§çªä¸‹ï¼Œè¿˜æœ‰å·¦å‰èƒ¸ç—›å§ï¼Œæ˜¯é‚£è¿™è„šç—›çš„æ„Ÿè§‰ï¼ŒèƒŒéƒ¨ä¹Ÿè„šç—›ï¼Œæ˜¯çªå‘çš„é—·èƒ€çš„é‚£ç§æ„Ÿè§‰ï¼Œä¹Ÿæœ‰ç‚¹é’ˆåˆºç—’ã€‚å‰æœŸç–¼çš„å‰å®³ä¸€ç‚¹ï¼Œç°åœ¨å¥½ç‚¹äº†ã€‚è¿˜æœ‰æ»‘è¡€"]
    
    # æµ‹è¯•æ‰€æœ‰æ¡ˆä¾‹
    print(f"\nğŸ“ çƒ­è¯æ•°é‡: {len(hotwords)}")
    print(f"ğŸ“ æµ‹è¯•æ¡ˆä¾‹æ•°é‡: {len(test_cases)}")
    print("="*80)
    
    total_time = 0
    
    for i, test_text in enumerate(test_cases, 1):
        print(f"\n{'='*80}")
        print(f"ğŸ§ª æµ‹è¯•æ¡ˆä¾‹ {i}/{len(test_cases)}")
        print(f"ğŸ“¥ åŸå§‹æ–‡æœ¬: {test_text}")
        print("-" * 80)
        
        start_time = time.time()
        try:
            corrected_text = correct_text_only(
                latest_context=None, 
                latest_options=hotwords, 
                text=test_text, 
                DEBUG=False
            )
            end_time = time.time()
            
            test_time = end_time - start_time
            total_time += test_time
            
            # åˆ¤æ–­æ˜¯å¦æœ‰ä¿®æ­£
            is_corrected = corrected_text != test_text
            
            print(f"âœ… ä¿®æ­£åæ–‡æœ¬: {corrected_text}")
            print(f"ğŸ”„ æ˜¯å¦ä¿®æ­£: {'æ˜¯' if is_corrected else 'å¦'}")
            print(f"â±ï¸  è€—æ—¶: {test_time:.3f}ç§’")
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        print("="*80)
    
    # æ€»ç»“æŠ¥å‘Š
    print("\n" + "="*80)
    print("ğŸ“ˆ æµ‹è¯•æ€»ç»“")
    print("="*80)
    print(f"æ€»æ¡ˆä¾‹æ•°: {len(test_cases)}")
    print(f"æ€»è€—æ—¶: {total_time:.3f}ç§’")
    print(f"å¹³å‡è€—æ—¶: {total_time / len(test_cases):.3f}ç§’/æ¡ˆä¾‹")
    print("="*80)
    